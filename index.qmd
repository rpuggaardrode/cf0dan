---
title: "Danish CF0"
subtitle: "maybe"
authors: 
  - name:
      given: 'Rasmus'
      family: 'Puggaard-Rode'
    affiliations:
      - id: lmu
        name: 'Institute for Phonetics and Speech Processing, <br> Ludwig Maximilian University, Munich'
    email: 'mailto:r.puggaard@phonetik.uni-muenchen.de'
    orcid: '0000-0003-4522-9987'
  - name:
      given: 'James'
      family: 'Kirby'
    affiliations:
      - ref: lmu
    email: 'jkirby@phonetik.uni-muenchen.de'
    orcid: '0000-0002-0502-5245'
  - name:
      given: 'Nicolai'
      family: 'Pharao'
    affiliations:
      - id: cph
        name: 'Department of Nordic Studies and Linguistics, <br> University of Copenhagen'
    email: 'nicolaip@hum.ku.dk'
    orcid: '0000-0002-6828-9061'
date: today
format:
  html:
    theme: cosmo
    code-fold: true
    toc: true
    toc-location: left
    reference-location: margin
    df-print: kable
  pdf:
    include-in-header:
      text: |
        \usepackage{float}
    mainfont: Times New Roman
    sansfont: Times New Roman
    df-print: kable
    execute:
      echo: false
    fig-dpi: 300
    fig-height: 4
    link-citations: true
    keep-tex: true
    prefer-html: true
bibliography: references.bib
csl: css/journal-of-linguistics.csl
number-sections: true
abstract: >
  Abstract goes here.
---

# Introduction

It is well-established that some segments exert a localized influence on pitch, which is superimposed on an overall pitch contour.
For example, pitch is higher during high vowels than during low vowels, and pitch is higher immediately following voiceless consonants than during voiced consonants.
Vowel-intrinsic *F*~0~ was first described more than a century ago [@meyer1897] and appears to be essentially universal [@whalen1995; @ting2023], although it does not appear to have phonological consequences or to play a role in sound change.
Co-intrinsic *F*~0~ of consonants [which we refer to as C*F*~0~ following e.g. @dicristo1986], i.e. the effect that consonants have on the *F*~0~ of surrounding segments, has also been documented in many languages with various kinds of laryngeal contrasts in obstruents, but the effects are rather more variable than vowel-intrinsic *F*~0~ depending on e.g. the exact implementation of the laryngeal contrast and other aspects of the phonological system [e.g. @chen2011jphon; @kirby2018jphon].
C*F*~0~ is also assumed to play a major role in tonogenetic sound change processes, where C*F*~0~ is often assumed to have transphonologized into lexical tone with concomitant loss of the voiced--voiceless contrast [@hyman1976; @kirby2017].

There is a substantial body of literature on C*F*~0~, but several open questions remain about the underlying mechanisms.
For example, it remains unclear to which extent C*F*~0~ is actively controlled or an automatic by-product of e.g. laryngeal gestures aimed at inhibiting phonation.
If it is primarily the latter, it is still not clear what exactly those gestures might look like.
It also remains an open question how exactly C*F*~0~ interacts with other more and less localized sources of prosodic modification. 
Given that some extent of C*F*~0~ appears to be near-universal [@ting2023] and can demonstrably have crucial downstream consequences for phonological systems, understanding these mechanisms is important for the phonetic sciences and the study of sound change.
In this paper, we approach some of these open questions by revisiting C*F*~0~ in Danish, where both the prosodic phonology and the laryngeal contrast in stops have properties that make it suitable for approaching these questions.

Danish is an interesting case in terms of C*F*~0~ for at least the following reasons:
1) The laryngeal contrast in stops is somewhat unusual, contrasting a series of voiceless aspirated stops [pʰ tʰ kʰ] with a series of voiceless unaspirated stops [p t k] [@hutters1985; @puggaardrode2022labphon]. 
Unlike the corresponding unaspirated stops in most other Germanic languages [e.g. @beckman2013], the Danish voiceless unaspirated stops are *actively* devoiced, in the sense that voiceless realizations are the norm even in intervocalic position [@puggaardrode2022labphon], and this is enforced through (light) glottal spreading [@fischerjorgensen1974lips; @hutters1985].
This make Danish particularly suitable for testing whether C*F*~0~ is caused by active adjustment to enhance a phonological contrast (in which case only one stop series should be affected), or whether it is caused by gestures inhibiting voicing (in which case both stop series should potentially be affected).
2) The physiology of the Danish laryngeal contrast in obstruents is -- all things considered -- studied very extensively, using fiberoptic laryngoscopy [@fischerjorgensen1969; @hutters1978; -@hutters1984; -@hutters1985], electromyography [@fischerjorgensen1974lips; @hutters1984; -@hutters1985], various measures of airflow and air pressure [@fischerjorgensen1969], among others, making a comparison between (acoustic) C*F*~0~ patterns and articulation reasonable.
3) There is regional variation in Danish in the location of the pitch peak relative to stress [e.g. @thorsen1981; @thorsen1982; -@thorsen1988; @gronnum1989; -@gronnum1990], making it possible to tease apart the respective influence of stress and high pitch on C*F*~0~, by comparing varieties where pitch peak and stress coincide with varieties where they do not.
4) Danish has a voice quality contrast (known as *stød*) which is, among other things, cued by pitch differences immediately after an initial consonant [e.g. @petersen1973; @fischerjorgensen1989; @pena2022], making it possible to investigate how C*F*~0~ interacts with other localized pitch modifications.

C*F*~0~ has already been investigated in Danish [@jeel1975; @petersen1978aripuc; -@petersen1983]; these studies suggest that C*F*~0~ is indeed found in Danish [although cf. @fischerjorgensen1969], but the studies were not designed with the aforementioned open questions in mind, and thus cannot directly be used to approach them.
Perhaps just as importantly, these studies are cited not infrequently in favor of arguments that we are not convinced the studies can actually support, which makes a larger-scale replication study valuable.

Our results show that both series of stops raise *F*~0~, although the temporal extent and magnitude of the effect differs.
Given what we know about the articulation of these stops and how voicelessness is implemented, these results challenge some existing theories of the biomechanical source of C*F*~0~; the relevant literature is covered in the next sections. 
We find some evidence of global, intonational high pitch targets enhancing C*F*~0~, but we also find a tendency for the reverse effect when there are competing phonological demands on the local pitch level.

The following two subsections review the general literature on C*F*~0~, especially pertaining to the open questions we are interested in here, and the relevant literature on the Danish laryngeal contrast, regional variability in stress and pitch peak alignment, and the implementation of stød. Our research questions and hypotheses are presented in @sec-rq.
Our experimental design, participants, recording methodology, and statistical methodology are presented in @sec-methods. 
We present the results of the study in @sec-results, and discuss them in light of our research questions and hypotheses in @sec-disc.

## Co-intrinsic *F*~0~

### General overview {#sec-cf0overview}

C*F*~0~ was first studied in English by @house1953, and has since been found in a very wide range of languages [see overviews in e.g. @kirby2018jphon; @ting2023].
C*F*~0~ effects should be thought of as deviations from an overarching pitch contour, so when studying them, it is crucial to ensure that they are compared to a suitable baseline, and that the prosodic context is controlled.
Modally voiced sonorant consonants are not expected to cause *F*~0~-perturbations, since their articulatory configuration should not provide any obstructions to airflow, so unlike in e.g. voiced stops [@sole2018], voicing proceeds without making articulatory adjustments to support it.
For this reason, nasals in particular are often recorded in a comparable context in studies of C*F*~0~, and *F*~0~ following nasals serves as a baseline condition [e.g. @hanson2009; @kirby2016; @ladd2018].
The prosodic context is typically controlled by having items produced in citation form [e.g. @kirby2020jasa; @gao2024] or embedding them in a controlled carrier phrase [e.g. @lehiste1961; @silverman1986; @hanson2009; @kirby2016; @gao2019].
@xu2021 further argue that it is important to compare equivalent time points within the syllables of interest, stressing that pitch peaks in intonation contours are not necessarily timed to the onset of voicing after a stop; if pitch peaks are e.g. timed relative to the beginning of the syllable and *F*~0~ is compared at voicing onset, it will inevitably result in an overestimation of the temporal extent of C*F*~0~ [see also @wong2007]. 
@xu2021 in fact hypothesize that pitch trajectories are *always* synchronized to syllables.

Some have suggested that *F*~0~ is *raised* following voiceless stops due to gestures that inhibit voicing, such as stiffening or vertical tensing of the vocal folds [@halle1971; @hombert1979], in particular tensing of the cricothyroid muscle [@lofqvist1989; @hoole2011], or due to abrupt activity of the vocalis muscle to initiate voicing [@hoole2006; @hoole2011].
Others have suggested that *F*~0~ is *lowered* following voiced stops due to gestures that promote closure voicing, such as larynx lowering [e.g. @ewan1974; @ewan1976] with concomitant vocal fold slackening [@ohde1984; @honda1999], or that *F*~0~ lowering in this context is an active adjustment to perceptually enhance the voicing contrast [@kingston1994; @kingston2007].
Note that these two mechanisms may not be mutually exclusive.
When comparing post-stop *F*~0~ trajectories to a suitable baseline, C*F*~0~ effects in the direction of *F*~0~ raising after voiceless stops are typically found to be much more extensive than *F*~0~ lowering [@hanson2009].
Lowering is often found only during the stop closure itself [@kirby2016], although @maspong2024 do find evidence of this effect extending into the initial parts of the vowel in Italian.^[If *F*~0~ lowering is found only during the stop closure, this should technically be considered an *intrinsic* *F*~0~ effect (I*F*~0~) rather than co-intrinsic, cf. @krug2021.]

An alternative explanation of C*F*~0~ holds that the effects are caused by intraoral air pressure differences after voiced and voiceless stops [e.g. @ladefoged1967; @ohala1973; @hombert1976]; this explanation is attractive since it in principle accounts for both *F*~0~ lowering and *F*~0~ raising, but it arguably fails to predict the scope of *F*~0~ modifications, especially that *F*~0~ raising can be quite long-lasting [see @hombert1979]. 
An aerodynamic account would also predict covariation between especially positive voice onset time (pVOT) and the extent of *F*~0~ raising, which many studies do not find evidence for [e.g. @dmitrieva2015; @kirby2016; @pinget2023], although cf. @shultz2012 and @kirby2015.

### Universality {#sec-universality}

C*F*~0~ appears to be relatively independent of how exactly a laryngeal contrast is implemented.
The overall effect -- namely that *F*~0~ is higher following 'less voiced' stops than 'more voiced' stops (in a very broad sense) -- are found in 'aspiration languages', where the main cue to the laryngeal contrast is post-aspiration in the voiceless series of stops, such as English [e.g. @house1953] and German [e.g. @kohler1982; @kirby2020icphs], and in 'true voice languages', where the main cue to the contrast is the presence of glottal pulsing during the closure in the voiced series of stops, such as Italian [@kirby2015; -@kirby2016], French [ibid., @fischerjorgensen1969], Spanish [@dmitrieva2015], and Dutch [@lofqvist1989; @pinget2023].
It is also found in languages which primarily distinguishes stops through closure duration, such as Swiss German [@ladd2018] and Salentino [@burroni2022], and in languages where both pre-voicing and aspiration ostensibly plays a role in the contrast, such as Swedish [@kirby2023icphs; although cf. @ting2023].^[Swedish is often considered to have an 'overspecified' laryngeal contrast between pre-voiced and post-aspirated stops [e.g. @helgason2008; @beckman2011], but several studies have failed to find evidence of consistent pre-voicing [@keating1983; @sundberg1999; @lundeborg2012; @kirby2023icphs].]

A complicating factor is that this relationship between 'voicelessness' and *F*~0~ is often less straightforward in languages with more complicated laryngeal contrasts in obstruents, or languages which already have lexical tone.
While post-aspiration consistently seems to raise *F*~0~ in non-tonal languages with simple two-way contrasts, it has sometimes been shown to lower *F*~0~ in languages which contrast *both* voicing and aspiration, such as Nepali and Bengali [@clements2007; @reetz2019].
In languages with lexical tone, results have been much more mixed.
In Shanghai Wu and Shuangfeng Xiang, post-aspiration generally lowers *F*~0~ [@chen2011jphon; @shi2020diss], whereas in Khmer, Thai, Vietnamese, and Taiwanese, post-aspiration generally raises *F*~0~ [@lai2009eal; @kirby2018jphon]; in all of these languages, the scope of C*F*~0~ depends greatly on tonal context, and in other languages such as Mandarin Chinese and Cantonese, even the direction of C*F*~0~ can depend on tonal context [e.g. @francis2006; @shi2020jasa; @guo2022].^[Some studies [@xu2003; @lo2022] find that aspiration consistently serves to raise *F*~0~ in Mandarin Chinese.]
Two plausible reasons for these discrepancies are that languages use different articulatory mechanisms to implement post-aspiration, and that the range of possible C*F*~0~ effects are limited when the phonological context places competing demands on the larynx, e.g. to produce a certain pitch level.
As we will see below, Danish is an intriguing case study here, as 1) the articulatory mechanisms that produce post-aspiration are quite well-described, and 2) the voice quality contrast already places certain demands on the larynx with respect to pitch level.

### Pitch synergy

Several studies have found that the scope of C*F*~0~, in terms of both magnitude and temporal extent, is larger in environments with high pitch, such as when the word in question is uttered in a focus condition [e.g. @kohler1982; @hanson2009; @kirby2016].
The results of @chen2011jphon also suggest that there is synergy between C*F*~0~ and other pitch targets in a lexical tone language, *viz.* Shanghai Chinese: co-intrinsic *F*~0~ raising is enhanced in high pitch environments, while co-intrinsic *F*~0~ lowering is enhanced in low pitch environments. 
On the basis of this, she hypothesizes C*F*~0~ effects are more prominent when there is congruency between the vocal fold stiffness required by a tonal pitch target and that required by a consonant.
These effects are both strengthened under prosodic focus, suggesting that they may be the result of gestural enhancement.

It is difficult to tease apart the effect of high pitch, stress, and focus in studies of C*F*~0~, since items of interest are typically elicited in stressed or focused contexts. 
@hanson2009 and @kirby2016 evade this problem by designing materials aimed at eliciting focused words in both high and low pitch environments.
As we will see below, (variation in) the prosodic phonology of Danish makes it an intriguing case for teasing apart how different sources of high and low pitch affect C*F*~0~.

## Previous work on Danish {#sec-review-danish}

### The laryngeal contrast in stops

Danish stops display a two-way laryngeal contrast between /b d g/ and /p t k/.
In simple onset position before a full vowel, /b d g/ are voiceless unaspirated [p t k] and /p t k/ are voiceless aspirated [pʰ tʰ kʰ] [@fischerjorgensen1954]. 
Aspiration-based stop contrasts are the norm in Germanic languages [e.g. @iverson1995], but Danish is unusual in how much closure voicing is repressed in /b d g/.
Aspiration is of course regulated with a glottal spreading gesture, but several previous studies have shown that /b d g/ are *also* produced with a glottal spreading gesture, albeit of a smaller magnitude [@fischerjorgensen1969; @frokjaerjensen1971; @fischerjorgensen1974lips; @hutters1978; -@hutters1984; -@hutters1985]. 
Electromyographic studies have shown that this gesture is likely an active adjustment, in the sense that it is accomplished through tensing of the posterior cricoarytenoid muscles [@fischerjorgensen1974lips; @hutters1985], and not simply an aerodynamic by-product of the consonant--vowel transition, as originally proposed by @frokjaerjensen1971.
This glottal opening gesture serves to counteract voicing, even in e.g. intervocalic position [@puggaardrode2022labphon].
No such gesture is found in English /b d g/ [@sawashima1970], although a similar gesture is found in Icelandic /b d g/ [@petursson1976], where it likely also serves as an active devoicing gesture.

Glottal spreading, accomplished by tensing the posterior crycoarytenoids and suppressing activity in the interarytenoids, seems to be the main driver of devoicing in the production of Danish stops. 
Another potential driver, according to @hutters1985 and following e.g. @hirose1974, is suppressed activity in the vocalis muscle, which may reduce slackness in the vocal folds and hence impede voicing. 
Danish /p t k/ in particular show an abrupt increase in vocalis activity approaching the vowel onset; recall that @hoole2006 and @chen2011jphon discuss this as a possible mechanism behind C*F*~0~.
@hutters1985 only has stable cricothyroid measurements from a single speaker, and these hint that the cricothyroid is essentially in rest position during the production of /b d g/, while activity is slightly increased in /p t k/. 
We cannot draw any strong conclusions from this, but it certainly suggests that the cricothyroid is *not* a main driver in Danish stop devoicing.
If C*F*~0~ is indeed primarily caused by cricothyroid tensing, as suggested by @lofqvist1989, then we may expect to see relatively limited effects after /p t k/ and no effects at all after /b d g/. 

### Co-intrinsic *F*~0~ in Danish

The first to touch on C*F*~0~ in Danish was Fischer-Jørgensen [-@fischerjorgensen1968; -@fischerjorgensen1969]. 
She writes that the effect is not found in Danish, but she does not actually report the results of a C*F*~0~ study.

The topic was taken up again by @jeel1975, who measured 6 speakers reading words with initial stops and other obstruents in identical carrier phrases; for four of these speakers, words with initial sonorants were also recorded.
She finds that *F*~0~ immediately at the onset of the following vowel is consistently higher after /p t k/ than /b d g/; for those 4 speakers where stops can be compared to a sonorant baseline, the results are somewhat mixed, but *F*~0~ is shown to be higher or very similar after /b d/ compared to /m n/.
In several cases, the difference between sonorants and unaspirated stops is found to be greater than the difference between unaspirated and aspirated stops.

@petersen1978aripuc measured *F*~0~ for three speakers reading nonce words of the type [CVˈCVCV] (where V is one of the three corner vowels) embedded in a carrier sentence, reusing materials from a previous study on vowel-intrinsic *F*~0~ [@petersen1978jphon].^[@petersen1978jphon quite clearly finds the 'expected' effect of higher *F*~0~ in high vowels compared to low vowels.]
Only stop-initial words were measured, and due to the nature of the nonce words, the ecological validity of this study is rather low; the study consistently finds higher *F*~0~ after /p/ compared to /b/ in the medial stressed syllable, although the magnitude of the effect is frequently quite small.
He does not find any consistent differences between /b/ and /p/ in the pretonic and posttonic unstressed syllables.
In a later study, @petersen1983 measured three speakers reading nonce words of the type [CVˈfi] in a carrier sentence.
In this study, stops are compared with sonorants and other obstruents. 
The results show that *F*~0~ is initially raised after /p t k/ compared to /b d g/, and that both series of stops show raised *F*~0~ compared to nasals; in fact, the difference between unaspirated stops and nasals is found to initially be a fair bit greater than the difference between the two stop series, but at the end of the syllable, the effect of aspiration is typically greater than the difference between unaspirated stops and nasals. 
@petersen1983 compares *F*~0~ with measurements of larynx height, showing that there is no straightforward relationship between the two. 

@goldstein1986 cite both @jeel1975 and @petersen1983 in arguing that the laryngeal contrast is phonologically specified with continuous gestural underlying representations, claiming that their framework can account well for the raised *F*~0~ of both stop series relative to nasals, and for the difference in *F*~0~ between the two stop series.
@kingston1994, on the other hand, cite both sources as evidence that Danish /b d g/ are phonologically represented with the distinctive feature [+voice], which acts as an *F*~0~ depressor. 
We believe that this is a misinterpretation of the studies, since the studies suggest that both series of stops actually raise *F*~0~ relative to a neutral baseline.

### Stød production and *F*~0~

Standard Copenhagen Danish has a distinctive voice quality typically refered to as *stød*, which is realized over entire sonorant syllable rhymes [e.g. @gronnum2007].^[This section gives an overview of existing literature on the phonetics of stød as pertains to the present study; for a recent extensive general overview, see @gronnum2023.]
Stød in Copenhagen Standard Danish is generally acknowledged to be biphasic [@smith1944], where the first phase exhibits raised *F*~0~ relative to syllables without stød [e.g. @vihman1971; @petersen1973; @pena2022], and the second phase typically exhibits a drop in *F*~0~, a drop in intensity, and creaky, irregular phonation [e.g. @fischerjorgensen1987; -@fischerjorgensen1989; @hansen2015].
While early research suggested that the first phase played little role in the perception of stød [@thorsen1974], more recent research suggests that the first phase is actually particularly crucial to perceiving the voice quality contrast [@pena2023], and that words with and without stød are distinguished fairly well based on acoustic cues 
in the first phase alone [@pena2024], particularly *F*~0~ [@siem2023diss].

Articulatory work shows that the second phase of stød is produced with laryngeal constriction [@esling2019], in particular contraction of both the ventricular folds and the anterior part of the vocal folds [@fischerjorgensen1987; -@fischerjorgensen1989], leading to a reduced contact quotient between the folds relative to words without stød [@siem2023diss]. 
The first stød phase has further been found to be accompanied by *stronger* articulation in several ways: compared to syllables without stød, oral airflow is stronger [@smith1944], subglottal air pressure is higher, and the palatal contact area is larger [@fischerjorgensen1987; -@fischerjorgensen1989].
Electromyographic investigations suggest that the second phase is initiated with brief but strong activation peaks of the vocalis and lateral cricoarytenoids some 50 ms after the vowel onset, while the first phase is initiated with a strong activation peak of the cricothyroid prior to the onset of the vowel [@faaborgandersen1957; @fischerjorgensen1974stod; @fischerjorgensen1987; -@fischerjorgensen1989]; recall that the cricothyroid is likely partially responsible for devoicing in /p t k/ but not in /b d g/.
@gronnum2007 interpret the laryngeal control mechanisms as evidence of a single ballistic laryngeal gesture timed relative to the beginning of the syllable rhyme which accounts for both phases, while @pena2022 interprets them as evidence of two gestures corresponding to the two phases, the first timed relative to the vocalic onset, and the latter timed relative to the center of the syllable rhyme.

There is substantial regional variation in how stød is realized and how it patterns phonologically in Danish [e.g. @ejskjaer1990; -@ejskjaer2006].
Most of this variation is not relevant to our purposes here, but it is worth mentioning that stød in Aarhus Danish appears to be predominantly tonal [@kyst2008]; unlike in Standard Copenhagen Danish, syllables with and without stød are poorly distinguished using acoustic measures of spectral slope and harmonics-to-noise ratio, and the contact quotient does not differ [@siem2023diss].
There is also a much lower tendency for following syllables to have creaky phonation in Aarhus Danish relative to Standard Copenhagen Danish [@siem2023icphs].
The pitch pattern in the first phase, however, appears to be essentially the same: *F*~0~ at the vocalic onset is higher in syllables with stød, and these syllables display a falling pitch pattern.
A very brief overview of relevant parts of Danish geography is given in the next section.

### Stress and pitch peak alignment {#sec-stresspitch}

While Danish has been subject to extensive dialect leveling in the past century or so [e.g. @pedersen2003], prosodic cues such as the alignment between stress and pitch are still fairly distinct between major regions of Denmark [@tondering2020].
In Standard Copenhagen Danish, stress in disyllabic words is cued with low falling pitch on the tonic syllable and high rising pitch on the post-tonic syllable [e.g. @thorsen1978; -@thorsen1979; -@thorsen1983; @dyhr1993; @petersen2001; @tondering2008].
This is quite unlike in Jutland Danish, where stress is typically cued with high rising pitch on the tonic syllable [e.g. @thorsen1981; @thorsen1982; -@thorsen1988; @gronnum1989; -@gronnum1990; @jespersen2021].

Denmark can be seen in @fig-mapDK, where the two main dialect areas under consideration in this study are colored in. 
Jutland is the peninsula in Western Denmark; note that Northern Jutland is not colored and is kept out of this study, because we have reason to believe that the laryngeal contrast in stops may be implemented differently here [see e.g. @puggaardrode2024jphon].
The colored-in island in Eastern Denmark is Zealand.^[The smaller islands south of Zealand are in some respects part of the same administative unit as Zealand, but no speakers recorded for this study come from these islands.]
Since a few of the speakers recorded for the study are from outside the greater Copenhagen area but distinctly have the stress--pitch peak alignment associated with Standard Copenhagen Danish, we conceptualize this variety instead as *Zealand Danish* here; see @sec-speakers.

::: {.content-visible when-format="html"}
::: {.callout-note collapse="true"}

## Generating maps with `eurostat` and `ggplot2`

The map in @fig-mapDK is made in R using the packages `ggplot2` and `eurostat`. `eurostat` has coordinates for the outlines of a bunch of countries and internal administrative areas at various levels of granularity. These coordinates are loaded into R using the `get_eurostat_geospatial()` function as below. 

I set `resolution = '1'` to get the highest possible resolution. `nuts_level` refers to the Eurostat NUTS level (**n**omenclature of **t**erritorial **u**nits for **s**tatistics); this determines the granularity of the regions that the maps are divided into. We use `3` here, because `2` would give us official regions of Denmark, which for various reasons isn't very useful. It'd actually be nice with an even smaller granularity, but `3` are the smallest available units.

```{r Get geospatial data}
#| code-fold: false
#| error: false
#| warning: false

library(tidyverse)
library(patchwork)
library(eurostat)

geodata <- get_eurostat_geospatial(resolution = '1', nuts_level = 3)
```

We now downloaded a huge object with small administrative units for all available countries. This can be filtered on a by-country basis by using the `CNTR_CODE` column in the `geodata` object. 

Here we grab the outlines of Denmark, and also the bordering countries Germany and Sweden.

```{r Filter geospatial data}
#| code-fold: false

geodataDK <- geodata[geodata$CNTR_CODE=='DK',]
geodataDE <- geodata[geodata$CNTR_CODE=='DE',]
geodataSE <- geodata[geodata$CNTR_CODE=='SE',]
```

Administrative areas can be filtered by using the `NUTS_NAME` column in `geodata`. The available areas in Denmark are the following:

```{r View Danish NUTS}
#| code-fold: false

unique(geodataDK$NUTS_NAME)
```
So we can use differential coloring for different areas, we further subdivide `geodataDK` into relevant parts of Jutland `jAreas`, Zealand `zAreas`, and `restofDK`. (Unfortunately the large area `Vest- og Sydsjælland` includes Lolland--Falster south of Zealand, but for this study those aren't actually conceptualized as part of Zealand).

```{r Filter Danish NUTS}
#| code-fold: false

jAreas <- c('Sydjylland', 'Vestjylland', 'Østjylland')
jutland <- geodataDK[geodataDK$NUTS_NAME %in% jAreas,]
zAreas <- c('Nordsjælland', 'Østsjælland', 'Vest- og Sydsjælland', 
            'Byen København', 'Københavns omegn')
zealand <- geodataDK[geodataDK$NUTS_NAME %in% zAreas,]
restofDK <- geodataDK[!geodataDK$NUTS_NAME %in% c(jAreas, zAreas),]
```

The figure is now a `ggplot` object which makes heavy use of the non-standard `geom_sf` class. We can use those because `geodata` and the derived objects are not traditional data frames:

```{r View geospatial class}
#| code-fold: false

class(geodata)
```

The `sf` object class (for geospatial data) makes it possible to store complex numeric vectors in something like a data frame cell, and these can then be plotted as polygons with `ggplot()` using the `geom_sf()` function. For the map, we create a blank plotting area with a light blue background (for the ocean!), color in the areas that we've filtered out above differentially, and embellish the plot using regular geographical coordinates.

```{r Generate map plot}
#| code-fold: false

mapDK <- ggplot() + 
  geom_sf(data=jutland, fill='wheat') +
  geom_sf(data=zealand, fill='thistle1') + 
  geom_sf(data=restofDK, fill='lightgrey') +
  geom_sf(data=geodataDE, fill='lightgrey') +
  geom_sf(data=geodataSE, fill='lightgrey') + 
  annotate(geom='point', x=12.3, y=55.4, size=4, col='red') +
  annotate(geom='label', x=12.3, y=55.1, label='Copenhagen\n(Zealand)') +
  annotate(geom='point', x=10.2, y=56.1, size=4, col='red') + 
  annotate(geom='label', x=10.2, y=55.8, label='Aarhus\n(Jutland)') +
  xlim(8, 13) +
  ylim(54.7, 58) + 
  theme_bw() +
  theme(panel.background=element_rect(fill='lightblue'),
        panel.border=element_blank(),
        panel.grid.major=element_blank(),
        panel.grid.minor=element_blank(),
        axis.text.y=element_blank(),
        axis.text.x=element_blank(),
        axis.title.y=element_blank(),
        axis.title.x=element_blank(),
        axis.ticks=element_blank())
```

:::
:::

```{r}
#| label: fig-mapDK
#| fig-cap: Map of Denmark showing roughly the two dialect areas considered in this study (the Jutland peninsula to the west, and the island of Zealand to the east) and highlighting the two cities where recordings took place.

mapDK
```

This particular pattern of variation gives a unique opportunity to tease apart the influences of stress and pitch on C*F*~0~. 
If the previous findings of more extensive C*F*~0~ under stress are actually due to synergistic effects of multiple sources of pitch raising, we should find stronger C*F*~0~ effects in Jutland Danish compared to Zealand Danish, at least in syllables without stød.
However, if the findings are actually due to stress and not pitch, the varieties are expected to show similar behavior.

## Research questions {#sec-rq}

*RQ*1: What will C*F*~0~ look like in a language which contrasts two series of voiceless stops?

* *H*1~a~: /b d g/ are underlyingly represented as [+voice], which acts as an *F*~0~ depressor even if the stops are phonetically voiceless, and the *F*~0~ levels following consonants is ranked /p ~ m/ > /b/. This would be evidence in favor of the proposal of @kingston1994 regarding the underlying representation of Danish stops.
* *H*1~b~: *F*~0~ is raised after /p t k/, since the production of these stops (and only these stops) involves tensing of the cricothyroid [following @hutters1984; -@hutters1985], and the *F*~0~ levels following consonants is ranked /p/ > /b ~ m/. This would be evidence in favor of the proposal of @lofqvist1989 that C*F*~0~ is a physiological side effect of inhibiting phonation specifically through cricothyroid tensing.
* *H*1~c~: *F*~0~ is raised after both stop series, which would be evidence in favor of the proposal of e.g. @goldstein1986 that C*F*~0~ effects are a general physiological side effect of laryngeal gestures that inhibit phonation. The *F*~0~ levels following consonants would then be ranked either /p ~ b/ > /m/ or /p/ > /b/ > /m/, depending on whether the magnitude of the gestures in question is expected to have an observable influence on C*F*~0~. The /p/ > /b/ ordering is not explicitly predicted by @goldstein1986, but arguably follows naturally from their account.

*RQ*2: How do stress and high pitch respectively affect C*F*~0~?^[Note that these hypotheses assume that there is no lowering effect of stops with a proposed [+voice] specification in Danish, i.e. that *H*1~a~ is false; the previous research generally leads us to expect this.]

* *H*2~a~: C*F*~0~ is generally stronger in speakers from Jutland than speakers from Zealand. This would suggest that stress in itself does not affect C*F*~0~, but high pitch *does*, since stress is not cued with high pitch on the tonic syllable in Zealand Danish.
* *H*2~b~: C*F*~0~ is enhanced in global high pitch environments in speakers from both Jutland and Zealand. This would suggest that the global pitch environment affects C*F*~0~, but stress in itself does not.
* *H*2~c~: Both varieties have similar C*F*~0~ effects, and C*F*~0~ is not affected by the global pitch environment in either variety. This would suggest that there is no synergy.

*RQ*3: Do lexical demands on pitch level (specifically the stød contrast) affect C*F*~0~?

* *H*3~a~: C*F*~0~ is stronger in syllables with stød, i.e. C*F*~0~ strengthens when pitch is high, regardless of the source of high pitch.
* *H*3~b~: C*F*~0~ is stronger in syllables without stød, since the lack of competing demands on the vocal folds allows for more modulation of *F*~0~.
* *H*3~c~: C*F*~0~ is not affected by the stød contrast either way.

# Methods and materials {#sec-methods}

## Speech materials

We constructed 132 alternative question sentences of the form *Er det **dine** eller er det **mine**?* 'Are they **yours** or are they **mine**?'. 
Following @kirby2016, this sentence structure was intended to prompt a high pitch reading of the first alternative (in this case *dine*) and a low pitch reading of the second alternative (in this case *mine*).
All items of interest occur in both high and low position.
The items of interest were crossed to contain all possible combinations of the following variable levels in the stressed syllable:

* [onset category]{.smallcaps}: *nasal*, *unaspirated*, *aspirated*
* [place of articulation]{.smallcaps}: *bilabial*, *alveolar*
* [vowel height]{.smallcaps}: *high*, *low*
* [stød]{.smallcaps}: *present*, *absent*

The test items all have phonologically long vowels in the stressed syllable.^[Some speakers have short vowels in the possessive pronouns *dine* 'yours' and *mine* 'mine'; this is apparently due to a relatively recent change in Zealand Danish [@schachtenhaufen2024].]
Most items were disyllabic with stress on the first syllable; a few were trisyllabic, with stress either on either the second or the first syllable.

Alternative question sentences were constructed around the test words.
Most items contained only one item of interest, in order to ensure that the sentence sounded relatively pragmatically natural, but when feasible, sentences contained two items of interest.

::: {.content-visible when-format="html"}
::: {.callout-note collapse="true"}
## A closer look at the speech materials

The prompts are stored in a comma-separated file. I'll load them in as `master` here:

```{r Load master doc}
#| code-fold: false

master <- read.csv('data/master.csv')
```

This file serves as a look-up table for later data analysis. It has the following columns:

* `filename` gives the file name associated with each sentence
* `sentence` gives the sentence orthographically
* `foc.item` gives the focused word orthographically
* `foc.moa` gives the manner or laryngeal category of the initial consonant of the focused word, either `unasp`, `asp`, or `nasal`
* `foc.poa` gives the place of articulation of the initial consonant of the focused word, either `alv` or `bilab`
* `foc.vheight` gives the height of the stressed vowel of the focused word, either `high` or `low`
* `foc.creak` gives the voice quality of the focused word, either `st` (stød) or `nst` (non-stød)
* Finally, there are five columns starting with `nfoc` which give the same values for the word not in focus

All values of the `foc` columns are `NA` if the focused word is not being analyzed, and same for the `nfoc` columns. 
The data frame has 137 columns because the first 5 sentences are used to accommodate the speakers to the experimental setup, and are not analyzed. The file names of these are `training1`, `training2`, etc.

You can have a look the data frame here:

```{r View master doc}
#| code-fold: false

master %>% DT::datatable()
```

:::
:::

## Participants {#sec-speakers}

31 speakers of Danish were recorded for the study.
Participants were either undergraduate students at the University of Copenhagen, or recruited in Aarhus from the extended network of the first author.
Participants self-reported their variety of Danish, year of birth, and gender.
We explicitly looked for speakers from either Zealand or Jutland, excluding speakers from Northern Jutland (see @sec-stresspitch).
In order to test *RQ*2, speakers were subsequently categorized as speakers of either *Jutland Danish* (*n* = 17) or *Zealand Danish* (*n* = 12); two speakers were excluded from the analysis, as they were late bilinguals with a different first language.
The Jutland Danish speakers were predominantly from Eastern Jutland near Aarhus (see @fig-mapDK), but a few came from Central Jutland and Southern Jutland. 
The Zealand Danish speakers were predominantly from the greater Copenhagen area, although a few came from other places in Zealand.
Two participants reported having a bidialectal upbringing; since variation in stress--pitch peak alignment was our reason for this categorization, and both speakers could straightforwardly be assigned to one of these two categories, we include these speakers in the final results.
Participants were between 19--34 years old at the time of recording. 
19 participants were female, 9 were male, and one was non-binary.

## Recording procedure

Recordings were made in sound-attenuated booths at the University of Copenhagen or Aarhus University.
Participants provided demographic information as outlined in the previous section, and signed informed consent forms.
The recordings made in Copenhagen were self-supervised after instructions by the third author as part of a course in acoustic phonetics; the recordings made in Aarhus were supervised by the first author.
Speakers were seated in front of an omnidirectional microphone (AKG P420 through a Zoom H5 in Aarhus; Sennheiser MKH40 in Copenhagen).
Sentence prompts appeared on a computer screen, and speakers were instructed to read as colloquially as possible, and at a natural pace.
The first 5 sentences were trial items not used in the analysis, in order to allow speakers to accomodate to the recording device.
Sentences were pseudo-randomized, and there was a break in the middle of the recording session.
Recordings were made direct to disk at a 44.1 kHz sampling rate using SpeechRecorder, version 6.8.5 [@speechrecorder].

## Pre-processing and annotation

Pre-processing, acoustic analysis, and statistical analysis was predominantly done in R [@r].
For each speaker, all recordings were concatenated to a single sound file using the `tuneR` library [@tuneR], and sentence-level orthographic annotations were automatically generated in the Praat TextGrid format [@boersma2001] using the `rPraat` library [@rPraat]. 
Recordings were then force-aligned using the DanFA module of the Autophon tool [@young2023; @danfa; @autophon], which implements the Montreal Forced Aligner [@mfa] with a series of pre- and post-processing steps. 
The force-aligned annotations were split to match the original audio files, and the resulting pairs of audio and annotation files were then converted to an EMU-SDMS database. Subsequent work with the files was done using the `emuR` interface [@emusdms]. 

::: {.content-visible when-format="html"}
::: {.callout-note collapse="true"}
## Preparing files for forced alignment and creating EMU-SDMS database

For each speaker, concatenated sound files and sentence-level annotations are created using the following custom function `make_master_wav_tg()` which takes a single argument, `sp`, which is the identifier for the speaker. 

The function matches the name of each audio file with the `filename` column in the `master` data frame we saw earlier, and grabs the corresponding orthography of the sentence. 

Sound files are read in using the `readWave()` function from the `tuneR` library and converted to mono using the `mono()` function, and the signals are concatenated using the `bind()` function. These resulting `Wave` objects are of the S4 class, so contents are accessed with the `@` operator. The signal of a mono audio file is stored in `@left`, where each sample is an integer between -32,767 and 32,767, corresponding to the 16 bit depth resolution of 65,536 possible amplitude values. For whatever reason, the above operation sometimes results in values above 32,767, which we just convert to 32,767 to ensure that `tuneR` is happy. The sound file is then saved using the `writeWave()` function.

As part of this loop, we also grab the durations of the sound files (by comparing the number of samples with the sampling rate stored in `@samp.rate` of the `Wave` objects) and store them in the vectors `t1` and `t2`. We create a TextGrid object from scratch using the `tg.createNewTextGrid()` function from the `rPraat` library. We add a tier with the `tg.insertNewIntervalTier()` function, and add intervals with the orthography for each sentence to the times in `t1` and `t2` using the `tg.addInterval()` function. We save this as a proper TextGrid with the `tg.write()` function. Here it's important to remember to set `format='text'`; the default format `'short'` can create a bunch of issues.

(This code isn't actually being run as part of knitting this document, this is just to show what the procedure looks like.)

```{r Function to concatenate sound and autogenerate TextGrid}
#| code-fold: false
#| message: false
#| warning: false

library(tuneR)
library(rPraat)
library(emuR)

make_master_wav_tg <- function(sp) {
  data_loc <- paste0('../data/', sp, '/')
  wavs <- list.files(data_loc, pattern='*.wav')

  base_fn <- wavs[1] %>% str_sub(start=5, end=-5)
  snd <- readWave(paste0(data_loc, wavs[1])) %>% mono
  dur <- length(snd@left)/snd@samp.rate
  t1 <- 0
  t2 <- dur
  ort <- master$sentence[which(master$filename==base_fn)]

  for (w in 2:length(wavs)) {
    base_fn <- wavs[w] %>% str_sub(start=5, end=-5)
    tmp <- readWave(paste0(data_loc, wavs[w])) %>% mono
    dur <- length(tmp@left)/tmp@samp.rate
    t1 <- c(t1, tail(t2, n=1))
    t2 <- c(t2, tail(t1, n=1)+dur)
    ort <- c(ort, master$sentence[which(master$filename==base_fn)])
    snd <- tuneR::bind(snd, tmp)
  }

  clip <- which(snd@left > 32767)
  snd@left[clip] <- 32767

  tg <- tg.createNewTextGrid(tMin=0, tMax=(length(snd@left)/snd@samp.rate)+1)
  tg <- tg.insertNewIntervalTier(tg, newTierName='ort')
  for (l in 1:length(ort)) {
    tg <- tg.insertInterval(tg, 'ort', tStart=t1[l], tEnd=t2[l], label=ort[l])
  }

  writeWave(snd, paste0(sp, 'concat.wav'))
  tg.write(tg, paste0(sp, 'concat.TextGrid'), format='text')
}
```

We then loop through all speakers and run this function like so:

```{r Loop through speakers prior to forced alignment}
#| code-fold: false
#| eval: false

d <- list.dirs('../data') %>% str_replace_all('../data/', '')
for (sp in d) make_master_wav_tg(sp)
```

Once the files are all force-aligned, we use the custom function `split_tg_wav()` to split the resulting TextGrids into separate files for each original sound file. This is again done with reference to the `master` data frame, although the output file of the forced aligner has removed all capitalization and punctuation, so this requires some string manipulation. We read in the final TextGrid using the `tg.read()`, and cut it up using the `tg.cut0()` function. 

(The reason for this circus of concatenating and splitting files is that the Autophon forced aligner -- at least when we force-aligned these files -- required files to be uploaded individually, which would have been a gargantuan task for the thousands of short sound files we have here, while the EMU-SDMS works best with short files.)

```{r Function to split concatenated TextGrid}
#| code-fold: false

split_tg_wav <- function(sp) {
  sp_dir <- paste0('tg_proc/', sp)
  dir.create(sp_dir)
  tg <- tg.read(paste0('../data/', sp, '.TextGrid'))
  len <- length(tg$trans$t1)
  t1 <- tg$trans$t1[-len]
  t2 <- tg$trans$t2[-len]
  sentences <- str_replace_all(master$sentence, '[?]', '') %>% tolower
  labs <- str_replace_all(tg$trans$label, '[?]', '')
  for (i in 1:(len-1)) {
    tg_sub <- tg.cut0(tg, t1[i], t2[i])
    id <- which(sentences==labs[i])
    base_fn <- master$filename[id]
    fn_tg <- paste0(sp, base_fn, '.TextGrid')
    tg.write(tg_sub, paste0(sp_dir, '/', fn_tg), 'text')
  }
}
```

And again, we repeat this step for each speaker. 

```{r Loop through speakers after forced alignment}
#| code-fold: false
#| eval: false

for (sp in d) split_tg_wav(sp)
```

We're now ready to convert the sounds to an EMU database, which we do with the `convert_TextGridCollection()` function from the `emuR` library.

```{r Make EMU database}
#| code-fold: false
#| eval: false

convert_TextGridCollection(dir='tg_proc', dbName='cf0dan',
                           targetDir='.')
```

You can now load the database with the `load_emuDB()` function. and have a look at it in a browser window using the `serve()` function:

```{r Load EMU database}
#| code-fold: false

db <- load_emuDB('../final_emuDB', verbose = FALSE)
```

You can have a look at the data base in a browser window using the `serve()` function:

```{r Serve EMU database}
#| code-fold: false
#| eval: false

serve(db, useViewer=FALSE)
```


A major advantage of using the EMU-SDMS is that annotations can be hierarchical. In Praat, the different TextGrid tiers are totally unaware of each other's existence, but in EMU, annotation levels can be linked, which makes it easy to fx find all [k]s occuring in the word *can't*. 

We add the first hierarchical layer to our annotations by creating a so-called 'one-to-many' connection between the `word` and `phone` annotation levels using the `add_linkDefinition()` function, and then we automatically create links between words and phones using the `autobuild_linkFromTimes()` function. 

```{r Add word-phone links to EMU annotations}
#| code-fold: false
#| eval: false

add_linkDefinition(db, type='ONE_TO_MANY', 
                   superlevelName='word', sublevelName='phone')
autobuild_linkFromTimes(db, superlevelName='word',
                        sublevelName='phone', convertSuperlevel=TRUE)
```

For more information on `emuR`, see [this in-progress tutorial](https://rpuggaard.github.io/emuintro){target='_blank'}.

:::
:::

In order to more precisely delimit the locations of stops, we used the `getVOT` library [@getVOT] to annotate landmarks associated with pVOT.
Prior to this, a bandpass filter was applied with cut-off frequencies of 50 Hz (abrupt) and 10,000 Hz (with a 100 Hz smooth Gaussian filter) using the `soundgen` library to eliminate an occasional low-frequency rumble and speed up the process.
`getVOT` is a simple utility that automatically searches for those landmarks in the speech signal that are typically manually annotated from inspecting the waveform: a sudden amplitude peak after a period of silence corresponding to the beginning of the release, and the onset of periodicity (operationalized here as increased autocorrelation of the signal) corresponding to the onset of voicing. 
There are multiple parameters that can be toggled to improve results, but `getVOT` has a function for automatically estimating optimal parameters from a few (typically less than 10) representative hand-annotated tokens.
`getVOT` may not be as precise as more sophisticated tools such as AutoVOT [@sonderegger2012] or Dr.VOT [@shrem2019], but it has the advantage of being very easy to set up and run, and of interacting directly with EMU-SDMS, which arguably makes it more suitable for medium-size datasets.

::: {.content-visible when-format="html"}
::: {.callout-note collapse="true"}
## Predicting voice onset time landmarks

We use the `getVOT` library to automatically predict voice onset time related landmarks. `getVOT` is available from GitHub, and can be installed using the `install_github()` function from the `devtools` library:

```{r Install getVOT}
#| code-fold: false
#| eval: false

library(devtools)
install_github('rpuggaardrode/getVOT')
```

`getVOT` in its current stage is quite sensitive to a low frequency rumble, so before using it we bandpass filter the files using the `bandpass()` function from the `soundgen` library in a loop. `bandpass` takes the arguments `lwr` and `upr` for the frequency ranges to pass to keep, and the `bw` argument that specifies the bandwidth of a Gaussian filter. This can be a vector, if different bandwidths should be used for the lower and upper ranges. By passing the vector `c(0,100)` we specify an abrupt cut-off at the lower range, but a `100` smooth filter at the upper range. This is done in a custom function `clean_audio()`, which also rounds the resulting signal vector to integers and rescales and normalizes the values to match the 16-bit depth using the `normalize()` function in `tuneR`. Files are then overwritten.

We do this by setting the working directory to the location of our EMU database, and then running the following code:

```{r Clean audio}
#| code-fold: false
#| eval: false

library(soundgen)

wavs <- list.files(pattern='*.wav', recursive=TRUE)

clean_audio <- function(file) {
  snd <- readWave(file)
  filt <- bandpass(snd, lwr=50, upr=10000, bw=c(0,100))
  snd@left <- round(filt, 0)
  snd <- snd %>% normalize(unit='16')
  writeWave(snd, file, extensible=FALSE)
}

for (w in wavs) clean_audio(w)
```

In order to predict voice onset time landmarks, we first need a list of words of interest to make sure that landmarks aren't predicted for *all* stops in the data. We take these from the `master` data frame, ignoring the nasal-initial stops and doing a bit of data wrangling to make sure that the strings exactly match the file names (which are not fully orthographic to avoid the Danish-specific letters *æ, ø, å*).

```{r Format stop items data frame}
#| code-fold: false

stop_items <- master %>%
  filter(foc.moa %in% c('asp', 'unasp')) %>%
  pull(foc.item) %>%
  data.frame(ort = .) %>%
  mutate(fn = str_replace_all(ort, c('æ' = 'E', 'ø' = 'OE', 'å' = 'O')),
         ort = tolower(ort))
```

We can now use the `query()` function in `emuR()` to find all matches for these words in our database. `getVOT` will later search for VOT landmarks only in these intervals.

```{r Query items for VOT landmark generation}
#| code-fold: false

sl <- query(db, paste0('word == ', paste(stop_items$ort, collapse='|')),
            timeRefSegmentLevel = 'phone')
sl %>% head(n=5)
```

In order to get a reasonable performance from `getVOT`, we've hand annotated the release and voicing onset of eight stop tokens. We can use that to estimate the best performing set of `getVOT` parameters, using the `pos_setParams()` function (`pos` because it's positive voice onset time). The hand-labeled tokens are in the `getVOT_training` directory. This function will spit out some text indicating its progress and indicating how closely the predicted VOT landmarks with the selected parameters match the hand-annotations. It will also spit out a plot comparing the the predictions with optimal parameters (red lines) to the hand-annotations (blue lines); if only blue lines are visible, it's because the predictions are very close to exactly matching the hand-annotations. Here we set the argument `cat=TRUE`, so that a picture of a cat is plotted along with the results. If you're a cat-hating monster you can use `cat=FALSE` instead. 

```{r Find parameters for VOT landmark estimation}
#| code-fold: false

library(getVOT)

params <- pos_setParams('data/getVOT_training', cat=TRUE)
```

The resulting object is a list that looks like this: 

```{r View parameters for VOT landmark estimation}
#| code-fold: false

params
```

For more information about what all this means, see [this extended overview](https://lingmethodshub.github.io/content/R/getVOT-tutorial/){target='_blank'}.


We can estimate VOT landmarks for our selected words and add them directly to the EMU database as a new annotation level using the function `addVOT2emuDB()`. We pass the `params` object to the `pos_params_list` argument.

```{r Estimate VOT landmarks and add them to EMU database}
#| code-fold: false
#| eval: false

addVOT2emuDB(db, sl, level='word', sign='positive', pos_params_list=params)
```

:::
:::

Finally, all relevant boundaries -- i.e., the beginning of the closure, the end of the closure, the end of the word, and onset of voicing after /b d p t/ -- were manually checked and adjusted when necessary, based primarily on visual inspection of the waveform.

::: {.content-visible when-format="html"}
::: {.callout-note collapse="true"}
## Creating annotation level with stop landmarks

After we've manually checked all annotations, we want to have a new convenient annotation level that has the same landmarks for all stop consonants, including the nasals. We'll add this new annotation level, called `landmarks` using the `add_levelDefinition()` function. The `type='EVENT'` specification is equivalent to creating a *point tier* in Praat. 

```{r Make new annotation level}
#| code-fold: false
#| eval: false

add_levelDefinition(db, 'landmarks', type='EVENT')
```

Here, we want to add specific points in time for the *closure*, *release*, *voicing onset* (not relevant for nasals), and *word offset*. It is a bit of a hassle to automatically create annotations in EMU, but there is a function `create_itemsInLevel()` that does it. This function requires a data frame of a specific format though. The custom function `populate_landmarks()` will take care of this formatting:

```{r Function to populate new annotation level}
#| code-fold: false

populate_landmarks <- function(seg_list, start, lab) {
  itc <- data.frame(session = seg_list[['session']],
                    bundle = seg_list[['bundle']],
                    level = rep('landmarks', nrow(seg_list)),
                    start = seg_list[[start]] / 
                      seg_list[1,'sample_rate'] * 1000,
                    labels = rep(lab, nrow(seg_list)),
                    db_uuid = db$UUID)
  return(itc)
}
```

`populate_landmarks()` takes as arguments a segment list created with the `query()` function, a column with start times from that segment list, and labels to repeat for that segment list. 

To get the times for the beginning of the closure and the word offset for oral stops, we can use the segment list `sl` that we already created above:

```{r Populate new annotation level with closure and offset}
#| code-fold: false

clo <- populate_landmarks(sl, 'sample_start', 'clo')
offset <- populate_landmarks(sl, 'sample_end', 'offset')
```

To get the times for release and voicing onset, we `query()` the annotation level `vot`.

```{r Populate new annotation level with release and voice onset}
#| code-fold: false

sl_vot <- query(db, 'vot == vot')

rel <- populate_landmarks(sl_vot, 'sample_start', 'rel')
vo <- populate_landmarks(sl_vot, 'sample_end', 'vo')
```

To get similar information about nasals, we need to create a segment list with only the nasals. We do this in the same way as we previously did with stops when making the `sl` list.

```{r Format nasal items data frame}
#| code-fold: false

nas_items <- master %>%
  filter(foc.moa == 'nasal') %>%
  pull(foc.item) %>%
  data.frame(ort = .) %>%
  mutate(fn = str_replace_all(ort, c('æ' = 'E', 'ø' = 'OE', 'å' = 'O')),
         ort = tolower(ort))
nas_ort <- paste(nas_items$ort, collapse='|')

sl_nas <- query(db, paste0('word == ', nas_ort), 
                timeRefSegmentLevel='phone') %>%
  distinct(.keep_all=TRUE)
```

Using this information, we can get all the word offset times:

```{r Populate new annotation level with nasal items offsets}
#| code-fold: false

offset_nas <- populate_landmarks(sl_nas, 'sample_end', 'offset')
```

We don't have the nasal *segment* information we need yet. To get that, we need some more complex queries (more on that [here](https://rpuggaardrode.github.io/emuintro/query.html){target='_blank'}).

```{r Populate new annotation level with other landmarks for nasals}
#| code-fold: false

q1 <- paste0('[#phone == m|n & Start(word,phone) == TRUE ^ word == ', 
             nas_ort, ']')
q2 <- '[#phone == n & End(word,phone) == FALSE ^ word == fornyet|forneden]'
sl_nasSeg <- rbind(
  query(db, q1),
  query(db, q2)
)

clo_nas <- populate_landmarks(sl_nasSeg, 'sample_start', 'clo')
rel_nas <- populate_landmarks(sl_nasSeg, 'sample_end', 'clo')
```

We can now combine all of the data frames we just made, and pass them on to the `create_itemsInLevel()` function:

```{r Populate landmarks annotation level}
#| code-fold: false
#| eval: false

itc <- rbind(clo, rel, vo, offset, clo_nas, rel_nas, offset_nas)
create_itemsInLevel(db, itc)
```

:::
:::

## Acoustic analysis

Durational measures, such as closure duration and pVOT, are straightforwardly extracted from the annotations described above.

In order to only include pitch measures that we were reasonably certain about, we calculated pitch using a cross-validation method with two distinct pitch tracking algorithms, *viz.* Praat and REAPER. 
Pitch was calculated using Boersma's [-@boersma1993] autocorrelation algorithm in Praat, using the `emuhelpeR` library [@emuhelpeR] to access the PraatSauce scripts [@praatsauce] and import the results into EMU-SDMS.
Additionally, pitch was calculated using Talkin's [-@reaper] REAPER (robust epoch and pitch estimator) algorithm, which first estimates the candidates for the locations of glottal closure instances, and then defines pitch as the distance between "winning candidates" (determined through a dynamic programming procedure). 
REAPER has been shown to perform particularly well for pathological and creaky speech [@vaysse2022; @white2022], which is highly relevant here since we measure syllables with stød.
A set of custom functions in R were used to call the REAPER utility and import the results into EMU-SDMS.

With both Praat and REAPER, we used the two-pass pitch estimation procedure proposed by @hirst2007 to dynamically estimate suitable pitch floor and ceiling values. This involves first running the algorithms with very liberal pitch floor and ceiling values of 60 Hz and 700 Hz respectively [following recommendations by @hirst2022]. 
For each speaker, quartiles $Q_n$ are calculated from all resulting pitch values, and the algorithms are rerun where the pitch floor is set to $\frac{3}{4}Q_1$ and the pitch ceiling is set to $1\frac{1}{2}Q_3$. 
This method reduces pitch tracking errors close to the edges of a speaker's register [@deloozeDiss].
Any *F*~0~ measures that fall outside of three standard deviations of a speaker's mean is treated as a missing value.

::: {.content-visible when-format="html"}
::: {.callout-note collapse="true"}
## Extracting pitch with Praat

Praat's pitch tracking algorithm is used via the `emuhelpeR` library, available from GitHub.

```{r Install emuhelpeR}
#| code-fold: false
#| eval: false

install_github('rpuggaardrode/emuhelpeR')
library(emuhelpeR)
```

We set the directory with folders of raw data as the working directory, and then call the function `run_ps_dynamic_minmax()`, which will calculate pitch twice for each speaker, once to get range estimates for setting the pitch floor and ceiling, and once with suitable floor and ceiling.

```{r Run PraatSauce with dynamic floor and ceiling}
#| code-fold: false
#| eval: false

ps_out <- run_ps_dynamic_minmax(getwd(), 
                                formantMeasures = FALSE, 
                                spectralMeasures = FALSE)
```

A bit of wrangling to get the format of the resulting data frame just right:

```{r Format PraatSauce results}
#| code-fold: false
#| eval: false

ps_out <- ps_out %>% mutate(
  session = str_sub(Filename, end=3)
) %>% relocate(session, .after=Label) %>%
  mutate(seg_Start = as.numeric(seg_Start),
         session = paste0('_', session))
```

And then we incorporate the values into the EMU database using the `praatsauce2ssff()` function:

```{r Add PraatSauce results to EMU database}
#| code-fold: false
#| eval: false

ps_out %>% praatsauce2ssff(db, 'session')
```

:::
:::

::: {.content-visible when-format="html"}
::: {.callout-note collapse="true"}
## Extracting pitch with REAPER

I have bundled up some functions for working with REAPER in R as the library `reapeR`. It has so far only been tested on Windows, so I can't make promises about how well it'll function with other operating systems.

The library can be installed from GitHub like so:

```{r Install reapeR}
#| code-fold: false
#| eval: false

devtools::install_github('rpuggaardrode/reapeR')
```

If you just installed this, it's recommended that you restart your R session before loading it.

This library has the function `reaper_bulk()` which has all the functionality we need built in: it'll interface directly with a loaded EMU database, and it the two-pass pitch floor and ceiling estimation is automated. We run it like this:

```{r Run REAPER with dynamic floor and ceiling}
#| code-fold: false
#| eval: false

library(reapeR)
reaper_out <- reaper_bulk(db, output = 'pitch', hirst2pass = TRUE)
```

We can add the resulting measurements to our EMU database with the function `reaper2ssff()`:

```{r Add REAPER results to EMU database}
#| code-fold: false
#| eval: false

reaper2ssff(reaper_out, db)
```

:::
:::

To cross-validate the resulting pitch measures, we analyze only measurements from frames where both trackers successfully estimated pitch, and where the estimates are no further than 20% apart.
For the remaining frames, we analyze the arithmetic mean of the two pitch estimates.
Prior to analysis, the Hz values of trajectories to be analyzed are converted to by-speaker *z*-scores, and in order to filter out octave jumps, trajectories were removed if they included changes of ±1.5 *z* between any adjacent measures.

::: {.content-visible when-format="html"}
::: {.callout-note collapse="true"}

## Preparing data for analysis -- first attempt!

To grab pitch measures for exactly those sequences that we're interested in, we create a *segment list* using the `query()` function in `emuR`. We do this multiple times to get all of the time information that we're interested in in a single data frame. When querying an `EVENT` level (similar to a point tier in Praat), the time information of the resulting object is stored in the `start` column (in ms) or the `sample_start` column (in raw samples).

```{r Query landmarks except voice onset}
#| code-fold: false

sl <- query(db, 'landmarks == clo')
sl$end <- query(db, 'landmarks == offset')$start
sl$sample_end <- query(db, 'landmarks == offset')$sample_start
sl$rel <- query(db, 'landmarks == rel')$start
```

Next, we do some wrangling to convert the information in the bundle name of each observation into separate named columns, which will tell us for each segment which word it is part of, the voicing status (nasal, unaspirated, or aspirated), the place of articulation, the vowel height, and whether or not the word has stød. Since some sentences have both items of interest in focus condition and non-focus condition, this adds up to ten columns. In a separate wrangling step (a not-very-pretty for-loop), we determine whether the item in a row is in focus or not in focus and save that information in a new column `ord` (for *order*). Subsequently, we use this information to create a column `cond` with information about the focus condition, and convert the other ten columns into five with only the relevant information.

```{r Wrangle segment list}
#| code-fold: false

sl <- sl %>%
  mutate(bndl_info = str_sub(bundle, start=4)) %>%
  separate(bndl_info, into=c(
    'foc_item', 'foc_voi', 'foc_poa', 'foc_vheight', 'foc_st',
    'nfoc_item', 'nfoc_voi', 'nfoc_poa', 'nfoc_vheight', 'nfoc_st'))

sl$ord <- rep(NA, nrow(sl))
for (i in 2:nrow(sl)) {
  bndl <- sl$bundle[i]
  n_item <- nrow(filter(sl, bundle==bndl))
  if (n_item > 1) {
    if (sl$bundle[i-1] == sl$bundle[i]) {
      sl$ord[i] <- 2
    } else {
      sl$ord[i] <- 1
    }
  }
}

sl <- sl %>%
  mutate(cond = case_when(
    foc_item == 'NA' ~ 'nfoc',
    nfoc_item == 'NA' ~ 'foc',
    ord == 1 ~ 'foc',
    ord == 2 ~ 'nfoc'),
    item = case_when(
      foc_item == 'NA' ~ nfoc_item,
      nfoc_item == 'NA' ~ foc_item,
      ord == 1 ~ foc_item,
      ord == 2 ~ nfoc_item),
    voi = case_when(
      foc_item == 'NA' ~ nfoc_voi,
      nfoc_item == 'NA' ~ foc_voi,
      ord == 1 ~ foc_voi,
      ord == 2 ~ nfoc_voi),
    poa = case_when(
      foc_item == 'NA' ~ nfoc_poa,
      nfoc_item == 'NA' ~ foc_poa,
      ord == 1 ~ foc_poa,
      ord == 2 ~ nfoc_poa),
    vheight = case_when(
      foc_item == 'NA' ~ nfoc_vheight,
      nfoc_item == 'NA' ~ foc_vheight,
      ord == 1 ~ foc_vheight,
      ord == 2 ~ nfoc_vheight),
    st = case_when(
      foc_item == 'NA' ~ nfoc_st,
      nfoc_item == 'NA' ~ foc_st,
      ord == 1 ~ foc_st,
      ord == 2 ~ nfoc_st)
  ) %>%
  select(-c(nfoc_item, foc_item, nfoc_voi, foc_voi, nfoc_poa, foc_poa,
            nfoc_vheight, foc_vheight, nfoc_st, foc_st, ord))
```

We still need to integrate information about voice onset for the stop items (we set it to zero for nasal items), which we do by splitting our `df` data frame in two and recombining them. Finally we add columns with the vowel duration `vdur`, open phase duration `opdur`, voice onset time `vot`, and closure duration `cldur`.

```{r Create final segment list with temporal measures}
#| code-fold: false

sl_vo <- query(db, 'landmarks == vo')

sl_nas <- sl %>% filter(voi == 'nasal') %>%
  mutate(vo = 0)
sl_stop <- sl %>% filter(voi != 'nasal') %>%
  mutate(vo = sl_vo$start)
sl <- rbind(sl_nas, sl_stop)

sl <- sl %>% mutate(
  vdur = ifelse(voi == 'nasal', end - rel, end - vo),
  opdur = end - rel,
  vot = ifelse(voi == 'nasal', NA, vo - rel),
  cldur = rel - start,
  syldur = end - start
)
```

And as a final step, we integrate metadata about speakers from the CSV file `meta`.

```{r Add speaker metadata}
#| code-fold: false

meta <- read.delim('data/meta.csv', sep=';')
sl <- left_join(sl, meta, by = 'session')
```

We can now use the function `get_trackdata()` to grab pitch measurements from just those sequences we're interested in. We also suitably convert `0` values from Praat to `NA`, and `-1` values from REAPER to `NA`. We save both of these in a data frame `td`.

```{r Import pitch measures}
#| code-fold: false

td_praat <- get_trackdata(db, sl, ssffTrackName='f0', verbose = FALSE)
td_praat[which(td_praat$T1 == 0),'T1'] <- NA

td_reaper <- get_trackdata(db, sl, ssffTrackName='rf0', verbose = FALSE)
td_reaper[which(td_reaper$T1 == -1),'T1'] <- NA

td <- td_praat %>% rename(praat_f0 = T1)
td$reaper_f0 <- td_reaper$T1
```

Next, we create a new column in `td`, `f0`, which contains the average of the two pitch trackers, and converts values to `NA` if they occur prior to the onset of voicing, if *any* of the pitch trackers has failed, if they differ by more than 20%, and if they differ by more than three standard deviations from the speaker's mean. Finally, we create the column `zf0` with by-speaker *z*-scored *F*~0~ values.

```{r Prepare pitch measures for analysis}
#| code-fold: false

td <- td %>% mutate(
  low_est = ifelse(reaper_f0 < praat_f0, reaper_f0, praat_f0),
  f0_diff = (reaper_f0-praat_f0)/low_est,
  f0 = case_when(
    is.na(f0_diff) ~ NA,
    abs(f0_diff) > 0.2 ~ NA,
    times_orig < vo ~ NA,
    TRUE ~ (praat_f0+reaper_f0)/2
  )) %>% group_by(session) %>%
  mutate(uppF0 = mean(f0, na.rm=T) + 3*sd(f0, na.rm=T),
         lowF0 = mean(f0, na.rm=T) - 3*sd(f0, na.rm=T),
         f0 = ifelse(f0 > uppF0 | f0 < lowF0, NA, f0)) %>%
  mutate(zf0 = as.numeric(scale(f0))) %>%
  ungroup()
```

The data is now ready for analysis! -- or is it? See below!

:::
:::

In total, 4,168 pitch trajectories were analyzed, yielding a total of 280,767 pitch frames, of which 44,879 contain missing values.

## Determining the domain of analysis {#sec-methods-domain}

Recall from @sec-cf0overview that @xu2021 have proposed that pitch trajectories are always synchronized to full syllables, and as a result, studies of C*F*~0~ should compare trajectories starting at the syllable onset and *not* at the onset of voicing to avoid overestimating C*F*~0~ effects.^[As discussed above, this study operationalizes the onset of voicing as the onset of periodicity in the waveform following the stop release. This does not necessarily correspond to the beginning of the vowel, which @fischerjorgensen1981aripuc have argued comes later, particularly after aspirated stops.]
In order to evaluate whether the syllabic or the onset of voicing is the optimal starting point for comparing pitch trajectories in the present study, we carried out some exploratory analyses.

::: {.content-visible when-format="html"}
::: {.callout-note collapse="true"}

## Trajectory duration differences depending on landmark

Here we tabulate the trajectory mean durations depending on whether the syllabic onset or the onset of voicing is taken as the starting point:

```{r Table of mean duration differences}
#| code-fold: false

sl %>% group_by(voi) %>% summarize('Onset of voicing' = mean(vdur)) %>%
  rename('Onset category' = voi) -> voMeans
sl %>% group_by(voi) %>% summarize('Syllabic onset' = mean(syldur)) %>% 
  rename('Onset category' = voi) -> sylMeans
left_join(sylMeans, voMeans, by='Onset category')
```

:::
:::

First, we checked whether the total durations of our words our words -- i.e., the duration of trajectories beginning at the syllabic onsets -- are roughly comparable across our onset categories. 
The word durations with nasal and unaspirated onsets are very similar (means = 391 ms and 388 ms, respectively), but words with aspirated onsets have systematically much longer durations (mean = 440 ms).
The mean *vowel durations*, on the other hand -- i.e., the duration of trajectories beginning at the onset of voicing -- *are* roughly comparable across onset categories (nasals = 314 ms, unaspirated = 304 ms, aspirated = 310 ms).
The distributions of trajectory durations using different landmarks are shown in @fig-durdist. 
This intuitively makes it seem likelier that pitch peaks are also timed to the onset voicing.

```{r}
#| label: fig-durdist
#| fig-cap: Violin plots showing the distributions of trajectory durations depending on which landmark is chosen to represent the beginning of the trajectory. Points show individual trajectory durations.

sl$voi <- factor(sl$voi, levels = c('nasal', 'unasp', 'asp'))
sl %>% pivot_longer(cols = c(syldur, vdur), names_to = 'landmark',
                    values_to='durcomp') %>% 
  ggplot() +
  aes(x=voi, y=durcomp, fill=voi) +
  geom_jitter(aes(col=voi), alpha=0.1) +
  geom_violin() +
  facet_grid(~landmark,
             labeller = labeller(
               landmark = c(vdur = 'Onset of voicing',
                            syldur = 'Syllabic onset'))) +
  xlab('') +
  ylab('Trajectory duration (ms)') +
  scale_color_manual(values = c('black', 'blue', 'darkorange'),
                     name = 'Onset',
                     labels = c('nasal', 'unaspirated', 'aspirated')) +
  scale_fill_manual(values = c('darkgrey', 'blue', 'darkorange'),
                     name = 'Onset',
                     labels = c('nasal', 'unaspirated', 'aspirated')) +
  theme(panel.background = element_rect(fill = NA),
        panel.border = element_rect(color = 'black', fill=NA),
        panel.grid.major = element_line(color='grey90'),
        panel.grid.minor = element_line(color='grey95'),
        legend.position = 'bottom',
        text = element_text(size = 12),
        legend.box = 'vertical',
        axis.title.y = ggtext::element_markdown(),
        axis.ticks.x = element_blank(),
        axis.text.x = element_blank())
```

::: {.content-visible when-format="html"}
::: {.callout-note collapse="true"}

## Preparing data for analysis -- second attempt!

It looks like we want to extract *F*~0~ trajectories over a different interval than we previously have. This means creating an alternative segment list with a `start` column that has the right information. We can do this straightforwardly, since we already have time information about the voicing onset in our existing `sl` object, so we use that to create an alternative:

```{r Create alternative segment list}
#| code-fold: false

alt_sl <- sl %>% mutate(start = ifelse(vo == 0, start, vo))

alt_sl <- sl %>% mutate(start = ifelse(vo == 0, rel, vo))
```

Now, we repeat the whole procedure for extracting pitch data from both tracking algorithms, removing outliers, getting *z*-scores etc.

```{r Repeat pitch processing steps for new trajectories}
#| code-fold: false

td2 <- get_trackdata(db, alt_sl, ssffTrackName='f0', verbose = FALSE)
td2[which(td2$T1 == 0),'T1'] <- NA

tdr2 <- get_trackdata(db, alt_sl, ssffTrackName='rf0', verbose = FALSE)
tdr2[which(tdr2$T1 == -1),'T1'] <- NA

td2 <- td2 %>% rename(praat_f0 = T1)
td2$reaper_f0 <- tdr2$T1

td2 <- td2 %>% mutate(
  low_est = ifelse(reaper_f0 < praat_f0, reaper_f0, praat_f0),
  f0_diff = (reaper_f0-praat_f0)/low_est,
  f0 = case_when(
    is.na(f0_diff) ~ NA,
    abs(f0_diff) > 0.2 ~ NA,
    times_orig < vo ~ NA,
    TRUE ~ (praat_f0+reaper_f0)/2
  )) %>% group_by(session) %>%
  mutate(uppF0 = mean(f0, na.rm=T) + 3*sd(f0, na.rm=T),
         lowF0 = mean(f0, na.rm=T) - 3*sd(f0, na.rm=T),
         f0 = ifelse(f0 > uppF0 | f0 < lowF0, NA, f0))

td2 <- td2 %>% group_by(session) %>%
  mutate(zf0 = as.numeric(scale(f0))) %>%
  ungroup()
```

This is the data frame we want for analysis, so we'll rename it `dat`.

```{r Creating dat object}
#| code-fold: false

dat <- td2
```

A final post-processing step is to remove trajectories that have too large inter-frame differences, as a relatively coarse way to remove octave jumps:

```{r Filter out trajectories with obvious octave jumps}
#| code-fold: false
#| warning: false
#| message: false

dat$diff <- rep(NA, nrow(dat))
dat$diff[2:nrow(dat)] <-
  dat$zf0[2:nrow(dat)] - dat$zf0[1:(nrow(dat)-1)]
dat[which(dat$times_rel == 0),'diff'] <- NA
max_diffs <- dat %>% group_by(sl_rowIdx) %>%
  summarize(m = abs(max(diff, na.rm=T)))
dat <- left_join(dat, max_diffs, by='sl_rowIdx')
dat <- dat %>% filter(m < 1.5)
```

:::
:::

To check whether this is indeed the case, we plot some representative trajectories.
@fig-landmarkcomp shows smoothed *F*~0~ trajectories of the words in the high pitch condition in the subgroup of speakers from Jutland. 
The figure shows that, on a raw time scale, prominent peaks and valleys are systematically misaligned across onset categories if trajectories begin at the syllable onset, but they align better after an initial perturbation if trajectories begin at voicing onset. 
The figure also suggests that any initial influence of aspiration on *F*~0~ would be obscured if trajectories begin at the syllabic onset due to variation in pVOT.

```{r}
#| label: fig-landmarkcomp
#| warning: false
#| message: false
#| fig-cap: Smoothed *F*~0~ trajectories over raw time in different conditions with different landmarks conditioning the beginning of the trajectory. Trajectories are smoothed using separate generalized additive models. Based on Jutland speakers and words in the high-pitch condition.

trajTheme <- theme(panel.background = element_rect(fill = NA),
                   panel.border = element_rect(color = 'black', fill=NA),
                   panel.grid.major = element_line(color='grey90'),
                   panel.grid.minor = element_line(color='grey95'),
                   legend.position = 'bottom',
                   text = element_text(size = 12),
                   legend.box = 'vertical',
                   plot.title = element_text(hjust = 0.5),
                   axis.title.y = ggtext::element_markdown())

td$alignment <- 'Aligned at syllable onset'
td2$alignment <- 'Aligned at voicing onset'
td_all <- rbind(td, td2)
td_all$voi <- factor(td_all$voi, levels = c('nasal', 'unasp', 'asp'))
td_all %>%
  filter(cond == 'foc', variety == 'j') %>%
  ggplot() +
  aes(x=times_rel, y=zf0, color=voi) %>%
  geom_smooth(method='gam') +
  xlim(0,500) +
  facet_grid(st~alignment,
             labeller = labeller(
               st = c(nst = 'non-stød', st = 'stød'))) +
  ylab('*F*~0~ (*z*-scored)') +
  xlab('Time (ms)') +
  scale_color_manual(values = c('black', 'blue', 'darkorange'),
                     name = 'Onset',
                     labels = c('nasal', 'unaspirated', 'aspirated')) +
  trajTheme
```

## Statistical analysis {#sec-methods-stats}

The research questions posed in @sec-rq are all statistically tested using a generalized additive mixed model (GAMM).
GAMMs are highly suitable for modelling data that change over time [@wieling2018], and they have been widely used in the past few years for modelling pitch data, including in studies of C*F*~0~ [e.g. @kirby2022khmu; @ting2023].
The advantage of using GAMMs over traditional linear mixed-effects regression models in the analysis of time series is that the GAMMs do not restrict the relationship between predictor and response variables to be linear; GAMMs can model data that vary dynamically in time, i.e. complex contour shapes. 
In this approach, non-linear (or *smooth*) effects are predicted by fitting the data to a series of basis functions (or *splines*). 
We fit GAMMs using the `mgcv` library in R [@mgcv], which provides a very flexible framework for selecting and combining basis functions, and for penalizing overfitting.

The model is fitted using fast restricted maximum likelihood estimation with discretized values for covariates to decrease computing load [@bam], and using the scaled-*t* error distribution to account for heavy-tailed residuals.
The residuals of the final model are approximately normal, although somewhat platykurtic.
The temporal dynamics of *F*~0~ is modeled with thin plate regression spline smooths [@wood2003; @wieling2018] using 10 basis functions, where time is normalized to a 0--1 scale; separate *F*~0~ contours are modelled for all levels of the four-way interaction between the variables [onset, pitch condition, stød]{.smallcaps} and [regional variety]{.smallcaps}.
The model further includes this same four-way interaction as well as [vowel height]{.smallcaps} as parametric, i.e. time-invariant, predictors.^[Since we expect the effect of [vowel height]{.smallcaps} to be more or less constant, it is only included as a parametric variable in the model.]
The model is fitted with a maximal random effects structure, including by-speaker and by-item *factor smooths* (the non-linear equivalent to random slopes) for each logically meaningful combination of the variables.
To decrease computing load, factor smooths are fitted with first-order penalty differences and are smoothed using only five basis functions.

Skipping over most implementation details, the model can be summarized as

$$
\begin{gather*}
F_{0ijk} = \alpha \\
+ onset_i condition_i stød_i variety_i + height_i \\
+ onset_i condition_i stød_i variety_i (t_i) \\
+ speaker_j onset_i condition_i stød_i (t_i) \\
+ item_k condition_i variety_i (t_i) \\
+ \rho e_{i - 1} + E_{ijk}
\end{gather*}
$$

where $\alpha$ denotes the intercept, $E$ denotes the residual error, $i$ indexes each observation, $j$ indexes each speaker, and $k$ indexes each item. 
A typical problem with time series analysis is that residual autocorrelation stemming from the high degree of similarity between adjacent measures in time series. 
We manage this problem by modulating the error of each observation $e_i$ by the error of the preceding observation $e_{i-1}$ by a factor of $\rho$; this is referred to as an AR(1) error model [@baayen2018; @wieling2018]. Following e.g. @wieling2016, $\rho$ is a fixed value equivalent to the average residual autocorrelation of adjacent measures in a nested model with no correction.
Residual autocorrelation in the corrected model is negligible.
A more ideal solution would be to fit the model with by-trajectory factor smooths, which preserves the identity of trajectories in the model and dispenses with the assumption that the degree of autocorrelation is constant [@soskuthy2021]; however, fitting such a model proved to be computationally infeasible.

::: {.content-visible when-format="html"}
::: {.callout-note collapse="true"}

## Fitting GAMM 

Before fitting the GAMM, we make sure that all factor variables are actually interpreted as factors.

```{r Factorizing factor variables}
#| code-fold: false

for (f in c('vheight', 'voi', 'variety', 'cond', 
            'st', 'item', 'session', 'sl_rowIdx')){
  dat[[f]] <- as.factor(dat[[f]])
}
```

R will automatically order these factor levels alphabetically, but if we want to interpret the parametric output of the GAMM, it's nice to have factor level ordering that corresponds more closely to the hypotheses we're interested in. The `cond` and `st` (focus condition and stød) variables are fine, since *focus* and *non-stød* are reasonable reference levels, but we reorder `vheight` so `low` is the reference, `variety` so `z` is the reference (since Zealand Danish is just more well-described than Jutland Danish), and crucially, `voi` so `nasal` is the reference.

```{r Setting reference levels}
#| code-fold: false

dat$vheight <- dat$vheight %>% relevel('low')
dat$voi <- dat$voi %>% relevel('nasal')
dat$variety <- dat$variety %>% relevel('z')
```

```{r Load mgcv and itsadug silently}
#| echo: false
#| message: false
#| warning: false

library(mgcv)
library(itsadug)
```


We're now ready to fit the actual model. The model with no AR(1) correction is fitted with this code:

```{r Fit model without AR1 correction}
#| code-fold: false
#| eval: false

library(mgcv)

gam_mod <- bam(zf0 ~ monsterInteraction + vheight +
                 s(times_norm, by=monsterInteraction) +
                 s(times_norm, session, by=bigInteraction, bs='fs', m=1, k=5) +
                 s(times_norm, item, by=smallInteraction, bs='fs', m=1, k=5),
               data = dat %>%
                 mutate(monsterInteraction = interaction(voi,cond,st,variety),
                        bigInteraction = interaction(voi,cond,st),
                        smallInteraction = interaction(cond,variety)),
               discrete = TRUE, nthreads = 10,
               family = 'scat')

gam_mod <- bam(zf0 ~ monsterInteraction + vheight +
                 s(times_rel, by=monsterInteraction) +
                 s(times_rel, session, by=bigInteraction, bs='fs', m=1, k=5) +
                 s(times_rel, item, by=smallInteraction, bs='fs', m=1, k=5),
               data = dat %>%
                 mutate(monsterInteraction = interaction(voi,cond,st,variety),
                        bigInteraction = interaction(voi,cond,st),
                        smallInteraction = interaction(cond,variety)) %>% 
                 filter(times_rel < 200),
               discrete = TRUE, nthreads = 10,
               family = 'scat',
               control = list(trace=T))
```

We use the `bam()` function which is typically used for efficiently fitting large GAMMs.
Smooths are constructed with the `s()` function. `mgcv` does not have built-in functionality to fit interaction terms within smooths, so these interaction terms (with very apt names) are created on the fly using the `interaction()` function. `bs='fs'` specifies a factor smooth, `m=1` specifies a first-order penalty difference, and `k=5` specifies the number of basis functions to use. `discrete = TRUE` tells `mgcv` to use discretized values for covariates. `nthreads = 10` specifies the number of cores to use, set to 10 here. `family = 'scat'` specifies the scaled-*t* error distribution.

This model is only fitted so we can find out what's a reasonably `rho` parameter for AR(1) correction. We do this using the `acf_resid()` function from the `itsadug` library, which returns a vector of autocorrelation values at progressively higher lags in the time series. Autocorrelation at lag 1 is always equal to 1 (it's how much any value is correlated with itself, which is logically a perfect correlation), so we grab the second value of that vector. We also add a column `startEvent`, this is a Boolean column which is `TRUE` for the first row of each time series and `FALSE` otherwise; this column is passed to the argument `AR.start`. Otherwise the code is the same:

```{r Fit model with AR1 correction}
#| code-fold: false
#| eval: false

library(itsadug)

gam_mod_rho <- bam(zf0 ~ monsterInteraction + vheight +
                     s(times_norm, by=monsterInteraction) +
                     s(times_norm, session, by=bigInteraction, bs='fs', m=1, k=5) +
                     s(times_norm, item, by=smallInteraction, bs='fs', m=1, k=5),
                   data = dat %>%
                     mutate(monsterInteraction = interaction(voi,cond,st,variety),
                            bigInteraction = interaction(voi,cond,st),
                            smallInteraction = interaction(cond,variety),
                            startEvent = times_rel == 0),
                   discrete = TRUE, nthreads = 10,
                   family = 'scat',
                   rho = itsadug::acf_resid(gam_mod)[2], AR.start = startEvent)
```

Since fitting these models is so time-demanding, we do not actually do it as part of rendering this document; instead, it's done on the IPS server, and just loaded in here: 

```{r Load final model}
#| code-fold: false

load('data/gam_maxre_rho.Rda')
```

The residuals of the model are reasonably normally distributed, although somewhat light tailed:

```{r Check residuals}
#| fig-height: 3.5

res <- gam_mod_rho$residuals
m <- mean(res)
s <- sd(res)

normdist <- ggplot(data.frame(res)) + 
  aes(x=res) +
  geom_histogram(aes(y=after_stat(density)), bins=24) +
  stat_function(fun=dnorm,
                args=list(mean=m, sd=s),
                color='blue', lwd=1) +
  xlim(-4, 4) +
  ggtitle('Comparison with normal distribution') +
  xlab('Residuals') +
  trajTheme

qqpl <- ggplot() +
  aes(sample=res) +
  stat_qq() +
  stat_qq_line(color='blue', lwd=1) +
  ggtitle('QQ plot') +
  xlab('Theoretical quantiles') + ylab('Samples') +
  trajTheme

gridExtra::grid.arrange(normdist, qqpl, ncol=2)
```

And the model has only very negligible residual autocorrelation:

```{r Check residual autocorrelation}
acf_resid(gam_mod_rho, main = 'Residual autocorrelation')
```

:::
:::

It is not straightforward to test hypotheses from the non-parametric components of GAMMs. 
The *F*-test provided by the `mgcv` library essentially tests the significance of the spline fitting procedure [@wood2013], which is typically not something phoneticians have hypotheses about. 
In this study, hypothesis testing is done through pointwise comparisons of relevant model-predicted trajectories with random effects removed, using the `itsadug` library [@itsadug].
Comparisons are considered significant at time points where the predicted 95% confidence intervals do not overlap. 

::: {.content-visible when-format="html"}
::: {.callout-note collapse="true"}

## Extracting fitted trajectories and pointwise comparisons

Extracting fitted trajectories is relatively straightforward. We do this with the `get_predictions()` function from `itsadug`. We have a four-way interaction with a total of 24 levels; `get_predictions()` extracts one of these at a time (chosen with the `select` argument), so we do this in a loop, and combine the resulting data frames in an object `preds`. This object has a column `monsterInteraction` which we split into four columns which describes each level of each interaction.

```{r Get model predictions}
#| code-fold: false

u <- levels(interaction(dat$voi,dat$cond,dat$st,dat$variety))
preds <- itsadug::get_predictions(gam_mod_rho, 
                                cond=list(monsterInteraction = u[1],
                                          times_norm = seq(0, 1, length=100)),
                                print.summary = F)
for (i in 2:24) {
  tmp <- itsadug::get_predictions(gam_mod_rho, 
                                  cond=list(monsterInteraction = u[i],
                                            times_norm = seq(0, 1, length=100)),
                                  print.summary = F)
  preds <- rbind(preds, tmp)
}

preds <- preds %>%
  separate(monsterInteraction, into = c('voi', 'cond', 'st', 'variety'),
           remove = F)

####

# u <- levels(interaction(dat$voi,dat$cond,dat$st,dat$variety))
# preds <- itsadug::get_predictions(gam_mod_rho, 
#                                 cond=list(monsterInteraction = u[1],
#                                           times_rel = seq(0, 200, length=100)),
#                                 print.summary = F)
# for (i in 2:24) {
#   tmp <- itsadug::get_predictions(gam_mod_rho, 
#                                   cond=list(monsterInteraction = u[i],
#                                             times_rel = seq(0, 200, length=100)),
#                                   print.summary = F)
#   preds <- rbind(preds, tmp)
# }
# 
# preds <- preds %>%
#   separate(monsterInteraction, into = c('voi', 'cond', 'st', 'variety'),
#            remove = F)
```

The model allows us to test a *lot* of comparisons, most of which we aren't really interested in. What we want to test is essentially whether *F*~0~ is significantly higher after unaspirated/aspirated stops than after nasals. That adds up to 16 comparisons, which we get in a loop using the `get_difference()` function in `itsadug`. This gives us the predicted difference between two variable levels and the associated 95% confidence intervals. Using this, we create a vector `sig` which simply has `1` for each pointwise comparisons where the *F*~0~ following a stop is significantly higher than following a nasal, and `0` where it isn't.

```{r Get term comparisons}
#| code-fold: false

u <- as.character(unique(preds$monsterInteraction))
sig <- c()
diff <- c()
unaspAspSig <- c()
for (i in 1:length(u)) {
  m <- strsplit(u[i], '\\.')[[1]][1]
  if (m == 'nasal') {
    thisSig <- rep(NA, 100)
    sig <- c(sig, thisSig)
    thisDiff <- rep(NA, 100)
    diff <- c(diff, thisDiff)
    thisUnaspAspSig <- rep(NA, 100)
    unaspAspSig <- c(unaspAspSig, thisUnaspAspSig)
  } else {
    intlevel <- paste(strsplit(u[i], '\\.')[[1]][2:4], collapse='.')
    complevel <- paste('nasal', intlevel, sep='.')
    dif <- itsadug::get_difference(gam_mod_rho, list(
      monsterInteraction = c(complevel, u[i])
    ), cond=list(times_norm=seq(0,1,length.out=100)), se=T, print.summary=F)
    thisSig <- ifelse(dif$difference + dif$CI > 0, 0, 1)
    sig <- c(sig, thisSig)
    thisDiff <- dif$difference
    diff <- c(diff, thisDiff)
    if (m == 'unasp') {
      thisUnaspAspSig <- rep(NA, 100)
      unaspAspSig <- c(unaspAspSig, thisUnaspAspSig)
    } else {
      complevel <- paste('unasp', intlevel, sep='.')
      dif <- itsadug::get_difference(gam_mod_rho, list(
        monsterInteraction = c(complevel, u[i])
      ), cond=list(times_norm=seq(0,1,length.out=100)), se=T, print.summary=F)
      thisUnaspAspSig <- ifelse(dif$difference + dif$CI > 0, 0, 1)
      unaspAspSig <- c(unaspAspSig, thisUnaspAspSig)
    }
  }
}

preds$sig <- sig
preds$diff <- diff
preds$unaspAspSig <- unaspAspSig

####

# u <- as.character(unique(preds$monsterInteraction))
# sig <- c()
# diff <- c()
# unaspAspSig <- c()
# for (i in 1:length(u)) {
#   m <- strsplit(u[i], '\\.')[[1]][1]
#   if (m == 'nasal') {
#     thisSig <- rep(NA, 100)
#     sig <- c(sig, thisSig)
#     thisDiff <- rep(NA, 100)
#     diff <- c(diff, thisDiff)
#     thisUnaspAspSig <- rep(NA, 100)
#     unaspAspSig <- c(unaspAspSig, thisUnaspAspSig)
#   } else {
#     intlevel <- paste(strsplit(u[i], '\\.')[[1]][2:4], collapse='.')
#     complevel <- paste('nasal', intlevel, sep='.')
#     dif <- itsadug::get_difference(gam_mod_rho, list(
#       monsterInteraction = c(complevel, u[i])
#     ), cond=list(times_rel=seq(0,200,length.out=100)), se=T, print.summary=F)
#     thisSig <- ifelse(dif$difference + dif$CI > 0, 0, 1)
#     sig <- c(sig, thisSig)
#     thisDiff <- dif$difference
#     diff <- c(diff, thisDiff)
#     if (m == 'unasp') {
#       thisUnaspAspSig <- rep(NA, 100)
#       unaspAspSig <- c(unaspAspSig, thisUnaspAspSig)
#     } else {
#       complevel <- paste('unasp', intlevel, sep='.')
#       dif <- itsadug::get_difference(gam_mod_rho, list(
#         monsterInteraction = c(complevel, u[i])
#       ), cond=list(times_rel=seq(0,200,length.out=100)), se=T, print.summary=F)
#       thisUnaspAspSig <- ifelse(dif$difference + dif$CI > 0, 0, 1)
#       unaspAspSig <- c(unaspAspSig, thisUnaspAspSig)
#     }
#   }
# }
# 
# preds$sig <- sig
# preds$diff <- diff
# preds$unaspAspSig <- unaspAspSig
```

In order to plot these significance levels later, we create separate columns for significant differences of unaspirated and aspirated stops, and columns containing the time information for where to indicate significance.

```{r Format comparisons}
#| code-fold: false

preds$unasp_sig <- ifelse(preds$sig == 1 & preds$voi == 'unasp', 'sig', 'nsig')
preds$unasp_sig <- ifelse(preds$voi != 'unasp', NA, preds$unasp_sig)
preds$unasp_lower <- ifelse(preds$unasp_sig == 'sig', preds$times_norm, NA)
preds$unasp_upper <- ifelse(preds$unasp_sig == 'sig', preds$times_norm +
                              (1/99), NA)

preds$asp_sig <- ifelse(preds$sig == 1 & preds$voi == 'asp', 'sig', 'nsig')
preds$asp_sig <- ifelse(preds$voi != 'asp', NA, preds$asp_sig)
preds$asp_lower <- ifelse(preds$asp_sig == 'sig', preds$times_norm, NA)
preds$asp_upper <- ifelse(preds$asp_sig == 'sig', preds$times_norm +
                              (1/99), NA)

preds$unaspAsp_lower <- ifelse(preds$unaspAspSig == 1, preds$times_norm, NA)
preds$unaspAsp_upper <- ifelse(preds$unaspAspSig == 1, preds$times_norm +
                              (1/99), NA)

####

# preds$unasp_sig <- ifelse(preds$sig == 1 & preds$voi == 'unasp', 'sig', 'nsig')
# preds$unasp_sig <- ifelse(preds$voi != 'unasp', NA, preds$unasp_sig)
# preds$unasp_lower <- ifelse(preds$unasp_sig == 'sig', preds$times_rel, NA)
# preds$unasp_upper <- ifelse(preds$unasp_sig == 'sig', preds$times_rel +
#                               (2.5), NA)
# 
# preds$asp_sig <- ifelse(preds$sig == 1 & preds$voi == 'asp', 'sig', 'nsig')
# preds$asp_sig <- ifelse(preds$voi != 'asp', NA, preds$asp_sig)
# preds$asp_lower <- ifelse(preds$asp_sig == 'sig', preds$times_rel, NA)
# preds$asp_upper <- ifelse(preds$asp_sig == 'sig', preds$times_rel +
#                               (2.5), NA)
# 
# preds$unaspAsp_lower <- ifelse(preds$unaspAspSig == 1, preds$times_rel, NA)
# preds$unaspAsp_upper <- ifelse(preds$unaspAspSig == 1, preds$times_rel +
#                               (2.5), NA)
```

Finally, we make sure that the `voi` factor is ordered in the same way as in the `dat` data frame:

```{r Factorize onset variable in comparisons data frame}
#| code-fold: false

preds$voi <- factor(preds$voi, levels = c('nasal', 'unasp', 'asp'))
```

:::
:::

# Results {#sec-results}

## Checking assumptions

Before proceeding to the statistical analysis of C*F*~0~ in @sec-res-cf0, in this section we first present some brief data exploration to check whether the assumptions underlying our research questions and hypotheses hold up. 

A core assumption of *RQ*2 is that the aspiration contrast is comparable in speakers from Jutland and Zealand; if this contrast differs in these two varieties, it would potentially be a major confound. 
As proxies for this, we plot the distributions of pVOT in @fig-pVOT. 
The plots show that pVOT is quite similar across varieties; aspirated stops are slightly longer in Jutland varieties, but the difference is below 5 ms on average.
We also facet this by sentence position, to check whether there are major pVOT differences between words with in the high and low pitch condition, for example due to phrase final lengthening. pVOT appears to be very similar across conditions.

```{r}
#| label: fig-pVOT
#| warning: false
#| message: false
#| fig-cap: Violin plots showing the distributions of positive voice onset time values by onset category, sentence position, and variety.

sl %>% mutate(varietyFullNames = 
                ifelse(variety == 'j', 'Jutland', 'Zealand')) %>%
  filter(voi != 'nasal', !is.na(variety)) %>% 
  ggplot() +
  aes(x=varietyFullNames, y=vot, fill=voi) +
  geom_jitter(aes(col=voi), alpha=0.1) +
  geom_violin() +
  facet_grid(cond~voi,
             labeller = labeller(
               cond = c(foc = 'High pitch condition', 
                        nfoc= 'Low pitch condition'),
               voi = c(unasp = 'Unaspirated',
                       asp = 'Aspirated'))) +
  xlab('Variety') +
  ylab('Positive voice onset time (ms)') +
  scale_color_manual(values = c('blue', 'darkorange'),
                     name = 'Onset',
                     labels = c('unaspirated', 'aspirated'),
                     guide = 'none') +
  scale_fill_manual(values = c('blue', 'darkorange'),
                    name = 'Onset',
                    labels = c('unaspirated', 'aspirated'),
                    guide = 'none') +
  trajTheme
```

Both *RQ*2 and *RQ*3 rely on specific assumptions about the baseline pitch contour when combining sentence position, the voice quality contrast, and regional varieties. To this end, we plot the *F*~0~ trajectories of items with nasal onsets in all those combinations in @fig-baselineTrajs. 
The top-right frame of @fig-baselineTrajs shows that the pitch peak in Jutland Danish does indeed fall earlier than in Zealand Danish as discussed in @sec-stresspitch, but the two trajectories are more similar than expected from previous descriptions. 
While we cannot straightforwardly make judgments about syllable boundaries from @fig-baselineTrajs, it appears that the pitch peak in both varieties falls in the post-tonic syllable, although there is likely an earlier and more prominent rise in the tonic syllable among the Jutland speakers. 
This somewhat complicates the interpretation of *RQ*2, as not all of our assumptions are fully met. We will discuss this further in light of the results in @sec-disc-rq2.

```{r}
#| label: fig-baselineTrajs
#| warning: false
#| message: false
#| fig-cap: Smoothed *F*~0~ trajectories of words with nasal onsets showing combinations of the sentence position, voice quality contrast, and regional variety. Trajectories are smoothed using separate generalized additive models.

td2 %>%
  filter(!is.na(variety), voi == 'nasal') %>%
  ggplot() +
  aes(x=times_norm, y=zf0, color=variety) %>%
  geom_smooth(method='gam') +
  facet_grid(st~cond,
             labeller = labeller(
               cond = c(foc = 'High pitch condition', 
                        nfoc= 'Low pitch condition'),
               st = c(nst = 'Non-stød',
                       st = 'Stød'))) +
  ylab('*F*~0~ (*z*-scored)') +
  xlab('Time (norm.)') +
  scale_color_manual(values = c('blue', 'darkorange'),
                     labels = c('Jutland', 'Zealand')) +
  trajTheme
```

The bottom-right frame of @fig-baselineTrajs shows that the pitch onset is higher in syllables with stød, and that pitch rises slightly and then drops. 
This is the case in both varieties, but pitch both rises and drops much more dramatically in Jutland Danish. 
This is in line with the findings of @kyst2008 and @siem2023diss that stød in Jutland Danish is predominantly tonal, while in Zealand Danish there is a voice quality component which may not be captured in @fig-baselineTrajs. 
In any case, it is clearly the case -- in both varieties, but more so in Jutland Danish -- that syllables with stød place constraints on the vocal folds that may either strengthen or weaken C*F*~0~ effects, following *RQ*3.
It is the case across the board that trajectories in the low pitch condition have similar shapes to the high pitch condition condition, but with a clear difference in pitch level and the scope of the excursions.

## Co-intrinsic *F*~0~ {#sec-res-cf0}

The research questions posed in @sec-rq are tested with the GAMM that was presented in @sec-methods-stats. The model has a high effect size of $R^2=0.64$. 
We do not explore the parametric coefficients of the model in any detail, as they are all control variables, and generally taken into account in the plots below. 
It is worth mentioning here that all dynamic model terms are highly significant, that most levels of the parametric four-way interaction also differ significantly from the model intercept (i.e., they exert a constant influence on pitch level), and that high vowels are predicted to raise pitch by 0.29 standard deviations or approx. 16 Hz ($SE = 0.02, t = 12.02, p < .001$).

All model-predicted trajectories are shown in @fig-gammfit-nonst and @fig-gammfit-st. Both plots are faceted by sentence position and variety, such that the high pitch condition is shown in the left column and the low pitch condition in the right column, and speakers from Jutland are shown in the top row and speakers from Zealand in the second row.
Lines are colored by onset category, and in addition to the predicted values, the plots also show pointwise 95% confidence intervals. 
The straight lines at the top and bottom of each plot indicate parts of trajectories that are significantly higher than the nasal baseline.
@fig-gammfit-nonst shows words without stød, and @fig-gammfit-st shows words with stød.

```{r}
#| label: fig-gammfit-nonst
#| warning: false
#| message: false
#| fig-cap: Model predicted *F*~0~ trajectories with 95% confidence intervals of words without stød, faceted by focus condition and variety and colored by onset category. Straight lines at the top and bottom of each facet indicate parts of trajectories that are significantly above the nasal baseline, and straight lines at the bottom of each facet indicate parts of aspirated trajectories that are significantly higher than unaspirated trajectories.
#| fig-height: 5.5

preds %>% filter(st == 'nst') %>%
  ggplot() +
  aes(x=times_norm) +
  geom_ribbon(aes(ymin = fit - CI, ymax = fit + CI,
                  fill = voi), alpha = 0.2) +
  geom_line(aes(y = fit, color = voi)) +
  geom_linerange(aes(xmin=unasp_lower, xmax=unasp_upper, y=2.4),
                 color = 'blue', lwd = 1) +
  geom_linerange(aes(xmin=asp_lower, xmax=asp_upper, y=2.5),
                 color = 'darkorange', lwd=1) +
  geom_linerange(aes(xmin=unaspAsp_lower, xmax=unaspAsp_upper, y=-2),
                 color = 'magenta', lwd=1) +
  facet_grid(variety~cond,
             labeller = labeller(
               variety = c(j = 'Jutland', z = 'Zealand'),
               cond = c(foc = 'High pitch condition', 
                        nfoc = 'Low pitch condition'))) +
  xlim(0, 1) +
  ylab('Fitted *F*~0~ (z-scored)') +
  xlab('Time (norm.)') +
  scale_color_manual(values = c('black', 'blue', 'darkorange'),
                     name = 'Onset',
                     labels = c('nasal', 'unaspirated', 'aspirated')) +
  scale_fill_manual(values = c('black', 'blue', 'darkorange'),
                     name = 'Onset',
                     labels = c('nasal', 'unaspirated', 'aspirated')) +
  ggtitle('Non-stød') +
  trajTheme

####

# preds %>% filter(st == 'nst') %>%
#   ggplot() +
#   aes(x=times_rel) +
#   geom_ribbon(aes(ymin = fit - CI, ymax = fit + CI,
#                   fill = voi), alpha = 0.2) +
#   geom_line(aes(y = fit, color = voi)) +
#   geom_linerange(aes(xmin=unasp_lower, xmax=unasp_upper, y=2.4),
#                  color = 'blue', lwd = 1) +
#   geom_linerange(aes(xmin=asp_lower, xmax=asp_upper, y=2.5),
#                  color = 'darkorange', lwd=1) +
#   geom_linerange(aes(xmin=unaspAsp_lower, xmax=unaspAsp_upper, y=-2),
#                  color = 'magenta', lwd=1) +
#   facet_grid(variety~cond,
#              labeller = labeller(
#                variety = c(j = 'Jutland', z = 'Zealand'),
#                cond = c(foc = 'High pitch condition', 
#                         nfoc = 'Low pitch condition'))) +
#   xlim(0, 200) +
#   ylab('Fitted *F*~0~ (z-scored)') +
#   xlab('Time (norm.)') +
#   scale_color_manual(values = c('black', 'blue', 'darkorange'),
#                      name = 'Onset',
#                      labels = c('nasal', 'unaspirated', 'aspirated')) +
#   scale_fill_manual(values = c('black', 'blue', 'darkorange'),
#                      name = 'Onset',
#                      labels = c('nasal', 'unaspirated', 'aspirated')) +
#   ggtitle('Non-stød') +
#   trajTheme
```

```{r}
#| label: fig-gammfit-st
#| warning: false
#| message: false
#| fig-cap: Model predicted *F*~0~ trajectories with 95% confidence intervals of words with stød, faceted by focus condition and variety and colored by onset category. Straight lines at the top of each facet indicate parts of trajectories that are significantly above the nasal baseline.
#| fig-height: 5.5

preds %>% filter(st == 'st') %>%
  ggplot() +
  aes(x=times_norm) +
  geom_ribbon(aes(ymin = fit - CI, ymax = fit + CI,
                  fill = voi), alpha = 0.2) +
  geom_line(aes(y = fit, color = voi)) +
  geom_linerange(aes(xmin=unasp_lower, xmax=unasp_upper, y=2.4),
                 color = 'blue', lwd = 1) +
  geom_linerange(aes(xmin=asp_lower, xmax=asp_upper, y=2.5),
                 color = 'darkorange', lwd=1) +
  geom_linerange(aes(xmin=unaspAsp_lower, xmax=unaspAsp_upper, y=-2),
                 color = 'magenta', lwd=1) +
  facet_grid(variety~cond,
             labeller = labeller(
               variety = c(j = 'Jutland', z = 'Zealand'),
               cond = c(foc = 'High pitch condition', 
                        nfoc = 'Low pitch condition'))) +
  xlim(0, 1) +
  ylab('Fitted *F*~0~ (z-scored)') +
  xlab('Time (norm.)') +
  scale_color_manual(values = c('black', 'blue', 'darkorange'),
                     name = 'Onset',
                     labels = c('nasal', 'unaspirated', 'aspirated')) +
  scale_fill_manual(values = c('black', 'blue', 'darkorange'),
                     name = 'Onset',
                     labels = c('nasal', 'unaspirated', 'aspirated')) +
  ggtitle('Stød') +
  trajTheme

####

# preds %>% filter(st == 'st') %>%
#   ggplot() +
#   aes(x=times_rel) +
#   geom_ribbon(aes(ymin = fit - CI, ymax = fit + CI,
#                   fill = voi), alpha = 0.2) +
#   geom_line(aes(y = fit, color = voi)) +
#   geom_linerange(aes(xmin=unasp_lower, xmax=unasp_upper, y=2.4),
#                  color = 'blue', lwd = 1) +
#   geom_linerange(aes(xmin=asp_lower, xmax=asp_upper, y=2.5),
#                  color = 'darkorange', lwd=1) +
#   geom_linerange(aes(xmin=unaspAsp_lower, xmax=unaspAsp_upper, y=-2),
#                  color = 'magenta', lwd=1) +
#   facet_grid(variety~cond,
#              labeller = labeller(
#                variety = c(j = 'Jutland', z = 'Zealand'),
#                cond = c(foc = 'High pitch condition', 
#                         nfoc = 'Low pitch condition'))) +
#   xlim(0, 200) +
#   ylab('Fitted *F*~0~ (z-scored)') +
#   xlab('Time (norm.)') +
#   scale_color_manual(values = c('black', 'blue', 'darkorange'),
#                      name = 'Onset',
#                      labels = c('nasal', 'unaspirated', 'aspirated')) +
#   scale_fill_manual(values = c('black', 'blue', 'darkorange'),
#                      name = 'Onset',
#                      labels = c('nasal', 'unaspirated', 'aspirated')) +
#   ggtitle('Stød') +
#   trajTheme
```

```{r}
#| label: tbl-diffs
#| tbl-cap: Model-predicted *F*~0~ differences between stops and nasals in different conditions at different points in normalized time.

diffs0 <- preds %>% 
  filter(round(times_norm,3) == 0, voi != 'nasal') %>% 
  select(cond, st, variety, voi, diff) %>% 
  mutate(diffHz = diff * sd(dat$f0, na.rm=T))
diffs10 <- preds %>% 
  filter(round(times_norm,3) == 0.101, voi != 'nasal') %>% 
  select(cond, st, variety, voi, diff) %>% 
  mutate(diffHz = diff * sd(dat$f0, na.rm=T))
diffs20 <- preds %>% 
  filter(round(times_norm,3) == 0.202, voi != 'nasal') %>% 
  select(cond, st, variety, voi, diff) %>% 
  mutate(diffHz = diff * sd(dat$f0, na.rm=T))
diffs <- data.frame(cond = gsub('nfoc', 'low', diffs0$cond) %>% 
                      gsub('foc', 'high', .),
                    st = gsub('st', 'stød', diffs0$st) %>% 
                      gsub('nst', 'non-st', .),
                    variety = gsub('j', 'Jutland', diffs0$variety) %>% 
                      gsub('z', 'Zealand', .),
                    voi = gsub('asp', 'aspirated', diffs0$voi))
colnames(diffs) <- c('condition', 'voice quality', 'variety', 'onset')
diffs[,'diff.(SD/Hz), 0%'] <- paste(round(-diffs0$diff, 2), '/', 
                                    round(-diffs0$diffHz, 0))
diffs[,'diff.(SD/Hz), 10%'] <- paste(round(-diffs10$diff, 2), '/', 
                                    round(-diffs10$diffHz, 0))
diffs[,'diff.(SD/Hz), 20%'] <- paste(round(-diffs20$diff, 2), '/', 
                                    round(-diffs20$diffHz, 0))
diffs <- diffs[order(diffs$onset),]
rownames(diffs) <- NULL
diffs
```

@tbl-diffs gives the predicted *F*~0~ differences between stops and nasals in different conditions and at different points in time; note that the trajectories are approx. 312 ms long on average, so the reported differences 20% into the trajectory correspond to differences just above 60 ms after the onset of voicing on average. 
The *F*~0~ differences are given both in terms of standard deviations and in terms of approximate Hz values, estimated by converting the *z*-scores back to raw frequency using the global mean in the data.

The results show that both unaspirated and aspirated stops cause C*F*~0~ effects in all conditions, although of differing magnitude and temporal extent.
*F*~0~ immediately following unaspirated stops is typically closer to aspirated stops than to nasals.
Unaspirated stops display C*F*~0~ effects of smaller magnitude and shorter temporal extent; this is empirically the case across all conditions, but for some conditions, the difference between the two stop series is negligible and not significant at any point in the trajectories.
Among Zealand speakers, the C*F*~0~ effects of unaspirated stops is very short-lasting in all conditions. 

If we consider words without stød, the predicted C*F*~0~ effects are stronger in the high pitch condition in terms of both magnitude and temporal extent. 
Interestingly, in this condition, the significant differences between the two stop series actually last longer than the difference between either stop series and nasals, presumably because of the dip after the initially high *F*~0~.
This is the case for both Jutland and Zealand speakers, although in aspirated stops, the attrition of C*F*~0~ effects in the low pitch condition is clearly more extensive for Jutland speakers. 
Unfortunately, as the pitch peak among Jutland speakers is quite delayed compared to previous descriptions, the results cannot be as straightforwardly explained with reference to dialectal differences as laid out in @sec-rq. 

The situation is different in words with stød. 
Here, there is no obvious across-the-board attrition of C*F*~0~ effects in the low pitch condition.
In fact, if anything, C*F*~0~ effects tend to last somewhat longer in the low pitch condition, although the magnitude of the effects is not greater in the low pitch condition.
This is especially clear for Jutland speakers.
When comparing focused words with and without stød, C*F*~0~ effects of aspirated stops in particular last much shorter in words with stød, and the magnitude of effects in aspirated stops is also much smaller.
While C*F*~0~ effects still last longer in aspirated stops than unaspirated stops, the two trajectories never differ significantly from each other in syllables with stød.

Note that in the stød words of Zealand speakers in the high pitch condition, words with nasal onsets appear to have an *F*~0~ dip about halfway through the trajectory that words with obstruent onsets do not share. 
The global pitch shape in general appears simpler in words with obstruent onsets. 
We have no hypotheses about this or explanations of it and will not discuss this further; it may be due to pitch tracking issues during the stød phase proper, which is after all expected to be much less modal among speakers from Zealand than speakers from Jutland.

In the following section, we will discuss the theoretical implications of these findings in light of the research questions and hypotheses posed in @sec-rq.

# Discussion {#sec-disc}

In this section, we discuss our findings in light of our three research questions in turn: in @sec-disc-rq1, the effect of having two series of voiceless stops, and what the results tell us about general mechanisms of C*F*~0~ in light of the existing studies of how the Danish laryngeal contrast is implemented; in @sec-disc-rq2, we attempt to tease apart the influence of high pitch and focus on C*F*~0~; and in @sec-disc-rq3, we discuss how competing demands on the larynx influence C*F*~0~.

## Multiple series of voiceless stops and C*F*~0~ {#sec-disc-rq1}

Across all contexts and varieties tested in this study, we find raised *F*~0~ after stop releases relative to a neutral baseline, and we find more raising after aspirated stops, i.e. /p/ > /b/ > /m/, where the difference between two stop series and the nasal is generally greater than the difference between the two stop series.
These findings reproduce the results of @petersen1983 in a greater range of contexts and with more naturalistic data.
The findings are in line with *H*1~c~, and are clear evidence against Kingson and Diehl's [-@kingston1994] characterization of Danish stops. 
Instead, the results support accounts of C*F*~0~ as a predominantly physiological reaction to gestures that inhibit voicing; this is captured in the phonological proposal by @goldstein1986], where the laryngeal contrast is underlyingly represented with continuous gestural scores. 
This proposal has the added advantage that it is also consistent with the intervocalic voicing patterns for Danish discussed by @puggaardrode2022labphon.
The ranking and internal relationships among segment categories in terms of C*F*~0~ are similar to recent results from Mandarin Chinese [@luo2018; @lo2022], another language which contrasts two series of voiceless stops and where intervocalic voicing is comparatively infrequent [@shih1999; @deterding2007].^[Note that this is particularly found in tonal contexts where *F*~0~ is initially high, and is not reproduced by @guo2022.]

@goldstein1986 do not offer many specific details about how this mechanism would work in practice.
@lofqvist1989 propose that it follows from tensing of the cricothyroid muscle, but our results do not support this, since the limited available evidence suggests that the cricothyroid is in rest position during the production of Danish /b d g/ [@hutters1985].
A more likely culprit is suppression of vocalis activity, followed by a sudden increase in activity near the vowel onset to re-initiate voicing, following e.g. @hoole2006; @hutters1985 finds evidence of this behavior in both series of stops, but especially /p t k/, which is in line with differences in magnitude and temporal extent of the reported C*F*~0~ effects.
Several studies have found a correlation between vocalis tension and *F*~0~ [e.g. @hirano1969; @atkinson1978; @kempster1988], although the correlation is generally weaker than that between the cricothyroid and *F*~0~.
According to Titze's body--cover model of pitch control [e.g. @titze1988; @titze1994], the cricothyroid and vocalis jointly control *F*~0~, and in the regular pitch range for speech, increased tension of the vocalis uniformly serves to increase *F*~0~.
This, of course, does not negate that the cricothyroid is a driver of C*F*~0~ in languages where that muscle is also the main driver of devoicing; the cricothyroid and the vocalis can both contribute to devoicing (although in different ways), so it is very much in line with the prediction of @goldstein1986 that they can both contribute to C*F*~0~ effects.

The effect of aspiration on *F*~0~ is not universal. 
While aspiration increases *F*~0~ in languages like English, German, and Swedish, as well as Danish, but lowers *F*~0~ in languages like Nepali and Bengali. 
In yet other languages, like Kurtöp, *F*~0~ appears to be raised after aspirated stops but less so than after plain voiceless stops [@hyslop2024].
Similarly, syllable final /h/ has been shown to cause *F*~0~ lowering in the preceding vowel in some languages, like Arabic and Itunyuso Trique [@hombert1979; @dicanio2012], whereas in other languages, e.g. Eastern Khmu, it causes *F*~0~ raising [@kirby2024].
In other words, glottal spreading (achieved through tensing of the posterior cricoarytenoids) does not appear to lead to a specific *F*~0~ pattern, but rather, the various C*F*~0~ affects are likely the result of other concomitant laryngeal gestures (such as cricothyroid tensing, or suppression followed by rapid activation of the vocalis).

It should be noted that a short *F*~0~ rise after voiceless unaspirated stops have also sometimes been noted in languages where there is no indication of an active devoicing gesture, predominantly English [@ohde1984; @hanson2009; @xu2021], but also at least empirically in some varieties of German [@pohnlein2023]. 
@xu2021 suggest that such an initial peak is found because the very first glottal cycles involve only the outer layer of the vocal folds, which vibrate at a higher natural frequency than the main vocal folds due to smaller mass, triggering *F*~0~ generated at the falsetto register. 
This is arguably unlikely to be the explanation for the Danish findings presented here, as it is unlikely that our cross-validation method for pitch tracking will have picked this up; Praat's autocorrelation method (using standard settings which penalize rapid changes in the predicted pitch contour) is probably not well-suited for capturing one or very few initial glottal cycles that are very different from subsequent cycles. 
Additionally, it is not clear how Xu and Xu's [-@xu2021] proposal capture the relatively large differences in onset *F*~0~ after the different stop series.

## C*F*~0~, stress, and intonation {#sec-disc-rq2}

The design of the current study was motivated by studies, predominantly from the 1980s, showing that the pitch peak placement in a stress group falls much earlier in Jutland Danish than Copenhagen Danish. 
While we do find an earlier pitch peak in Jutland Danish, both speaker groups appear to have peak delay in the current study, possibly due to incipient change that causes Jutland Danish to become more similar to Standard Copenhagen Danish, but it would require more research to state this with any degree of certainty.
In any case, this makes it difficult to directly test the hypotheses associated with our *RQ*2, i.e. to tease apart the influence of high pitch and focus on C*F*~0~ effects.
Luckily, our design affords some other ways to approach this.

Target *F*~0~ appears to be relatively low in the beginning of stressed syllables in both varieties. 
Even so, C*F*~0~ effects are stronger when there is a global intonational high pitch target -- at least in words with modal voice, i.e. words without stød.
We cannot straightforwardly interpret this as a synergy effect between a high pitch target and the direction of C*F*~0~ [as discussed by @chen2011jphon], as we would presumably not expect C*F*~0~ synergy unless it co-occurs with a pitch target that is *actually* high.
Another reason to doubt a straightforward *F*~0~ synergy account of C*F*~0~ enhancement is that we do *not* see C*F*~0~ enhancement in words with stød relative to words without, even though stød words *do* have a high initial pitch target. 

We do, however, find some evidence in favor of both *H*2~a~ and *H*2~b~: when the voice quality is modal, C*F*~0~ effects are generally stronger in speakers from Jutland, and they are generally stronger in global high pitch environments.
Effects are enhanced in speakers from Jutland (*H*2~a~) in spite of this speaker group displaying an unexpected peak delay in their pitch contours. 
The pitch contours do remain different across speaker groups though, with Zealand speakers displaying both a later peak and a steaper rise (cf. @fig-baselineTrajs).
Instead of supporting a straightforward *F*~0~ synergy account, we argue that the group differences arise because the perceptual salience of the pitch rise, i.e. the transition from low to high pitch, is higher in Zealand Danish.
This would explain why *F*~0~ after aspirated stops typically falls to a low position and then rises, unlike in Jutland Danish, where the results suggest that the pitch rise is optional after aspirated stops.
Meanwhile, effects are enhanced in a global high pitch environment (*H*2~b~).
We discussed above why this is likely not due to *F*~0~ synergy per se, since the local pitch target is not high in modal syllables, and the enhancement disappears in stød syllables where there *is* a local high pitch target. 
A more likely explanation is that *some* sources of high *F*~0~, but not all, serve to enhance C*F*~0~, and this depends not on *F*~0~ itself but rather synergy at the level of laryngeal implementation.

## C*F*~0~ and other demands on the vocal folds {#sec-disc-rq3}

The patterns in the results that we have yet to discuss can arguably be explained if we assume that C*F*~0~ effects can be constrained if there are pre-existing demands on the vocal folds. 
As discussed in @sec-universality, there is ample support for this from tone languages, where C*F*~0~ effects often vary in scope, magnitude, and even direction based on the tonal context [for an overview, see @kirby2018jphon].

As mentioned above, we do not find direct evidence of a synergistic effect where C*F*~0~ is enhanced in high pitch contexts, as discussed by e.g. @chen2011jphon.
There is certainly no evidence for this in words with stød, where there is attrition of C*F*~0~ effects even though they consistently have higher *F*~0~ onset than words without it. 
In Fischer-Jørgensen's [-@fischerjorgensen1987; -@fischerjorgensen1989] physiological study of stød, the pitch contour in syllables with stød can straightforwardly be explained with reference to activation level of the cricothyroid muscle. 
Since the cricothyroid does not appear to play a major role in regulating the laryngeal contrast, it stands to reason that there is no strong synergistic effect of cricothyroid activation.
If we assume that the vocalis is a driver of C*F*~0~ effects in Danish, it further stands to reason why effects would be attenuated in the stød context: following Titze's body--cover model (see @sec-disc-rq1), there is a complex interaction between the influence of cricothyroid and vocalis tension in pitch control, such that the effect of increased vocalis activity on pitch is reduced if it co-occurs with strong cricothyroid activity [@titze1989]. 

In addition to strong initial cricothyroid activity, Fischer-Jørgensen [-@fischerjorgensen1987; -@fischerjorgensen1989] also finds that the second phase of stød is accomplished with strong coactivation of the vocalis and lateral cricoarytenoids. 
Comparing the results of @hutters1985 and Fischer-Jørgensen [-@fischerjorgensen1987; -@fischerjorgensen1989], the activation of the vocalis required for the second stød phase is much stronger than the peak found immediately after a voiceless stop.
This corresponds well to the finding that the vocalis tension, especially at high levels, can either raise or lower *F*~0~ depending on the overall state of the glottis [@titze1989]. 
Very simply put, stød places a range of complicated phonological demands on the larynx, and our results suggest that this reduces the capability of C*F*~0~ effects to be temporally extensive.
Such a mechanism can also help explain why C*F*~0~ effects appear to be *more* extensive in when stød is found in the low pitch condition; the pitch range is generally reduced here, so it is likely that the laryngeal adjustments required for stød are also weaker, allowing greater range for the C*F*~0~ effects.
These results support *H*3~b~.

# Conclusion

In this paper, we have revisited co-intrinsic pitch effects in Danish, a language with two series of contrastive voiceless stops. 
We found that both series of stops increase the pitch of the following vowel relative to a neutral baseline, although the aspirated and unaspirated series differ in terms of magnitude and temporal extent.
This result challenges accounts of co-intrinsic pitch as primarily a result of cricothyroid tensing to enforce voicelessness, since previous research suggests that the cricothyroid is essentially in rest position during the production of Danish unaspirated stops.
Our results are more in line with co-intrinsic pitch being caused by a sudden activation of the vocalis muscle after a period of suppression, although the exact biomechanical cause of co-intrinsic pitch in Danish is a topic we leave for further investigation.

In order to test how co-intrinsic pitch is affected by the phonological context in various ways, we varied the intonational pitch context and phonological voice quality of items, and recruited speakers of different varieties of Danish which do not appear to differ in the implementation of laryngeal contrast, but differ in terms of prosodic phonology.
The upshot is that we do not find evidence of co-intrinsic pitch being enhanced in high pitch environments as has previously been suggested, but rather we find evidence that co-intrinsic pitch is inhibited or strengthened based on the phonological source of high pitch, presumably because the laryngeal mechanisms inducing high pitch differ.
