---
title: "Danish CF0"
subtitle: "maybe"
authors: 
  - name:
      given: 'Rasmus'
      family: 'Puggaard-Rode'
    affiliations:
      - id: lmu
        name: 'Institute for Phonetics and Speech Processing, <br> Ludwig Maximilian University, Munich'
    email: 'mailto:r.puggaard@phonetik.uni-muenchen.de'
    orcid: '0000-0003-4522-9987'
  - name:
      given: 'James'
      family: 'Kirby'
    affiliations:
      - ref: lmu
    email: 'jkirby@phonetik.uni-muenchen.de'
    orcid: '0000-0002-0502-5245'
  - name:
      given: 'Nicolai'
      family: 'Pharao'
    affiliations:
      - id: cph
        name: 'Department of Nordic Studies and Linguistics, <br> University of Copenhagen'
    email: 'nicolaip@hum.ku.dk'
    orcid: '0000-0002-6828-9061'
date: today
format:
  html:
    theme: cosmo
    code-fold: true
    toc: true
    toc-location: left
    reference-location: margin
    df-print: kable
  pdf:
    include-in-header:
      text: |
        \usepackage{float}
    mainfont: Times New Roman
    sansfont: Times New Roman
    df-print: paged
    execute:
      echo: false
    fig-dpi: 300
    fig-height: 4
    link-citations: true
    keep-tex: true
    prefer-html: true
bibliography: references.bib
csl: css/journal-of-linguistics.csl
number-sections: true
abstract: >
  Abstract goes here.
---

# Introduction

It is well-established that some segments exert a localized influence on pitch, which is superimposed on an overall pitch contour.
For example, pitch is higher during high vowels than during low vowels, and pitch is higher immediately following voiceless consonants than during voiced consonants.
Vowel-intrinsic *F*~0~ was first described more than a century ago [@meyer1897] and appears to be essentially universal [@whalen1995; @ting2023], although it does not appear to have phonological consequences or to play a role in sound change.
Co-intrinsic *F*~0~ of consonants [which we refer to as C*F*~0~ following e.g. @dicristo1986], i.e. the effect that consonants have on the *F*~0~ of surrounding segments, has also been documented in many languages with various kinds of laryngeal contrasts in obstruents, but the effects are rather more variable than vowel-intrinsic *F*~0~ depending on e.g. the exact implementation of the laryngeal contrast and other aspects of the phonological system [e.g. @chen2011jphon; @kirby2018jphon].
However, C*F*~0~ is often implicated in theories of phonological representation, playing a crucial role in how the feature [voice] is defined by e.g. @keating1984language and @kingston1994, and how the phonological element |H| is defined by e.g. @harris1994 and @backley2011.
C*F*~0~ is also assumed to play a major role in tonogenetic sound change processes, where C*F*~0~ is often assumed to have transphonologized into lexical tone with concomitant loss of the voiced--voiceless contrast [@hyman1976; @kirby2017].

There is a substantial body of literature on C*F*~0~, but several open questions remain about the underlying mechanisms.
For example, it remains unclear to which extent C*F*~0~ is actively controlled or an automatic by-product of e.g. laryngeal gestures aimed at inhibiting phonation.
If it is primarily the latter, it is still not clear what exactly those gestures might look like.
It also remains an open question how exactly C*F*~0~ interacts with other more and less localized sources of prosodic modification. 

In this paper, we approach some of these open questions using Danish as a test case.
C*F*~0~ has already been investigated in Danish [@jeel1975; @petersen1978aripuc; -@petersen1983]; these studies suggest that C*F*~0~ is indeed found in Danish [although cf. @fischerjorgensen1969], but the studies have methodological limitations that make them unsuitable for approaching the aforementioned open questions. 
Perhaps just as importantly, these studies are cited not infrequently in favor of arguments that we are not convinced the studies can actually support, which makes a larger-scale replication study valuable.

Danish is an interesting case in terms of C*F*~0~ for at least the following reasons:
1) The laryngeal contrast in stops is somewhat unusual, contrasting a series of voiceless aspirated stops [pʰ tʰ kʰ] with a series of voiceless unaspirated stops [p t k] [@hutters1985; @puggaardrode2022labphon]. 
Unlike the corresponding unaspirated stops in most other Germanic languages [e.g. @beckman2013], the Danish voiceless unaspirated stops are *actively* devoiced, in the sense that voiceless realizations are the norm even in intervocalic position [@puggaardrode2022labphon], and this is enforced through (light) glottal spreading [@fischerjorgensen1974; @hutters1985].
2) The physiology of the Danish laryngeal contrast in obstruents is -- all things considered -- studied very extensively, using fiberoptic laryngoscopy [@fischerjorgensen1969; @hutters1978; -@hutters1984; -@hutters1985], electromyography [@fischerjorgensen1974lips; @hutters1984; -@hutters1985], various measures of airflow and air pressure [@fischerjorgensen1969], among others, making a comparison between (acoustic) C*F*~0~ patterns and articulation reasonable.
3) There is regional variation in Danish in the location of the pitch peak relative to stress [e.g. @thorsen1981; @thorsen1982; -@thorsen1988; @gronnum1989; -@gronnum1990], making it possible to tease apart the respective influence of contrastive focus and high pitch on C*F*~0~, by comparing varieties where pitch peak and stress coincide with varieties where they do not.
4) Danish has a voice quality contrast (known as *stød*) which is, among other things, cued by pitch differences immediately after an initial consonant [e.g. @petersen1973; @fischerjorgensen1989; @pena2022], making it possible to investigate how C*F*~0~ interacts with other localized pitch modifications.

The results show that both series of stops raise *F*~0~, although the temporal extent and magnitude of the effect differs.
Given what we know about the articulation of these stops and how voicelessness is implemented, these results challenge some existing theories of the biomechanical source of C*F*~0~; the relevant literature is covered in the next sections. 
We do not find evidence of high pitch enhancing C*F*~0~ -- if anything, there is a tendency for the reverse effect, or at least that C*F*~0~ is weaker when there are competing phonological demands on pitch -- but we do find effects of focus enhancing C*F*~0~.

The following two subsections review the general literature on C*F*~0~, especially pertaining to the open questions we are interested in here, and the relevant literature on the Danish laryngeal contrast, regional variability in stress and pitch peak alignment, and the implementation of stød. Our research questions and hypotheses are presented in @sec-rq.
Our experimental design, participants, recording methodology, and statistical methodology are presented in @sec-methods. 
We present the results of the study in @sec-results, and discuss them in light of our research questions and hypotheses in @sec-disc.

## Co-intrinsic *F*~0~

### General overview {#sec-cf0overview}

C*F*~0~ was first studied in English by @house1953, and has since been found in a very wide range of languages [see overviews in e.g. @kirby2018jphon; @ting2023].
C*F*~0~ effects should be thought of as deviations from an overarching pitch contour, so when studying them, it is crucial to ensure that they are compared to a suitable baseline, and that the prosodic context is controlled.
Modally voiced sonorant consonants are not expected to cause *F*~0~-perturbations, since their articulatory configuration should not provide any obstructions to airflow, so unlike in e.g. voiced stops [@sole2018], voicing proceeds without making articulatory adjustments to support it.
For this reason, nasals in particular are often recorded in a comparable context in studies of C*F*~0~, and *F*~0~ following nasals serves as a baseline condition [e.g. @hanson2009; @kirby2016; @ladd2018].
The prosodic context is typically controlled by having items produced in citation form [e.g. @kirby2020jasa; @gao2024] or embedding them in a controlled carrier phrase [e.g. @lehiste1961; @silverman1986; @hanson2009; @kirby2016; @gao2019].
@xu2021 further argue that it is important to compare equivalent time points within the syllables of interest, stressing that pitch peaks in intonation contours are not necessarily timed to the onset of voicing after a stop; if pitch peaks are e.g. timed relative to stop releases and *F*~0~ is compared at voicing onset, it will inevitably result in an overestimation of the temporal extent of C*F*~0~ [see also @wong2007]. 
Xu & Xu suggest that pitch peaks are *always* timed relative to stop releases, but we argue in @sec-methods-domain that this may well be language-specific, and that pitch peaks in Danish appear to be timed relative to the onset of voicing.

The directionality of C*F*~0~ has been debated a great deal. 
Some have suggested that *F*~0~ is *raised* following voiceless stops due to gestures that inhibit voicing, such as stiffening or vertical tensing of the vocal folds [@halle1971; @hombert1979], in particular tensing of the cricothyroid muscle [@lofqvist1989; @hoole2011], or due to abrupt activity of the vocalis muscle to initiate voicing [@hoole2006; @hoole2011].
Alternatively, it has been suggested that *F*~0~ is *lowered* following voiced stops due to gestures that promote closure voicing, such as larynx lowering [e.g. @ewan1974; @ewan1976] with concomitant vocal fold slackening [@ohde1984; @honda1999], or that *F*~0~ lowering in this context is an active adjustment to perceptually enhance the voicing contrast [@kingston1994; @kingston2007].
When stops are compared to a suitable sonorant baseline, results arguably mainly support C*F*~0~ effects in the direction of *F*~0~ raising, and not lowering [@hanson2009; @kirby2016].
This is in accordance with the suggestion that *F*~0~ is lowered due to gestures that reduce intraoral air pressure.
*F*~0~ tends to be very comparable after sonorants and voiced stops, although @kirby2016 do find evidence of *F*~0~ lowering during the closure of voiced stops in French and Italian, and @maspong2024 find evidence of this effect extending into the initial parts of the vowel in Italian; this suggests the possibility of different mechanisms governing *F*~0~ raising after voiceless stops and *F*~0~ lowering after voiced stops.

An alternative explanation holds that the effects are caused by intraoral air pressure differences after voiced and voiceless stops [e.g. @ladefoged1967; @ohala1973; @hombert1976]; this explanation is attractive since it in principle accounts for both *F*~0~ lowering and *F*~0~ raising, but it arguably fails to predict the scope of *F*~0~ modifications, especially that *F*~0~ raising can be quite long-lasting [see @hombert1979]. 
An aerodynamic account would also predict covariation between especially positive voice onset time (pVOT) and the extent of *F*~0~ raising, which many studies do not find evidence for [e.g. @dmitrieva2015; @kirby2016; @pinget2023], although cf. @shultz2012 and @kirby2015.

### Universality and phonological implications {#sec-universality}

C*F*~0~ appears to be relatively independent of how exactly a laryngeal contrast is implemented.
The effects are found in 'aspiration languages', where the main cue to the contrast is post-aspiration in the voiceless series of stops, such as English [e.g. @house1953] and German [e.g. @kohler1982; @kirby2020icphs], and in 'true voice languages', where the main cue to the contrast is the presence of glottal pulsing during the closure in the voiced series of stops, such as Italian [@kirby2015; -@kirby2016], French [ibid., @fischerjorgensen1969], Spanish [@dmitrieva2015], and Dutch [@lofqvist1989; @pinget2023], but also in languages which primarily distinguishes stops through closure duration, such as Swiss German [@ladd2018] and Salentino [@burroni2022], and in languages where both pre-voicing and aspiration ostensibly plays a role in the contrast, such as Swedish [@kirby2023icphs; although cf. @ting2023].^[Swedish is often considered to have an 'overspecified' laryngeal contrast between pre-voiced and post-aspirated stops [e.g. @helgason2008; @beckman2011], but several studies have failed to find evidence of consistent pre-voicing [@keating1983; @sundberg1999; @lundeborg2012; @kirby2023icphs].]

Many languages have simple, two-way laryngeal contrasts in their stop consonants that can in principle be captured with a binary phonological feature like [±voice], but there is substantial variation in how exactly the contrast is realized, e.g. with post-aspiration, pre-voicing, gemination etc. as discussed above. 
Because of this, and because of the relative stability of C*F*~0~ as a cue to these contrasts, C*F*~0~ has sometimes been taken as an invariant phonetic cue to a phonological [±voice] feature [@keating1984language; @kingston1994].
This is in opposition to the 'laryngeal realist' framework [e.g. @iverson1995; @honeybone2005; @beckman2013] for representing laryngeal contrasts, which proposes that aspiration-based contrasts (represented with a feature such as [spread glottis]) and voicing-based contrasts (represented with a feature such as [voice]) show different phonological behaviors; see @kirby2018poznan for further discussion of this point.

Another phonological implication of C*F*~0~ is that it is a main driver in tonogenetic processes, i.e. the development of lexical tone [for an overview, see @kirby2017]. 
C*F*~0~ effects originating in onset laryngeal contrasts have often led to splits in languages that had already developed tones from other sources, but there are also examples from non-tonal languages where onset laryngeal contrasts seemingly transphonologize into primarily *F*~0~-based contrasts, such as Korean [@kang2013; @bang2018] and Afrikaans [@coetzee2018].
These processes suggest that even if C*F*~0~ starts out as an automatic physiological by-product of laryngeal adjustments, they are also necessarily perceptible [see e.g. @whalen1993] and can necessarily come under speaker control even if they are not so initially. 

A complicating factor is that this relationship between 'voicelessness' and *F*~0~ is often less straightforward in languages with more complicated laryngeal contrasts in obstruents, or languages which already have lexical tone.
While post-aspiration consistently seems to raise *F*~0~ in non-tonal languages with simple two-way contrasts, it has sometimes been shown to lower *F*~0~ in languages which contrast *both* voicing and aspiration, such as Nepali and Bengali [@clements2007; @reetz2019].
In languages with lexical tone, results have been much more mixed.
In Mandarin Chinese and Shuangfeng Xiang, post-aspiration generally lowers *F*~0~ [@xu2003; @shi2020diss], whereas in Khmer, Thai, Vietnamese, and Taiwanese, post-aspiration generally raises *F*~0~ [@lai2009eal; @kirby2018jphon]; in all of these languages, the scope of C*F*~0~ depends greatly on tonal context, and in other languages such as Wu and Cantonese, even the direction of C*F*~0~ can depend on tonal context [e.g. @francis2006; @chen2011jphon; @shi2020jasa].
Two plausible reasons for these discrepancies are that languages use different articulatory mechanisms to implement post-aspiration, and that the range of possible C*F*~0~ effects are limited when the phonological context places competing demands on the larynx, e.g. to produce a certain pitch level.
As we will see below, Danish is an intriguing case study here, as 1) the articulatory mechanisms that produce post-aspiration are quite well-described, and 2) the voice quality contrast already places certain demands on the larynx with respect to pitch level.

### Focus and synergistic effects

Several studies have found that the scope of C*F*~0~, in terms of both magnitude and temporal extent, is larger in environments with high pitch, such as when the word in question is uttered in a focus condition [e.g. @kohler1982; @hanson2009; @kirby2016].
These two effects -- *viz.* high pitch and focus -- are difficult to tease apart. 
Focus has been shown to generally increase pitch range, including in tonal languages [e.g. @xu1999; @xu2005], which may suggest that focus is the driving force, especially if C*F*~0~ is assumed to be under speaker control.
On the other hand, the results of @chen2011jphon suggest that there is synergy between C*F*~0~ and other pitch targets: co-intrinsic *F*~0~ raising is strengthened in high pitch environments, while co-intrinsic *F*~0~ lowering is strengthened in low pitch environments. 
On the basis of this, she hypothesizes C*F*~0~ effects are more prominent when there is congruency between the vocal fold stiffness required by a tonal pitch target and that required by a consonant.
These effects are both strengthened under prosodic focus, suggesting that they may be the result of gestural enhancement. 
There is articulatory evidence that supralaryngeal gestures in stop production are enhanced under focus [@cho2006], and acoustic evidence suggests that stress increases pVOT in aspirated stops [@lisker1967], including in various varieties of Danish [@puggaardrode2022jphon; -@puggaardrode2024jphon], suggesting that laryngeal gestures related to stop production are also strengthened when stressed.
As we will see below, variation in the intonational phonology of Danish makes it a particularly intriguing case for teasing apart the respective effects of high pitch and focus on C*F*~0~.

## Previous work on Danish {#sec-review-danish}

### The laryngeal contrast in stops

Danish stops display a two-way laryngeal contrast between /b d g/ and /p t k/.
In simple onset position before a full vowel, /b d g/ are voiceless unaspirated [p t k] and /p t k/ are voiceless aspirated [pʰ tʰ kʰ] [@fischerjorgensen1954]. 
Aspiration-based stop contrasts are the norm in Germanic languages [e.g. @iverson1995], but Danish is unusual in how much closure voicing is repressed in /b d g/.
Aspiration is of course regulated with a glottal spreading gesture, but several previous studies have shown that /b d g/ are *also* produced with a glottal spreading gesture, albeit of a smaller magnitude [@fischerjorgensen1969; @frokjaerjensen1971; @fischerjorgensen1974lips; @hutters1978; -@hutters1984; -@hutters1985]. 
Electromyographic studies have shown that this gesture is likely an active adjustment, in the sense that it is accomplished through tensing of the posterior cricoarytenoid muscles [@fischerjorgensen1974lips; @hutters1985], and not simply an aerodynamic by-product of the consonant--vowel transition, as originally proposed by @frokjaerjensen1971.
This glottal opening gesture serves to counteract voicing, even in e.g. intervocalic position [@puggaardrode2022labphon].
No such gesture is found in English /b d g/ [@sawashima1970], although a similar gesture is found in Icelandic /b d g/ [@petursson1976], where it likely also serves as an active devoicing gesture.

Glottal spreading, accomplished by tensing the posterior crycoarytenoids and suppressing activity in the interarytenoids, seems to be the main driver of devoicing in the production of Danish stops. 
Another potential driver, according to @hutters1985 and following e.g. @hirose1974, is suppressed activity in the vocalis muscle, which may reduce slackness in the vocal folds and hence impede voicing. 
Danish /p t k/ in particular show an abrupt increase in vocalis activity approaching the vowel onset; recall that @hoole2006 and @chen2011jphon discuss this as a possible mechanism behind C*F*~0~.
@hutters1985 only has stable cricothyroid measurements from a single speaker, and these hint that the cricothyroid is essentially in rest position during the production of /b d g/, while activity is slightly increased in /p t k/. 
We cannot draw any strong conclusions from this, but it certainly suggests that the cricothyroid is *not* a main driver in Danish stop devoicing.
If C*F*~0~ is indeed primarily caused by cricothyroid tensing, as suggested by @lofqvist1989, then we may expect to see relatively limited effects after /p t k/ and no effects at all after /b d g/. 

The phonological representation of the Danish laryngeal contrast has been discussed extensively in the literature.
With the exception of @kohler1984, these approaches all suggest that the contrast should be represented primarily in terms of a relatively abstract [voice] feature [@rischel1970grad; @keating1984language; @kingston1994], or in terms of the presence or aspiration, either with a relatively concrete [spread glottis] feature [@iverson1995; @basboll2005; @beckman2013], or through other means of representation [@goldstein1986; @puggaardrode2022labphon; @puggaardrode2023qcv].
Different analyses make different assumptions and try to account for different aspects of the sounds' behavior.
When aspiration is concretely taken to be the distinguishing feature, analyses aim to account for the most common realizations of the sounds, and phonological processes such as progressive devoicing of following sonorants. 
When [voice] is more abstractly taken to be the distinguishing feature, analyses aim to account for e.g. the semivocalic allophones of /b d g/ in weak prosodic positions [for discussion of this, see @horslund2022acta].^[@kingston1994 also assume that the feature [voice] accounts for the prevalence of intervocalic voicing in Danish, but note that the corpus study of @puggaardrode2022labphon show that intervocalic voicing is actually not at all widespread in Danish.]

Both @kingston1994, who assume that an abstract [voice] feature manages the laryngeal contrast, and @goldstein1986, who assume that various degrees of phonologized glottal spreading manages the laryngeal contrast, claim that their analyses can account for the observed C*F*~0~ effects.
As we will see below, they actually account for different directions of C*F*~0~ effects, and the phonetic studies that they aim to formally explain are arguably not clear enough to warrant phonological implications.
For a more extensive overview of existing literature on Danish stops and their phonological representation, see @puggaardrode2023diss.

### Segment-intrinsic *F*~0~

The first to touch on C*F*~0~ in Danish was Fischer-Jørgensen [-@fischerjorgensen1968; -@fischerjorgensen1969]. 
She writes that there is no C*F*~0~, ostensibly on the basis of recordings of a single Danish--French bilingual speaker, but she does not actually report the results of a C*F*~0~ study.

The topic was taken up again by @jeel1975, who measured 6 speakers reading words with initial stops and other obstruents in identical carrier phrases; for four of these speakers, words with initial sonorants were also recorded.
She finds that *F*~0~ immediately at the onset of the following vowel is consistently higher after /p t k/ than /b d g/; for those 4 speakers where stops can be compared to a sonorant baseline, the results are somewhat mixed, but *F*~0~ is shown to be higher or very similar after /b d/ compared to /m n/.
In several cases, the difference between sonorants and unaspirated stops is found to be greater than the difference between unaspirated and aspirated stops.

@petersen1978aripuc measured *F*~0~ for three speakers reading nonce words of the type [CVˈCVCV] (where V is one of the three corner vowels) embedded in a carrier sentence, reusing materials from a previous study on vowel-intrinsic *F*~0~ [@petersen1978jphon].^[@petersen1978jphon quite clearly finds the 'expected' effect of higher *F*~0~ in high vowels compared to low vowels.]
Only stop-initial words were measured, and due to the nature of the nonce words, the ecological validity of this study is rather low; the study consistently finds higher *F*~0~ after /p/ compared to /b/ in the medial stressed syllable, although the magnitude of the effect is frequently quite small.
He does not find any consistent differences between /b/ and /p/ in the pretonic and posttonic unstressed syllables.
In a later study, @petersen1983 measured three speakers reading nonce words of the type [CVˈfi] in a carrier sentence.
In this study, stops are compared with sonorants and other obstruents. 
The results show that *F*~0~ is initially raised after /p t k/ compared to /b d g/, and that both series of stops show raised *F*~0~ compared to nasals; in fact, the difference between unaspirated stops and nasals is found to initially be a fair bit greater than the difference between the two stop series, but at the end of the syllable, the effect of aspiration is typically greater than the difference between unaspirated stops and nasals. 
@petersen1983 compares *F*~0~ with measurements of larynx height, showing that there is no straightforward relationship between the two. 

@goldstein1986 cite both @jeel1975 and @petersen1983 in arguing for continuous gestural underlying representations of laryngeal contrast, claiming that their framework can account well for the raised *F*~0~ of both stop series relative to nasals, and for the difference in *F*~0~ between the two stop series.
@kingston1994, on the other hand, cite both sources as evidence that Danish /b d g/ are phonologically represented with [+voice], which acts as an *F*~0~ depressor. 
We believe that this is a misinterpretation of the studies, since the studies suggest that both series of stops actually raise *F*~0~ relative to a neutral baseline.

### Stød production and *F*~0~

Standard Copenhagen Danish has a distinctive voice quality typically refered to as *stød*, which is realized over entire sonorant syllable rhymes [e.g. @gronnum2007].^[This section gives an overview of existing literature on the phonetics of stød as pertains to the present study; for a recent extensive general overview, see @gronnum2023.]
Stød in Copenhagen Standard Danish is generally acknowledged to be biphasic [@smith1944], where the first phase exhibits raised *F*~0~ relative to syllables without stød [e.g. @vihman1971; @petersen1973; @pena2022], and the second phase typically exhibits a drop in *F*~0~, a drop in intensity, and creaky, irregular phonation [e.g. @fischerjorgensen1987; -@fischerjorgensen1989; @hansen2015].
While early research suggested that the first phase played little role in the perception of stød [@thorsen1974], more recent research suggests that the first phase is actually particularly crucial to perceiving the voice quality contrast [@pena2023], and that words with and without stød are distinguished fairly well based on acoustic cues 
in the first phase alone [@pena2024], particularly *F*~0~ [@siem2023diss].

Articulatory work shows that the second phase of stød is produced with laryngeal constriction [@esling2019], in particular contraction of both the ventricular folds and the anterior part of the vocal folds [@fischerjorgensen1987; -@fischerjorgensen1989], leading to a reduced contact quotient between the folds relative to words without stød [@siem2023diss]. 
The first stød phase has further been found to be accompanied by *stronger* articulation in several ways: compared to syllables without stød, oral airflow is stronger [@smith1944], subglottal air pressure is higher, and the palatal contact area is larger [@fischerjorgensen1987; -@fischerjorgensen1989].
Electromyographic investigations suggest that the second phase is initiated with brief but strong activation peaks of the vocalis and lateral cricoarytenoids some 50 ms after the vowel onset, while the first phase is initiated with a strong activation peak of the cricothyroid prior to the onset of the vowel [@faaborgandersen1957; @fischerjorgensen1974stod; @fischerjorgensen1987; -@fischerjorgensen1989]; recall that the cricothyroid is likely partially responsible for devoicing in /p t k/ but not in /b d g/.
@gronnum2007 interpret the laryngeal control mechanisms as evidence of a single ballistic laryngeal gesture timed relative to the beginning of the syllable rhyme which accounts for both phases, while @pena2022 interprets them as evidence of two gestures corresponding to the two phases, the first timed relative to the vocalic onset, and the latter timed relative to the center of the syllable rhyme.

There is substantial regional variation in how stød is realized and how it patterns phonologically in Danish [e.g. @ejskjaer1990; -@ejskjaer2006].
Most of this variation is not relevant to our purposes here, but it is worth mentioning that stød in Aarhus Danish appears to be predominantly tonal [@kyst2008]; unlike in Standard Copenhagen Danish, syllables with and without stød are poorly distinguished using acoustic measures of spectral slope and harmonics-to-noise ratio, and the contact quotient does not differ [@siem2023diss].
There is also a much lower tendency for following syllables to have creaky phonation in Aarhus Danish relative to Standard Copenhagen Danish [@siem2023icphs].
The pitch pattern in the first phase, however, appears to be essentially the same: *F*~0~ at the vocalic onset is higher in syllables with stød, and these syllables display a falling pitch pattern.
A very brief overview of relevant parts of Danish geography is given in the following section.

### Stress and pitch peak alignment {#sec-stresspitch}

While Danish has been subject to extensive dialect leveling in the past century or so [e.g. @pedersen2003], prosodic cues such as the alignment between stress and pitch are still fairly distinct between major regions of Denmark [@tondering2020].
In Standard Copenhagen Danish, stress in disyllabic words is cued with low falling pitch on the tonic syllable and high rising pitch on the post-tonic syllable [e.g. @thorsen1978; -@thorsen1979; -@thorsen1983; @dyhr1993; @petersen2001; @tondering2008].
This is quite unlike in Jutland Danish, where stress is typically cued with high rising pitch on the tonic syllable [e.g. @thorsen1981; @thorsen1982; -@thorsen1988; @gronnum1989; -@gronnum1990; @jespersen2021].

Denmark can be seen in @fig-mapDK, where the two main dialect areas under consideration in this study are colored in. 
Jutland is the peninsula in Western Denmark; note that Northern Jutland is not colored and is kept out of this study, because we have reason to believe that the laryngeal contrast in stops may be implemented differently here [see e.g. @puggaardrode2024jphon].
The colored-in island in Eastern Denmark is Zealand.^[The smaller islands south of Zealand are in some respects part of the same administative unit as Zealand, but no speakers recorded for this study come from these islands.]
Since a few of the speakers recorded for the study are from outside the greater Copenhagen area but distinctly have the stress--pitch peak alignment associated with Standard Copenhagen Danish, we conceptualize this variety instead as *Zealand Danish* here; see @sec-speakers.

::: {.content-visible when-format="html"}
::: {.callout-note collapse="true"}

## Generating maps with `eurostat` and `ggplot2`

The map in @fig-mapDK is made in R using the packages `ggplot2` and `eurostat`. `eurostat` has coordinates for the outlines of a bunch of countries and internal administrative areas at various levels of granularity. These coordinates are loaded into R using the `get_eurostat_geospatial()` function as below. 

I set `resolution = '1'` to get the highest possible resolution. `nuts_level` refers to the Eurostat NUTS level (**n**omenclature of **t**erritorial **u**nits for **s**tatistics); this determines the granularity of the regions that the maps are divided into. We use `3` here, because `2` would give us official regions of Denmark, which for various reasons isn't very useful. It'd actually be nice with an even smaller granularity, but `3` are the smallest available units.

```{r Get geospatial data}
#| code-fold: false
#| error: false
#| warning: false

library(tidyverse)
library(patchwork)
library(eurostat)

geodata <- get_eurostat_geospatial(resolution = '1', nuts_level = 3)
```

We now downloaded a huge object with small administrative units for all available countries. This can be filtered on a by-country basis by using the `CNTR_CODE` column in the `geodata` object. 

Here we grab the outlines of Denmark, and also the bordering countries Germany and Sweden.

```{r Filter geospatial data}
#| code-fold: false

geodataDK <- geodata[geodata$CNTR_CODE=='DK',]
geodataDE <- geodata[geodata$CNTR_CODE=='DE',]
geodataSE <- geodata[geodata$CNTR_CODE=='SE',]
```

Administrative areas can be filtered by using the `NUTS_NAME` column in `geodata`. The available areas in Denmark are the following:

```{r View Danish NUTS}
#| code-fold: false

unique(geodataDK$NUTS_NAME)
```
So we can use differential coloring for different areas, we further subdivide `geodataDK` into relevant parts of Jutland `jAreas`, Zealand `zAreas`, and `restofDK`. (Unfortunately the large area `Vest- og Sydsjælland` includes Lolland--Falster south of Zealand, but for this study those aren't actually conceptualized as part of Zealand).

```{r Filter Danish NUTS}
#| code-fold: false

jAreas <- c('Sydjylland', 'Vestjylland', 'Østjylland')
jutland <- geodataDK[geodataDK$NUTS_NAME %in% jAreas,]
zAreas <- c('Nordsjælland', 'Østsjælland', 'Vest- og Sydsjælland', 
            'Byen København', 'Københavns omegn')
zealand <- geodataDK[geodataDK$NUTS_NAME %in% zAreas,]
restofDK <- geodataDK[!geodataDK$NUTS_NAME %in% c(jAreas, zAreas),]
```

The figure is now a `ggplot` object which makes heavy use of the non-standard `geom_sf` class. We can use those because `geodata` and the derived objects are not traditional data frames:

```{r View geospatial class}
#| code-fold: false

class(geodata)
```

The `sf` object class (for geospatial data) makes it possible to store complex numeric vectors in something like a data frame cell, and these can then be plotted as polygons with `ggplot()` using the `geom_sf()` function. For the map, we create a blank plotting area with a light blue background (for the ocean!), color in the areas that we've filtered out above differentially, and embellish the plot using regular geographical coordinates.

```{r Generate map plot}
#| code-fold: false

mapDK <- ggplot() + 
  geom_sf(data=jutland, fill='wheat') +
  geom_sf(data=zealand, fill='thistle1') + 
  geom_sf(data=restofDK, fill='lightgrey') +
  geom_sf(data=geodataDE, fill='lightgrey') +
  geom_sf(data=geodataSE, fill='lightgrey') + 
  annotate(geom='point', x=12.3, y=55.4, size=4, col='red') +
  annotate(geom='label', x=12.3, y=55.1, label='Copenhagen\n(Zealand)') +
  annotate(geom='point', x=10.2, y=56.1, size=4, col='red') + 
  annotate(geom='label', x=10.2, y=55.8, label='Aarhus\n(Jutland)') +
  xlim(8, 13) +
  ylim(54.7, 58) + 
  theme_bw() +
  theme(panel.background=element_rect(fill='lightblue'),
        panel.border=element_blank(),
        panel.grid.major=element_blank(),
        panel.grid.minor=element_blank(),
        axis.text.y=element_blank(),
        axis.text.x=element_blank(),
        axis.title.y=element_blank(),
        axis.title.x=element_blank(),
        axis.ticks=element_blank())
```

:::
:::

```{r}
#| label: fig-mapDK
#| fig-cap: Map of Denmark showing roughly the two dialect areas considered in this study (the Jutland peninsula to the west, and the island of Zealand to the east) and highlighting the two cities where recordings took place.

mapDK
```

This particular pattern of variation gives a unique opportunity to tease apart the influences of stress (or, in our case, focus) and pitch on C*F*~0~. 
If the previous findings of more extensive C*F*~0~ under stress are actually due to synergistic effects of multiple sources of pitch raising, we should not find any influence of stress on C*F*~0~ in Zealand Danish. 
However, if the findings are actually due to stress and not pitch, we should find an influence of stress on C*F*~0~ in either variety.

## Research questions {#sec-rq}

*RQ*1: What will C*F*~0~ look like in a language which contrasts two series of voiceless stops? How does this inform discussions about the phonological representation of Danish stops?

* *H*1~a~: /b d g/ are underlyingly represented as [+voice], which acts as an *F*~0~ depressor even if the stops are phonetically voiceless, and the *F*~0~ levels following consonants is ranked /p ~ m/ > /b/. This would be evidence in favor of the proposal of @kingston1994 regarding the underlying representation of Danish stops.
* *H*1~b~: The Danish stops do not exhibit C*F*~0~, since neither series is voiced. This would be evidence in favor of the proposal of e.g. @ewan1976 that C*F*~0~ is a physiological side effect of gestures that actively promote closure voicing.
* *H*1~c~: *F*~0~ is raised after /p t k/, since the production of these stops (and only these stops) involves tensing of the cricothyroid [following @hutters1984; -@hutters1985], and the *F*~0~ levels following consonants is ranked /p/ > /b ~ m/. This would be evidence in favor of the proposal of @lofqvist1989 that C*F*~0~ is a physiological side effect of inhibiting phonation specifically through cricothyroid tensing.
* *H*1~d~: *F*~0~ is raised after both stop series, but the magnitude and temporal extent of the raising differs, and the *F*~0~ levels following consonants is ranked /p/ > /b/ > /m/. This would be evidence in favor of the proposal of e.g. @goldstein1986 that C*F*~0~ effects are a general physiological side effect of laryngeal gestures that inhibit phonation.

*RQ*2: How do focus and high pitch respectively affect C*F*~0~?^[Note that these hypotheses assume that C*F*~0~, if present in Danish, does not lower pitch, i.e. that *H*1~a~ is false; the previous research generally leads us to expect this.]

* *H*2~a~: C*F*~0~ is stronger under focus in speakers from Jutland, but not speakers from Zealand. This would suggest that focus in itself does not affect C*F*~0~, but high pitch *does*, since focus is not cued with high pitch on the tonic syllable in Zealand Danish.
* *H*2~b~: C*F*~0~ is stronger under focus in speakers from Jutland and Zealand. This would suggest that focus in itself strengthens C*F*~0~, independently of the pitch target.
* *H*2~c~: C*F*~0~ is not affected by focus in either variety. This would suggest that there is no synergy.

*RQ*3: Do phonological demands on pitch level (specifically the stød contrast) affect C*F*~0~?

* *H*3~a~: C*F*~0~ is stronger in syllables with stød, i.e. C*F*~0~ strengthens when pitch is high, regardless of the source of high pitch.
* *H*3~b~: C*F*~0~ is stronger in syllables without stød, since the lack of competing demands on the vocal folds allows for more modulation of *F*~0~.
* *H*3~c~: C*F*~0~ is not affected by the stød contrast either way.

# Methods and materials {#sec-methods}

## Speech materials

We constructed 132 alternative question sentences of the form *Er det **dine** eller er det **mine**?* 'Are they **yours** or are they **mine**?'. 
Following @kirby2016, this sentence structure was intended to prompt a high pitch reading of the first alternative (the focus item, in this case *dine*) and a low pitch reading of the second alternative (the non-focus item, in this case *mine*).
All items of interest occur in both focus and non-focus position.
The items of interest were crossed to contain all possible combinations of the following variable levels in the stressed syllable:

* [onset category]{.smallcaps}: *nasal*, *unaspirated*, *aspirated*
* [place of articulation]{.smallcaps}: *bilabial*, *alveolar*
* [vowel height]{.smallcaps}: *high*, *low*
* [stød]{.smallcaps}: *present*, *absent*

The test items all have phonologically long vowels in the stressed syllable.^[Some speakers have short vowels in the possessive pronouns *dine* 'yours' and *mine* 'mine'; this is apparently due to a relatively recent change in Zealand Danish [@schachtenhaufen2024].]
Most items were disyllabic with stress on the first syllable; a few were trisyllabic, with stress either on either the second or the first syllable.

Alternative question sentences were constructed around the test words.
Most items contained only one item of interest, in order to ensure that the sentence sounded relatively pragmatically natural, but some sentences contained two items of interest.

::: {.content-visible when-format="html"}
::: {.callout-note collapse="true"}
## A closer look at the speech materials

The prompts are stored in a comma-separated file. I'll load them in as `master` here:

```{r Load master doc}
#| code-fold: false

master <- read.csv('data/master.csv')
```

This file serves as a look-up table for later data analysis. It has the following columns:

* `filename` gives the file name associated with each sentence
* `sentence` gives the sentence orthographically
* `foc.item` gives the focused word orthographically
* `foc.moa` gives the manner or laryngeal category of the initial consonant of the focused word, either `unasp`, `asp`, or `nasal`
* `foc.poa` gives the place of articulation of the initial consonant of the focused word, either `alv` or `bilab`
* `foc.vheight` gives the height of the stressed vowel of the focused word, either `high` or `low`
* `foc.creak` gives the voice quality of the focused word, either `st` (stød) or `nst` (non-stød)
* Finally, there are five columns starting with `nfoc` which give the same values for the word not in focus

All values of the `foc` columns are `NA` if the focused word is not being analyzed, and same for the `nfoc` columns. 
The data frame has 137 columns because the first 5 sentences are used to accommodate the speakers to the experimental setup, and are not analyzed. The file names of these are `training1`, `training2`, etc.

You can have a look the data frame here:

```{r View master doc}
#| code-fold: false

master %>% DT::datatable()
```

:::
:::

## Participants {#sec-speakers}

31 speakers of Danish were recorded for the study.
Participants were either undergraduate students at the University of Copenhagen, or recruited in Aarhus from the extended network of the first author.
Participants self-reported their variety of Danish, year of birth, and gender.
We explicitly looked for speakers from either Zealand or Jutland, excluding speakers from Northern Jutland (see @sec-stresspitch).
In order to test *RQ*2, speakers were subsequently categorized as speakers of either *Jutland Danish* (*n* = 17) or *Zealand Danish* (*n* = 12); two speakers were excluded from the analysis, as they were late bilinguals with a different first language.
The Jutland Danish speakers were predominantly from Eastern Jutland near Aarhus (see @fig-mapDK), but a few came from Central Jutland and Southern Jutland. 
The Zealand Danish speakers were predominantly from the greater Copenhagen area, although a few came from other places in Zealand.
Two participants reported having a bidialectal upbringing; since variation in stress--pitch peak alignment was our reason for this categorization, and both speakers could straightforwardly be assigned to one of these two categories, we include these speakers in the final results.
Participants were between 19--34 years old at the time of recording. 
19 participants were female, 9 were male, and one was non-binary.

## Recording procedure

Recordings were made in sound-attenuated booths at the University of Copenhagen or Aarhus University.
Participants provided demographic information as outlined in the previous section, and signed informed consent forms.
The recordings made in Copenhagen were self-supervised after instructions by the third author as part of a course in acoustic phonetics; the recordings made in Aarhus were supervised by the first author.
Speakers were seated in front of an omnidirectional microphone (AKG P420 through a Zoom H5 in Aarhus; Sennheiser MKH40 in Copenhagen).
Sentence prompts appeared on a computer screen, and speakers were instructed to read as colloquially as possible, and at a natural pace.
The first 5 sentences were trial items not used in the analysis, in order to allow speakers to accomodate to the recording device.
Sentences were pseudo-randomized, and there was a break in the middle of the recording session.
Recordings were made direct to disk at a 44.1 kHz sampling rate using SpeechRecorder, version 6.8.5 [@speechrecorder].

## Pre-processing and annotation

Pre-processing, acoustic analysis, and statistical analysis was predominantly done in R [@r].
For each speaker, all recordings were concatenated to a single sound file using the `tuneR` library [@tuneR], and sentence-level orthographic annotations were automatically generated in the Praat TextGrid format [@boersma2001] using the `rPraat` library [@rPraat]. 
Recordings were then force-aligned using the DanFA module of the Autophon tool [@young2023; @danfa; @autophon], which implements the Montreal Forced Aligner [@mfa] with a series of pre- and post-processing steps. 
The force-aligned annotations were split to match the original audio files, and the resulting pairs of audio and annotation files were then converted to an EMU-SDMS database. Subsequent work with the files was done using the `emuR` interface [@emusdms]. 

::: {.content-visible when-format="html"}
::: {.callout-note collapse="true"}
## Preparing files for forced alignment and creating EMU-SDMS database

For each speaker, concatenated sound files and sentence-level annotations are created using the following custom function `make_master_wav_tg()` which takes a single argument, `sp`, which is the identifier for the speaker. 

The function matches the name of each audio file with the `filename` column in the `master` data frame we saw earlier, and grabs the corresponding orthography of the sentence. 

Sound files are read in using the `readWave()` function from the `tuneR` library and converted to mono using the `mono()` function, and the signals are concatenated using the `bind()` function. These resulting `Wave` objects are of the S4 class, so contents are accessed with the `@` operator. The signal of a mono audio file is stored in `@left`, where each sample is an integer between -32,767 and 32,767, corresponding to the 16 bit depth resolution of 65,536 possible amplitude values. For whatever reason, the above operation sometimes results in values above 32,767, which we just convert to 32,767 to ensure that `tuneR` is happy. The sound file is then saved using the `writeWave()` function.

As part of this loop, we also grab the durations of the sound files (by comparing the number of samples with the sampling rate stored in `@samp.rate` of the `Wave` objects) and store them in the vectors `t1` and `t2`. We create a TextGrid object from scratch using the `tg.createNewTextGrid()` function from the `rPraat` library. We add a tier with the `tg.insertNewIntervalTier()` function, and add intervals with the orthography for each sentence to the times in `t1` and `t2` using the `tg.addInterval()` function. We save this as a proper TextGrid with the `tg.write()` function. Here it's important to remember to set `format='text'`; the default format `'short'` can create a bunch of issues.

(This code isn't actually being run as part of knitting this document, this is just to show what the procedure looks like.)

```{r Function to concatenate sound and autogenerate TextGrid}
#| code-fold: false
#| message: false
#| warning: false

library(tuneR)
library(rPraat)
library(emuR)

make_master_wav_tg <- function(sp) {
  data_loc <- paste0('../data/', sp, '/')
  wavs <- list.files(data_loc, pattern='*.wav')

  base_fn <- wavs[1] %>% str_sub(start=5, end=-5)
  snd <- readWave(paste0(data_loc, wavs[1])) %>% mono
  dur <- length(snd@left)/snd@samp.rate
  t1 <- 0
  t2 <- dur
  ort <- master$sentence[which(master$filename==base_fn)]

  for (w in 2:length(wavs)) {
    base_fn <- wavs[w] %>% str_sub(start=5, end=-5)
    tmp <- readWave(paste0(data_loc, wavs[w])) %>% mono
    dur <- length(tmp@left)/tmp@samp.rate
    t1 <- c(t1, tail(t2, n=1))
    t2 <- c(t2, tail(t1, n=1)+dur)
    ort <- c(ort, master$sentence[which(master$filename==base_fn)])
    snd <- tuneR::bind(snd, tmp)
  }

  clip <- which(snd@left > 32767)
  snd@left[clip] <- 32767

  tg <- tg.createNewTextGrid(tMin=0, tMax=(length(snd@left)/snd@samp.rate)+1)
  tg <- tg.insertNewIntervalTier(tg, newTierName='ort')
  for (l in 1:length(ort)) {
    tg <- tg.insertInterval(tg, 'ort', tStart=t1[l], tEnd=t2[l], label=ort[l])
  }

  writeWave(snd, paste0(sp, 'concat.wav'))
  tg.write(tg, paste0(sp, 'concat.TextGrid'), format='text')
}
```

We then loop through all speakers and run this function like so:

```{r Loop through speakers prior to forced alignment}
#| code-fold: false
#| eval: false

d <- list.dirs('../data') %>% str_replace_all('../data/', '')
for (sp in d) make_master_wav_tg(sp)
```

Once the files are all force-aligned, we use the custom function `split_tg_wav()` to split the resulting TextGrids into separate files for each original sound file. This is again done with reference to the `master` data frame, although the output file of the forced aligner has removed all capitalization and punctuation, so this requires some string manipulation. We read in the final TextGrid using the `tg.read()`, and cut it up using the `tg.cut0()` function. 

(The reason for this circus of concatenating and splitting files is that the Autophon forced aligner -- at least when we force-aligned these files -- required files to be uploaded individually, which would have been a gargantuan task for the thousands of short sound files we have here, while the EMU-SDMS works best with short files.)

```{r Function to split concatenated TextGrid}
#| code-fold: false

split_tg_wav <- function(sp) {
  sp_dir <- paste0('tg_proc/', sp)
  dir.create(sp_dir)
  tg <- tg.read(paste0('../data/', sp, '.TextGrid'))
  len <- length(tg$trans$t1)
  t1 <- tg$trans$t1[-len]
  t2 <- tg$trans$t2[-len]
  sentences <- str_replace_all(master$sentence, '[?]', '') %>% tolower
  labs <- str_replace_all(tg$trans$label, '[?]', '')
  for (i in 1:(len-1)) {
    tg_sub <- tg.cut0(tg, t1[i], t2[i])
    id <- which(sentences==labs[i])
    base_fn <- master$filename[id]
    fn_tg <- paste0(sp, base_fn, '.TextGrid')
    tg.write(tg_sub, paste0(sp_dir, '/', fn_tg), 'text')
  }
}
```

And again, we repeat this step for each speaker. 

```{r Loop through speakers after forced alignment}
#| code-fold: false
#| eval: false

for (sp in d) split_tg_wav(sp)
```

We're now ready to convert the sounds to an EMU database, which we do with the `convert_TextGridCollection()` function from the `emuR` library.

```{r Make EMU database}
#| code-fold: false
#| eval: false

convert_TextGridCollection(dir='tg_proc', dbName='cf0dan',
                           targetDir='.')
```

You can now load the database with the `load_emuDB()` function. and have a look at it in a browser window using the `serve()` function:

```{r Load EMU database}
#| code-fold: false

db <- load_emuDB('../final_emuDB', verbose = FALSE)
```

You can have a look at the data base in a browser window using the `serve()` function:

```{r Serve EMU database}
#| code-fold: false
#| eval: false

serve(db, useViewer=FALSE)
```


A major advantage of using the EMU-SDMS is that annotations can be hierarchical. In Praat, the different TextGrid tiers are totally unaware of each other's existence, but in EMU, annotation levels can be linked, which makes it easy to fx find all [k]s occuring in the word *can't*. 

We add the first hierarchical layer to our annotations by creating a so-called 'one-to-many' connection between the `word` and `phone` annotation levels using the `add_linkDefinition()` function, and then we automatically create links between words and phones using the `autobuild_linkFromTimes()` function. 

```{r Add word-phone links to EMU annotations}
#| code-fold: false
#| eval: false

add_linkDefinition(db, type='ONE_TO_MANY', 
                   superlevelName='word', sublevelName='phone')
autobuild_linkFromTimes(db, superlevelName='word',
                        sublevelName='phone', convertSuperlevel=TRUE)
```

For more information on `emuR`, see [this in-progress tutorial](https://rpuggaard.github.io/emuintro){target='_blank'}.

:::
:::

In order to more precisely delimit the locations of stops, we used the `getVOT` library [@getVOT] to annotate landmarks associated with pVOT.
Prior to this, a bandpass filter was applied with cut-off frequencies of 50 Hz (abrupt) and 10,000 Hz (with a 100 Hz smooth Gaussian filter) using the `soundgen` library to eliminate an occasional low-frequency rumble and speed up the process.
`getVOT` is a simple utility that automatically searches for those landmarks in the speech signal that are typically manually annotated from inspecting the waveform: a sudden amplitude peak after a period of silence corresponding to the beginning of the release, and the onset of periodicity (operationalized here as increased autocorrelation of the signal) corresponding to the onset of voicing. 
There are multiple parameters that can be toggled to improve results, but `getVOT` has a function for automatically estimating optimal parameters from a few (typically less than 10) representative hand-annotated tokens.
`getVOT` may not be as precise as more sophisticated tools such as AutoVOT [@sonderegger2012] or Dr.VOT [@shrem2019], but it has the advantage of being very easy to set up and run, and of interacting directly with EMU-SDMS, which arguably makes it more suitable for medium-size datasets.

::: {.content-visible when-format="html"}
::: {.callout-note collapse="true"}
## Predicting voice onset time landmarks

We use the `getVOT` library to automatically predict voice onset time related landmarks. `getVOT` is available from GitHub, and can be installed using the `install_github()` function from the `devtools` library:

```{r Install getVOT}
#| code-fold: false
#| eval: false

library(devtools)
install_github('rpuggaardrode/getVOT')
```

`getVOT` in its current stage is quite sensitive to a low frequency rumble, so before using it we bandpass filter the files using the `bandpass()` function from the `soundgen` library in a loop. `bandpass` takes the arguments `lwr` and `upr` for the frequency ranges to pass to keep, and the `bw` argument that specifies the bandwidth of a Gaussian filter. This can be a vector, if different bandwidths should be used for the lower and upper ranges. By passing the vector `c(0,100)` we specify an abrupt cut-off at the lower range, but a `100` smooth filter at the upper range. This is done in a custom function `clean_audio()`, which also rounds the resulting signal vector to integers and rescales and normalizes the values to match the 16-bit depth using the `normalize()` function in `tuneR`. Files are then overwritten.

We do this by setting the working directory to the location of our EMU database, and then running the following code:

```{r Clean audio}
#| code-fold: false
#| eval: false

library(soundgen)

wavs <- list.files(pattern='*.wav', recursive=TRUE)

clean_audio <- function(file) {
  snd <- readWave(file)
  filt <- bandpass(snd, lwr=50, upr=10000, bw=c(0,100))
  snd@left <- round(filt, 0)
  snd <- snd %>% normalize(unit='16')
  writeWave(snd, file, extensible=FALSE)
}

for (w in wavs) clean_audio(w)
```

In order to predict voice onset time landmarks, we first need a list of words of interest to make sure that landmarks aren't predicted for *all* stops in the data. We take these from the `master` data frame, ignoring the nasal-initial stops and doing a bit of data wrangling to make sure that the strings exactly match the file names (which are not fully orthographic to avoid the Danish-specific letters *æ, ø, å*).

```{r Format stop items data frame}
#| code-fold: false

stop_items <- master %>%
  filter(foc.moa %in% c('asp', 'unasp')) %>%
  pull(foc.item) %>%
  data.frame(ort = .) %>%
  mutate(fn = str_replace_all(ort, c('æ' = 'E', 'ø' = 'OE', 'å' = 'O')),
         ort = tolower(ort))
```

We can now use the `query()` function in `emuR()` to find all matches for these words in our database. `getVOT` will later search for VOT landmarks only in these intervals.

```{r Query items for VOT landmark generation}
#| code-fold: false

sl <- query(db, paste0('word == ', paste(stop_items$ort, collapse='|')),
            timeRefSegmentLevel = 'phone')
sl %>% head(n=5)
```

In order to get a reasonable performance from `getVOT`, we've hand annotated the release and voicing onset of eight stop tokens. We can use that to estimate the best performing set of `getVOT` parameters, using the `pos_setParams()` function (`pos` because it's positive voice onset time). The hand-labeled tokens are in the `getVOT_training` directory. This function will spit out some text indicating its progress and indicating how closely the predicted VOT landmarks with the selected parameters match the hand-annotations. It will also spit out a plot comparing the the predictions with optimal parameters (red lines) to the hand-annotations (blue lines); if only blue lines are visible, it's because the predictions are very close to exactly matching the hand-annotations. Here we set the argument `cat=TRUE`, so that a picture of a cat is plotted along with the results. If you're a cat-hating monster you can use `cat=FALSE` instead. 

```{r Find parameters for VOT landmark estimation}
#| code-fold: false

library(getVOT)

params <- pos_setParams('data/getVOT_training', cat=TRUE)
```

The resulting object is a list that looks like this: 

```{r View parameters for VOT landmark estimation}
#| code-fold: false

params
```

For more information about what all this means, see [this extended overview](https://lingmethodshub.github.io/content/R/getVOT-tutorial/){target='_blank'}.


We can estimate VOT landmarks for our selected words and add them directly to the EMU database as a new annotation level using the function `addVOT2emuDB()`. We pass the `params` object to the `pos_params_list` argument.

```{r Estimate VOT landmarks and add them to EMU database}
#| code-fold: false
#| eval: false

addVOT2emuDB(db, sl, level='word', sign='positive', pos_params_list=params)
```

:::
:::

Finally, all relevant boundaries -- i.e., the beginning of the closure, the end of the closure, the end of the word, and onset of voicing after /b d p t/ -- were manually checked and adjusted when necessary, based primarily on visual inspection of the waveform.

::: {.content-visible when-format="html"}
::: {.callout-note collapse="true"}
## Creating annotation level with stop landmarks

After we've manually checked all annotations, we want to have a new convenient annotation level that has the same landmarks for all stop consonants, including the nasals. We'll add this new annotation level, called `landmarks` using the `add_levelDefinition()` function. The `type='EVENT'` specification is equivalent to creating a *point tier* in Praat. 

```{r Make new annotation level}
#| code-fold: false
#| eval: false

add_levelDefinition(db, 'landmarks', type='EVENT')
```

Here, we want to add specific points in time for the *closure*, *release*, *voicing onset* (not relevant for nasals), and *word offset*. It is a bit of a hassle to automatically create annotations in EMU, but there is a function `create_itemsInLevel()` that does it. This function requires a data frame of a specific format though. The custom function `populate_landmarks()` will take care of this formatting:

```{r Function to populate new annotation level}
#| code-fold: false

populate_landmarks <- function(seg_list, start, lab) {
  itc <- data.frame(session = seg_list[['session']],
                    bundle = seg_list[['bundle']],
                    level = rep('landmarks', nrow(seg_list)),
                    start = seg_list[[start]] / 
                      seg_list[1,'sample_rate'] * 1000,
                    labels = rep(lab, nrow(seg_list)),
                    db_uuid = db$UUID)
  return(itc)
}
```

`populate_landmarks()` takes as arguments a segment list created with the `query()` function, a column with start times from that segment list, and labels to repeat for that segment list. 

To get the times for the beginning of the closure and the word offset for oral stops, we can use the segment list `sl` that we already created above:

```{r Populate new annotation level with closure and offset}
#| code-fold: false

clo <- populate_landmarks(sl, 'sample_start', 'clo')
offset <- populate_landmarks(sl, 'sample_end', 'offset')
```

To get the times for release and voicing onset, we `query()` the annotation level `vot`.

```{r Populate new annotation level with release and voice onset}
#| code-fold: false

sl_vot <- query(db, 'vot == vot')

rel <- populate_landmarks(sl_vot, 'sample_start', 'rel')
vo <- populate_landmarks(sl_vot, 'sample_end', 'vo')
```

To get similar information about nasals, we need to create a segment list with only the nasals. We do this in the same way as we previously did with stops when making the `sl` list.

```{r Format nasal items data frame}
#| code-fold: false

nas_items <- master %>%
  filter(foc.moa == 'nasal') %>%
  pull(foc.item) %>%
  data.frame(ort = .) %>%
  mutate(fn = str_replace_all(ort, c('æ' = 'E', 'ø' = 'OE', 'å' = 'O')),
         ort = tolower(ort))
nas_ort <- paste(nas_items$ort, collapse='|')

sl_nas <- query(db, paste0('word == ', nas_ort), 
                timeRefSegmentLevel='phone') %>%
  distinct(.keep_all=TRUE)
```

Using this information, we can get all the word offset times:

```{r Populate new annotation level with nasal items offsets}
#| code-fold: false

offset_nas <- populate_landmarks(sl_nas, 'sample_end', 'offset')
```

We don't have the nasal *segment* information we need yet. To get that, we need some more complex queries (more on that [here](https://rpuggaardrode.github.io/emuintro/query.html){target='_blank'}).

```{r Populate new annotation level with other landmarks for nasals}
#| code-fold: false

q1 <- paste0('[#phone == m|n & Start(word,phone) == TRUE ^ word == ', 
             nas_ort, ']')
q2 <- '[#phone == n & End(word,phone) == FALSE ^ word == fornyet|forneden]'
sl_nasSeg <- rbind(
  query(db, q1),
  query(db, q2)
)

clo_nas <- populate_landmarks(sl_nasSeg, 'sample_start', 'clo')
rel_nas <- populate_landmarks(sl_nasSeg, 'sample_end', 'clo')
```

We can now combine all of the data frames we just made, and pass them on to the `create_itemsInLevel()` function:

```{r Populate landmarks annotation level}
#| code-fold: false
#| eval: false

itc <- rbind(clo, rel, vo, offset, clo_nas, rel_nas, offset_nas)
create_itemsInLevel(db, itc)
```

:::
:::

## Acoustic analysis

Durational measures, such as closure duration and pVOT, are straightforwardly extracted from the annotations described above.

In order to only include pitch measures that we were reasonably certain about, we calculated pitch using a cross-validation method with two distinct pitch tracking algorithms, *viz.* Praat and REAPER. 
Pitch was calculated using Boersma's [-@boersma1993] autocorrelation algorithm in Praat, using the `emuhelpeR` library [@emuhelpeR] to access the PraatSauce scripts [@praatsauce] and import the results into EMU-SDMS.
Additionally, pitch was calculated using Talkin's [-@reaper] REAPER (robust epoch and pitch estimator) algorithm, which first estimates the candidates for the locations of glottal closure instances, and then defines pitch as the distance between "winning candidates" (determined through a dynamic programming procedure). 
REAPER has been shown to perform particularly well for pathological and creaky speech [@vaysse2022; @white2022], which is highly relevant here since we measure syllables with stød.
A set of custom functions in R were used to call the REAPER utility and import the results into EMU-SDMS.

With both Praat and REAPER, we used the two-pass pitch estimation procedure proposed by @hirst2007 to dynamically estimate suitable pitch floor and ceiling values. This involves first running the algorithms with very liberal pitch floor and ceiling values of 60 Hz and 700 Hz respectively [following recommendations by @hirst2022]. 
For each speaker, quartiles $Q_n$ are calculated from all resulting pitch values, and the algorithms are rerun where the pitch floor is set to $\frac{3}{4}Q_1$ and the pitch ceiling is set to $1\frac{1}{2}Q_3$. 
This method reduces pitch tracking errors close to the edges of a speaker's register [@deloozeDiss].
Any *F*~0~ measures that fall outside of three standard deviations of a speaker's mean is treated as a missing value.

::: {.content-visible when-format="html"}
::: {.callout-note collapse="true"}
## Extracting pitch with Praat

Praat's pitch tracking algorithm is used via the `emuhelpeR` library, available from GitHub.

```{r Install emuhelpeR}
#| code-fold: false
#| eval: false

install_github('rpuggaardrode/emuhelpeR')
library(emuhelpeR)
```

We set the directory with folders of raw data as the working directory, and then call the function `run_ps_dynamic_minmax()`, which will calculate pitch twice for each speaker, once to get range estimates for setting the pitch floor and ceiling, and once with suitable floor and ceiling.

```{r Run PraatSauce with dynamic floor and ceiling}
#| code-fold: false
#| eval: false

ps_out <- run_ps_dynamic_minmax(getwd(), 
                                formantMeasures = FALSE, 
                                spectralMeasures = FALSE)
```

A bit of wrangling to get the format of the resulting data frame just right:

```{r Format PraatSauce results}
#| code-fold: false
#| eval: false

ps_out <- ps_out %>% mutate(
  session = str_sub(Filename, end=3)
) %>% relocate(session, .after=Label) %>%
  mutate(seg_Start = as.numeric(seg_Start),
         session = paste0('_', session))
```

And then we incorporate the values into the EMU database using the `praatsauce2ssff()` function:

```{r Add PraatSauce results to EMU database}
#| code-fold: false
#| eval: false

ps_out %>% praatsauce2ssff(db, 'session')
```

:::
:::

::: {.content-visible when-format="html"}
::: {.callout-note collapse="true"}
## Extracting pitch with REAPER

I have bundled up some functions for working with REAPER in R as the library `reapeR`. It has so far only been tested on Windows, so I can't make promises about how well it'll function with other operating systems.

The library can be installed from GitHub like so:

```{r Install reapeR}
#| code-fold: false
#| eval: false

devtools::install_github('rpuggaardrode/reapeR')
```

If you just installed this, it's recommended that you restart your R session before loading it.

This library has the function `reaper_bulk()` which has all the functionality we need built in: it'll interface directly with a loaded EMU database, and it the two-pass pitch floor and ceiling estimation is automated. We run it like this:

```{r Run REAPER with dynamic floor and ceiling}
#| code-fold: false
#| eval: false

library(reapeR)
reaper_out <- reaper_bulk(db, output = 'pitch', hirst2pass = TRUE)
```

We can add the resulting measurements to our EMU database with the function `reaper2ssff()`:

```{r Add REAPER results to EMU database}
#| code-fold: false
#| eval: false

reaper2ssff(reaper_out, db)
```

:::
:::

To cross-validate the resulting pitch measures, we analyze only measurements from frames where both trackers successfully estimated pitch, and where the estimates are no further than 20% apart.
For the remaining frames, we analyze the arithmetic mean of the two pitch estimates.
Prior to analysis, the Hz values of trajectories to be analyzed are converted to by-speaker *z*-scores, and in order to filter out octave jumps, trajectories were removed if they included changes of ±1.5 *z* between any adjacent measures.

::: {.content-visible when-format="html"}
::: {.callout-note collapse="true"}

## Preparing data for analysis -- first attempt!

To grab pitch measures for exactly those sequences that we're interested in, we create a *segment list* using the `query()` function in `emuR`. We do this multiple times to get all of the time information that we're interested in in a single data frame. When querying an `EVENT` level (similar to a point tier in Praat), the time information of the resulting object is stored in the `start` column (in ms) or the `sample_start` column (in raw samples).

```{r Query landmarks except voice onset}
#| code-fold: false

sl <- query(db, 'landmarks == rel')
sl$end <- query(db, 'landmarks == offset')$start
sl$sample_end <- query(db, 'landmarks == offset')$sample_start
sl$clo <- query(db, 'landmarks == clo')$start
```

Next, we do some wrangling to convert the information in the bundle name of each observation into separate named columns, which will tell us for each segment which word it is part of, the voicing status (nasal, unaspirated, or aspirated), the place of articulation, the vowel height, and whether or not the word has stød. Since some sentences have both items of interest in focus condition and non-focus condition, this adds up to ten columns. In a separate wrangling step (a not-very-pretty for-loop), we determine whether the item in a row is in focus or not in focus and save that information in a new column `ord` (for *order*). Subsequently, we use this information to create a column `cond` with information about the focus condition, and convert the other ten columns into five with only the relevant information.

```{r Wrangle segment list}
#| code-fold: false

sl <- sl %>%
  mutate(bndl_info = str_sub(bundle, start=4)) %>%
  separate(bndl_info, into=c(
    'foc_item', 'foc_voi', 'foc_poa', 'foc_vheight', 'foc_st',
    'nfoc_item', 'nfoc_voi', 'nfoc_poa', 'nfoc_vheight', 'nfoc_st'))

sl$ord <- rep(NA, nrow(sl))
for (i in 2:nrow(sl)) {
  bndl <- sl$bundle[i]
  n_item <- nrow(filter(sl, bundle==bndl))
  if (n_item > 1) {
    if (sl$bundle[i-1] == sl$bundle[i]) {
      sl$ord[i] <- 2
    } else {
      sl$ord[i] <- 1
    }
  }
}

sl <- sl %>%
  mutate(cond = case_when(
    foc_item == 'NA' ~ 'nfoc',
    nfoc_item == 'NA' ~ 'foc',
    ord == 1 ~ 'foc',
    ord == 2 ~ 'nfoc'),
    item = case_when(
      foc_item == 'NA' ~ nfoc_item,
      nfoc_item == 'NA' ~ foc_item,
      ord == 1 ~ foc_item,
      ord == 2 ~ nfoc_item),
    voi = case_when(
      foc_item == 'NA' ~ nfoc_voi,
      nfoc_item == 'NA' ~ foc_voi,
      ord == 1 ~ foc_voi,
      ord == 2 ~ nfoc_voi),
    poa = case_when(
      foc_item == 'NA' ~ nfoc_poa,
      nfoc_item == 'NA' ~ foc_poa,
      ord == 1 ~ foc_poa,
      ord == 2 ~ nfoc_poa),
    vheight = case_when(
      foc_item == 'NA' ~ nfoc_vheight,
      nfoc_item == 'NA' ~ foc_vheight,
      ord == 1 ~ foc_vheight,
      ord == 2 ~ nfoc_vheight),
    st = case_when(
      foc_item == 'NA' ~ nfoc_st,
      nfoc_item == 'NA' ~ foc_st,
      ord == 1 ~ foc_st,
      ord == 2 ~ nfoc_st)
  ) %>%
  select(-c(nfoc_item, foc_item, nfoc_voi, foc_voi, nfoc_poa, foc_poa,
            nfoc_vheight, foc_vheight, nfoc_st, foc_st, ord))
```

We still need to integrate information about voice onset for the stop items (we set it to zero for nasal items), which we do by splitting our `df` data frame in two and recombining them. Finally we add columns with the vowel duration `vdur`, open phase duration `opdur`, voice onset time `vot`, and closure duration `cldur`.

```{r Create final segment list with temporal measures}
#| code-fold: false

sl_vo <- query(db, 'landmarks == vo')

sl_nas <- sl %>% filter(voi == 'nasal') %>%
  mutate(vo = 0)
sl_stop <- sl %>% filter(voi != 'nasal') %>%
  mutate(vo = sl_vo$start)
sl <- rbind(sl_nas, sl_stop)

sl <- sl %>% mutate(
  vdur = ifelse(voi == 'nasal', end - start, end - vo),
  opdur = end - start,
  vot = ifelse(voi == 'nasal', NA, vo - start),
  cldur = start - clo
)
```

And as a final step, we integrate metadata about speakers from the CSV file `meta`.

```{r Add speaker metadata}
#| code-fold: false

meta <- read.delim('data/meta.csv', sep=';')
sl <- left_join(sl, meta, by = 'session')
```

We can now use the function `get_trackdata()` to grab pitch measurements from just those sequences we're interested in. We also suitably convert `0` values from Praat to `NA`, and `-1` values from REAPER to `NA`. We save both of these in a data frame `td`.

```{r Import pitch measures}
#| code-fold: false

td_praat <- get_trackdata(db, sl, ssffTrackName='f0', verbose = FALSE)
td_praat[which(td_praat$T1 == 0),'T1'] <- NA

td_reaper <- get_trackdata(db, sl, ssffTrackName='rf0', verbose = FALSE)
td_reaper[which(td_reaper$T1 == -1),'T1'] <- NA

td <- td_praat %>% rename(praat_f0 = T1)
td$reaper_f0 <- td_reaper$T1
```

Next, we create a new column in `td`, `f0`, which contains the average of the two pitch trackers, and converts values to `NA` if they occur prior to the onset of voicing, if *any* of the pitch trackers has failed, if they differ by more than 20%, and if they differ by more than three standard deviations from the speaker's mean. Finally, we create the column `zf0` with by-speaker *z*-scored *F*~0~ values.

```{r Prepare pitch measures for analysis}
#| code-fold: false

td <- td %>% mutate(
  low_est = ifelse(reaper_f0 < praat_f0, reaper_f0, praat_f0),
  f0_diff = (reaper_f0-praat_f0)/low_est,
  f0 = case_when(
    is.na(f0_diff) ~ NA,
    abs(f0_diff) > 0.2 ~ NA,
    times_orig < vo ~ NA,
    TRUE ~ (praat_f0+reaper_f0)/2
  )) %>% group_by(session) %>%
  mutate(uppF0 = mean(f0, na.rm=T) + 3*sd(f0, na.rm=T),
         lowF0 = mean(f0, na.rm=T) - 3*sd(f0, na.rm=T),
         f0 = ifelse(f0 > uppF0 | f0 < lowF0, NA, f0)) %>%
  mutate(zf0 = as.numeric(scale(f0))) %>%
  ungroup()
```

The data is now ready for analysis! -- or is it? See below!

:::
:::

## Determining the domain of analysis {#sec-methods-domain}

Recall from @sec-cf0overview that @xu2021 have proposed that pitch peaks are always timed relative to stop releases, and as a result, studies of C*F*~0~ should compare trajectories starting at the stop release and *not* at the onset of voicing to avoid overestimating C*F*~0~ effects.^[As discussed above, this study operationalizes the onset of voicing as the onset of periodicity in the waveform following the stop release. This does not necessarily correspond to the beginning of the vowel, which @fischerjorgensen1981aripuc have argued comes later, particularly after aspirated stops.]
This is likely true for some languages, but it is unclear whether this holds true for all languages. 
In order to evaluate whether the stop release or the onset of voicing is the optimal starting point for comparing pitch trajectories in Danish, we carried out some exploratory analyses.

::: {.content-visible when-format="html"}
::: {.callout-note collapse="true"}

## Trajectory duration differences depending on landmark

Here we tabulate the trajectory mean durations depending on whether the stop release or the onset of voicing is taken as the starting point:

```{r Table of mean duration differences}
#| code-fold: false

sl %>% group_by(voi) %>% summarize('Stop release' = mean(opdur)) %>%
  rename('Onset category' = voi) -> stopRelMeans
sl %>% group_by(voi) %>% summarize('Onset of voicing' = mean(vdur)) %>%
  rename('Onset category' = voi) -> voMeans
left_join(stopRelMeans, voMeans, by='Onset category')
```

:::
:::

First, we checked whether *open phase durations* of our words -- i.e., the duration of trajectories beginning at the stop release -- are roughly comparable across our onset categories. 
The open phases of words with nasal and unaspirated onsets are very similar (means = 314 ms and 317 ms, respectively), but words with aspirated onsets have systematically much longer open phases (mean = 383 ms).
In fact, the difference in open phase duration after nasals and aspirated stops is similar to the expected duration of the aspiration phase [following e.g. @fischerjorgensen1954; @puggaardrode2022jphon], suggesting that the aspiration is 'appended' to the open phase. 
The mean *vowel durations*, on the other hand -- i.e., the duration of trajectories beginning at the onset of voicing -- *are* roughly comparable across onset categories (nasals = 314 ms, unaspirated = 304 ms, aspirated = 310 ms).
The distributions of trajectory durations using different landmarks are shown in @fig-durdist. 
This intuitively makes it seem likelier that pitch peaks are also timed to the onset voicing.

```{r}
#| label: fig-durdist
#| fig-cap: Violin plots showing the distributions of trajectory durations depending on which landmark is chosen to represent the beginning of the trajectory. Points show individual trajectory durations.

sl$voi <- factor(sl$voi, levels = c('nasal', 'unasp', 'asp'))
sl %>% pivot_longer(cols = c(opdur, vdur), names_to = 'landmark',
                    values_to='durcomp') %>% 
  ggplot() +
  aes(x=voi, y=durcomp, fill=voi) +
  geom_jitter(aes(col=voi), alpha=0.1) +
  geom_violin() +
  facet_grid(~landmark,
             labeller = labeller(
               landmark = c(opdur = 'Stop release', 
                            vdur = 'Onset of voicing'))) +
  xlab('') +
  ylab('Trajectory duration (ms)') +
  scale_color_manual(values = c('black', 'blue', 'darkorange'),
                     name = 'Onset',
                     labels = c('nasal', 'unaspirated', 'aspirated')) +
  scale_fill_manual(values = c('darkgrey', 'blue', 'darkorange'),
                     name = 'Onset',
                     labels = c('nasal', 'unaspirated', 'aspirated')) +
  theme(panel.background = element_rect(fill = NA),
        panel.border = element_rect(color = 'black', fill=NA),
        panel.grid.major = element_line(color='grey90'),
        panel.grid.minor = element_line(color='grey95'),
        legend.position = 'bottom',
        text = element_text(size = 12),
        legend.box = 'vertical',
        axis.title.y = ggtext::element_markdown(),
        axis.ticks.x = element_blank(),
        axis.text.x = element_blank())
```

::: {.content-visible when-format="html"}
::: {.callout-note collapse="true"}

## Preparing data for analysis -- second attempt!

It looks like we want to extract *F*~0~ trajectories over a different interval than we previous have. This means creating an alternative segment list with a `start` column that has the right information. We can do this straightforwardly, since we already have time information about the voicing onset in our existing `sl` object, so we use that to create an alternative:

```{r Create alternative segment list}
#| code-fold: false

alt_sl <- sl %>% mutate(start = ifelse(vo == 0, start, vo))
```

Now, we repeat the whole procedure for extracting pitch data from both tracking algorithms, removing outliers, getting *z*-scores etc.

```{r Repeat pitch processing steps for new trajectories}
#| code-fold: false

td2 <- get_trackdata(db, alt_sl, ssffTrackName='f0', verbose = FALSE)
td2[which(td2$T1 == 0),'T1'] <- NA

tdr2 <- get_trackdata(db, alt_sl, ssffTrackName='rf0', verbose = FALSE)
tdr2[which(tdr2$T1 == -1),'T1'] <- NA

td2 <- td2 %>% rename(praat_f0 = T1)
td2$reaper_f0 <- tdr2$T1

td2 <- td2 %>% mutate(
  low_est = ifelse(reaper_f0 < praat_f0, reaper_f0, praat_f0),
  f0_diff = (reaper_f0-praat_f0)/low_est,
  f0 = case_when(
    is.na(f0_diff) ~ NA,
    abs(f0_diff) > 0.2 ~ NA,
    times_orig < vo ~ NA,
    TRUE ~ (praat_f0+reaper_f0)/2
  )) %>% group_by(session) %>%
  mutate(uppF0 = mean(f0, na.rm=T) + 3*sd(f0, na.rm=T),
         lowF0 = mean(f0, na.rm=T) - 3*sd(f0, na.rm=T),
         f0 = ifelse(f0 > uppF0 | f0 < lowF0, NA, f0))

td2 <- td2 %>% group_by(session) %>%
  mutate(zf0 = as.numeric(scale(f0))) %>%
  ungroup()
```

This is the data frame we want for analysis, so we'll rename it `dat`.

```{r Creating dat object}
#| code-fold: false

dat <- td2
```

A final post-processing step is to remove trajectories that have too large inter-frame differences, as a relatively coarse way to remove octave jumps:

```{r Filter out trajectories with obvious octave jumps}
#| code-fold: false
#| warning: false
#| message: false

dat$diff <- rep(NA, nrow(dat))
dat$diff[2:nrow(dat)] <-
  dat$zf0[2:nrow(dat)] - dat$zf0[1:(nrow(dat)-1)]
dat[which(dat$times_rel == 0),'diff'] <- NA
max_diffs <- dat %>% group_by(sl_rowIdx) %>%
  summarize(m = abs(max(diff, na.rm=T)))
dat <- left_join(dat, max_diffs, by='sl_rowIdx')
dat <- dat %>% filter(m < 1.5)
```

:::
:::

To check whether this is indeed the case, we plot some representative trajectories.
@fig-landmarkcomp shows smoothed *F*~0~ trajectories of the words in the focus condition in the subgroup of speakers from Jutland. 
The figure shows that, on a raw time scale, prominent peaks and valleys are highly misaligned across onset categories if trajectories begin at the stop release, but they align nicely after an initial perturbation if trajectories begin at voicing onset. 
The figure also suggests that any real influence of aspiration on *F*~0~ would be obscured if trajectories begin at the stop release due to variation in the pVOT of aspirated tokens. 
*Contra* @xu2021, differences between onset categories would likely be highly overestimated if the stop release were taken as the suitable landmark for comparing trajectories, since pitch peaks do *not* appear to be timed to stop releases in Danish.

```{r}
#| label: fig-landmarkcomp
#| warning: false
#| message: false
#| fig-cap: Smoothed *F*~0~ trajectories over raw time in different conditions with different landmarks conditioning the beginning of the trajectory. Trajectories are smoothed using separate generalized additive models. Based on Jutland speakers and words in focus condition.

trajTheme <- theme(panel.background = element_rect(fill = NA),
                   panel.border = element_rect(color = 'black', fill=NA),
                   panel.grid.major = element_line(color='grey90'),
                   panel.grid.minor = element_line(color='grey95'),
                   legend.position = 'bottom',
                   text = element_text(size = 12),
                   legend.box = 'vertical',
                   plot.title = element_text(hjust = 0.5),
                   axis.title.y = ggtext::element_markdown())

td$alignment <- 'Aligned at stop release'
td2$alignment <- 'Aligned at voicing onset'
td_all <- rbind(td, td2)
td_all$voi <- factor(td_all$voi, levels = c('nasal', 'unasp', 'asp'))
td_all %>%
  filter(variety == 'j', cond == 'foc') %>%
  ggplot() +
  aes(x=times_rel, y=zf0, color=voi) %>%
  geom_smooth(method='gam') +
  xlim(0,400) +
  facet_grid(st~alignment,
             labeller = labeller(
               st = c(nst = 'non-stød', st = 'stød'))) +
  ylab('*F*~0~ (*z*-scored)') +
  xlab('Time (ms)') +
  scale_color_manual(values = c('black', 'blue', 'darkorange'),
                     name = 'Onset',
                     labels = c('nasal', 'unaspirated', 'aspirated')) +
  trajTheme
```


## Statistical analysis {#sec-methods-stats}

The research questions posed in @sec-rq are all statistically tested using a generalized additive mixed model (GAMM).
GAMMs are highly suitable for modelling data that change over time [@wieling2018], and they have been widely used in the past few years for modelling pitch data, including in studies of C*F*~0~ [e.g. @kirby2022khmu; @ting2023].
The advantage of using GAMMs over traditional linear mixed-effects regression models in the analysis of time series is that the GAMMs do not restrict the relationship between predictor and response variables to be linear; GAMMs can model data that vary dynamically in time, i.e. complex contour shapes. 
In this approach, non-linear (or *smooth*) effects are predicted by fitting the data to a series of basis functions (or *splines*). 
We fit GAMMs using the `mgcv` library in R [@mgcv], which provides a very flexible framework for selecting and combining basis functions, and for penalizing overfitting.

The model is fitted using fast restricted maximum likelihood estimation with discretized values for covariates to decrease computing load [@bam], and using the scaled-*t* error distribution to account for heavy-tailed residuals.
The residuals of the final model are approximately normal, although somewhat platykurtic.
The temporal dynamics of *F*~0~ is modeled with thin plate regression spline smooths [@wood2003; @wieling2018] using 10 basis functions, where time is normalized to a 0--1 scale; separate *F*~0~ contours are modelled for all levels of the four-way interaction between the variables [onset, focus condition, stød]{.smallcaps} and [regional variety]{.smallcaps}.
The model further included this same four-way interaction as well as [vowel height]{.smallcaps} as parametric, i.e. time-invariant, predictors.^[Since we expect the effect of [vowel height]{.smallcaps} to be more or less constant, it is only included as a parametric variable in the model.]
The model is fitted with a maximal random effects structure, including by-speaker and by-item *factor smooths* (the non-linear equivalent to random slopes) for each logically meaningful combination of the variables.
To decrease computing load, factor smooths are fitted with first-order penalty differences and are smoothed using only five basis functions.

Skipping over most implementation details, the model can be summarized as

$$
\begin{gather*}
F_{0ijk} = \alpha \\
+ onset_i focus_i stød_i variety_i + height_i \\
+ onset_i focus_i stød_i variety_i (t_i) \\
+ speaker_j onset_i focus_i stød_i (t_i) \\
+ item_k focus_i variety_i (t_i) \\
+ \rho e_{i - 1} + E_{ijk}
\end{gather*}
$$

where $\alpha$ denotes the intercept, $E$ denotes the residual error, $i$ indexes each observation, $j$ indexes each speaker, and $k$ indexes each item. 
A typical problem with time series analysis is that residual autocorrelation stemming from the high degree of similarity between adjacent measures in time series. 
We manage this problem by modulating the error of each observation $e_i$ by the error of the preceding observation $e_{i-1}$ by a factor of $\rho$; this is referred to as an AR(1) error model [@baayen2018; @wieling2018]. Following e.g. @wieling2016, $\rho$ is a fixed value equivalent to the average residual autocorrelation of adjacent measures in a nested model with no correction.
Residual autocorrelation in the corrected model is negligible.
A more ideal solution would be to fit the model with by-trajectory factor smooths, which preserves the identity of trajectories in the model and dispenses with the assumption that the degree of autocorrelation is constant [@soskuthy2021]; however, fitting such a model proved to be computationally infeasible.

::: {.content-visible when-format="html"}
::: {.callout-note collapse="true"}

## Fitting GAMM 

Before fitting the GAMM, we make sure that all factor variables are actually interpreted as factors.

```{r Factorizing factor variables}
#| code-fold: false

for (f in c('vheight', 'voi', 'variety', 'cond', 
            'st', 'item', 'session', 'sl_rowIdx')){
  dat[[f]] <- as.factor(dat[[f]])
}
```

R will automatically order these factor levels alphabetically, but if we want to interpret the parametric output of the GAMM, it's nice to have factor level ordering that corresponds more closely to the hypotheses we're interested in. The `cond` and `st` (focus condition and stød) variables are fine, since *focus* and *non-stød* are reasonable reference levels, but we reorder `vheight` so `low` is the reference, `variety` so `z` is the reference (since Zealand Danish is just more well-described than Jutland Danish), and crucially, `voi` so `nasal` is the reference.

```{r Setting reference levels}
#| code-fold: false

dat$vheight <- dat$vheight %>% relevel('low')
dat$voi <- dat$voi %>% relevel('nasal')
dat$variety <- dat$variety %>% relevel('z')
```

```{r Load mgcv and itsadug silently}
#| echo: false
#| message: false
#| warning: false

library(mgcv)
library(itsadug)
```


We're now ready to fit the actual model. The model with no AR(1) correction is fitted with this code:

```{r Fit model without AR1 correction}
#| code-fold: false
#| eval: false

library(mgcv)

gam_mod <- bam(zf0 ~ monsterInteraction + vheight +
                 s(times_norm, by=monsterInteraction) +
                 s(times_norm, session, by=bigInteraction, bs='fs', m=1, k=5) +
                 s(times_norm, item, by=smallInteraction, bs='fs', m=1, k=5),
               data = dat %>%
                 mutate(monsterInteraction = interaction(voi,cond,st,variety),
                        bigInteraction = interaction(voi,cond,st),
                        smallInteraction = interaction(cond,variety)),
               discrete = TRUE, nthreads = 10,
               family = 'scat')
```

We use the `bam()` function which is typically used for efficiently fitting large GAMMs.
Smooths are constructed with the `s()` function. `mgcv` does not have built-in functionality to fit interaction terms within smooths, so these interaction terms (with very apt names) are created on the fly using the `interaction()` function. `bs='fs'` specifies a factor smooth, `m=1` specifies a first-order penalty difference, and `k=5` specifies the number of basis functions to use. `discrete = TRUE` tells `mgcv` to use discretized values for covariates. `nthreads = 10` specifies the number of cores to use, set to 10 here. `family = 'scat'` specifies the scaled-*t* error distribution.

This model is only fitted so we can find out what's a reasonably `rho` parameter for AR(1) correction. We do this using the `acf_resid()` function from the `itsadug` library, which returns a vector of autocorrelation values at progressively higher lags in the time series. Autocorrelation at lag 1 is always equal to 1 (it's how much any value is correlated with itself, which is logically a perfect correlation), so we grab the second value of that vector. We also add a column `startEvent`, this is a Boolean column which is `TRUE` for the first row of each time series and `FALSE` otherwise; this column is passed to the argument `AR.start`. Otherwise the code is the same:

```{r Fit model with AR1 correction}
#| code-fold: false
#| eval: false

library(itsadug)

gam_mod_rho <- bam(zf0 ~ monsterInteraction + vheight +
                     s(times_norm, by=monsterInteraction) +
                     s(times_norm, session, by=bigInteraction, bs='fs', m=1, k=5) +
                     s(times_norm, item, by=smallInteraction, bs='fs', m=1, k=5),
                   data = dat %>%
                     mutate(monsterInteraction = interaction(voi,cond,st,variety),
                            bigInteraction = interaction(voi,cond,st),
                            smallInteraction = interaction(cond,variety),
                            startEvent = times_rel == 0),
                   discrete = TRUE, nthreads = 10,
                   family = 'scat',
                   rho = itsadug::acf_resid(gam_mod)[2], AR.start = startEvent)
```

Since fitting these models is so time-demanding, we do not actually do it as part of rendering this document; instead, it's done on the IPS server, and just loaded in here: 

```{r Load final model}
#| code-fold: false

load('data/gam_maxre_rho.Rda')
```

The residuals of the model are reasonably normally distributed, although somewhat light tailed:

```{r Check residuals}
#| fig-height: 3.5

res <- gam_mod_rho$residuals
m <- mean(res)
s <- sd(res)

normdist <- ggplot(data.frame(res)) + 
  aes(x=res) +
  geom_histogram(aes(y=after_stat(density)), bins=24) +
  stat_function(fun=dnorm,
                args=list(mean=m, sd=s),
                color='blue', lwd=1) +
  xlim(-4, 4) +
  ggtitle('Comparison with normal distribution') +
  xlab('Residuals') +
  trajTheme

qqpl <- ggplot() +
  aes(sample=res) +
  stat_qq() +
  stat_qq_line(color='blue', lwd=1) +
  ggtitle('QQ plot') +
  xlab('Theoretical quantiles') + ylab('Samples') +
  trajTheme

gridExtra::grid.arrange(normdist, qqpl, ncol=2)
```

And the model has only very negligible residual autocorrelation:

```{r Check residual autocorrelation}
acf_resid(gam_mod_rho, main = 'Residual autocorrelation')
```

:::
:::

It is not straightforward to test hypotheses from the non-parametric components of GAMMs. 
The *F*-test provided by the `mgcv` library essentially tests the significance of the spline fitting procedure [@wood2013], which is typically not something phoneticians have hypotheses about. 
In this study, hypothesis testing is done through pointwise comparisons of relevant model-predicted trajectories with random effects removed, using the `itsadug` library [@itsadug].
Comparisons are considered significant at time points where the predicted 95% confidence intervals do not overlap. 

::: {.content-visible when-format="html"}
::: {.callout-note collapse="true"}

## Extracting fitted trajectories and pointwise comparisons

Extracting fitted trajectories is relatively straightforward. We do this with the `get_predictions()` function from `itsadug`. We have a four-way interaction with a total of 24 levels; `get_predictions()` extracts one of these at a time (chosen with the `select` argument), so we do this in a loop, and combine the resulting data frames in an object `preds`. This object has a column `monsterInteraction` which we split into four columns which describes each level of each interaction.

```{r Get model predictions}
#| code-fold: false

u <- levels(interaction(dat$voi,dat$cond,dat$st,dat$variety))
preds <- itsadug::get_predictions(gam_mod_rho, 
                                cond=list(monsterInteraction = u[1],
                                          times_norm = seq(0, 1, length=100)),
                                print.summary = F)
for (i in 2:24) {
  tmp <- itsadug::get_predictions(gam_mod_rho, 
                                  cond=list(monsterInteraction = u[i],
                                            times_norm = seq(0, 1, length=100)),
                                  print.summary = F)
  preds <- rbind(preds, tmp)
}

preds <- preds %>%
  separate(monsterInteraction, into = c('voi', 'cond', 'st', 'variety'),
           remove = F)
```

The model allows us to test a *lot* of comparisons, most of which we aren't really interested in. What we want to test is essentially whether *F*~0~ is significantly higher after unaspirated/aspirated stops than after nasals. That adds up to 16 comparisons, which we get in a loop using the `get_difference()` function in `itsadug`. This gives us the predicted difference between two variable levels and the associated 95% confidence intervals. Using this, we create a vector `sig` which simply has `1` for each pointwise comparisons where the *F*~0~ following a stop is significantly higher than following a nasal, and `0` where it isn't.

```{r Get term comparisons}
#| code-fold: false

u <- as.character(unique(preds$monsterInteraction))
sig <- c()
for (i in 1:length(u)) {
  m <- strsplit(u[i], '\\.')[[1]][1]
  if (m == 'nasal') {
    thisSig <- rep(NA, 100)
    sig <- c(sig, thisSig)
  } else {
    intlevel <- paste(strsplit(u[i], '\\.')[[1]][2:4], collapse='.')
    complevel <- paste('nasal', intlevel, sep='.')
    dif <- itsadug::get_difference(gam_mod_rho, list(
      monsterInteraction = c(complevel, u[i])
    ), cond=list(times_norm=seq(0,1,length.out=100)), se=T, print.summary=F)
    thisSig <- ifelse(dif$difference + dif$CI > 0, 0, 1)
    sig <- c(sig, thisSig)
  }
}

preds$sig <- sig
```

In order to plot these significance levels later, we create separate columns for significant differences of unaspirated and aspirated stops, and columns containing the time information for where to indicate significance.

```{r Format comparisons}
#| code-fold: false

preds$unasp_sig <- ifelse(preds$sig == 1 & preds$voi == 'unasp', 'sig', 'nsig')
preds$unasp_sig <- ifelse(preds$voi != 'unasp', NA, preds$unasp_sig)
preds$unasp_lower <- ifelse(preds$unasp_sig == 'sig', preds$times_norm, NA)
preds$unasp_upper <- ifelse(preds$unasp_sig == 'sig', preds$times_norm +
                              (1/99), NA)

preds$asp_sig <- ifelse(preds$sig == 1 & preds$voi == 'asp', 'sig', 'nsig')
preds$asp_sig <- ifelse(preds$voi != 'asp', NA, preds$asp_sig)
preds$asp_lower <- ifelse(preds$asp_sig == 'sig', preds$times_norm, NA)
preds$asp_upper <- ifelse(preds$asp_sig == 'sig', preds$times_norm +
                              (1/99), NA)
```

Finally, we make sure that the `voi` factor is ordered in the same way as in the `dat` data frame:

```{r Factorize onset variable in comparisons data frame}
#| code-fold: false

preds$voi <- factor(preds$voi, levels = c('nasal', 'unasp', 'asp'))
```

:::
:::

# Results {#sec-results}

## Checking assumptions

Before proceeding to the statistical analysis of C*F*~0~ in @sec-res-cf0, in this section we first present some brief data exploration to check whether the assumptions underlying our research questions and hypotheses hold up. 

A core assumption of *RQ*2 is that the aspiration contrast is comparable in speakers from Jutland and Zealand; if this contrast differs in these two varieties, it would be a major confound. 
As proxies for this, we plot the distributions of pVOT in @fig-pVOT. 
The plots show that pVOT is quite similar across varieties; aspirated stops are slightly longer in Jutland varieties, but the difference is below 5 ms on average.
We also facet this by focus condition, to check whether there are major pVOT differences between words with focus and words without; this would not necessarily be a major confound, but might help in the interpretation of our results. 
Somewhat surprisingly, pVOT appears to be very similar across conditions.

```{r}
#| label: fig-pVOT
#| warning: false
#| message: false
#| fig-cap: Violin plots showing the distributions of positive voice onset time vlaues by onset category, focus condition, and variety.

sl %>% mutate(varietyFullNames = 
                ifelse(variety == 'j', 'Jutland', 'Zealand')) %>%
  filter(voi != 'nasal', !is.na(variety)) %>% 
  ggplot() +
  aes(x=varietyFullNames, y=vot, fill=voi) +
  geom_jitter(aes(col=voi), alpha=0.1) +
  geom_violin() +
  facet_grid(cond~voi,
             labeller = labeller(
               cond = c(foc = 'Focus', 
                        nfoc= 'Non-focus'),
               voi = c(unasp = 'Unaspirated',
                       asp = 'Aspirated'))) +
  xlab('Variety') +
  ylab('Positive voice onset time (ms)') +
  scale_color_manual(values = c('blue', 'darkorange'),
                     name = 'Onset',
                     labels = c('unaspirated', 'aspirated'),
                     guide = 'none') +
  scale_fill_manual(values = c('blue', 'darkorange'),
                    name = 'Onset',
                    labels = c('unaspirated', 'aspirated'),
                    guide = 'none') +
  trajTheme
```

Both *RQ*2 and *RQ*3 rely on specific assumptions about the baseline pitch contour when combining focus conditions, the voice quality contrast, and regional varieties. To this end, we plot the *F*~0~ trajectories of items with nasal onsets in all those combinations in @fig-baselineTrajs. 
The top-right frame of @fig-baselineTrajs shows that the pitch peak in Jutland Danish does indeed fall earlier than in Zealand Danish as discussed in @sec-stresspitch, but the two trajectories are more similar than expected from previous descriptions. 
While we cannot straightforwardly make judgments about syllable boundaries from @fig-baselineTrajs, it appears that the pitch peak in both varieties falls in the post-tonic syllable, although there is likely an earlier and more prominent rise in the tonic syllable among the Jutland speakers. 
This somewhat complicates the interpretation of *RQ*2, as not all of our assumptions are fully met. We will discuss this further in light of the results in @sec-disc-rq2.

```{r}
#| label: fig-baselineTrajs
#| warning: false
#| message: false
#| fig-cap: Smoothed *F*~0~ trajectories of words with nasal onsets showing combinations of the focus condition, voice quality contrast, and regional variety. Trajectories are smoothed using separate generalized additive models.

td2 %>%
  filter(!is.na(variety), voi == 'nasal') %>%
  ggplot() +
  aes(x=times_norm, y=zf0, color=variety) %>%
  geom_smooth(method='gam') +
  facet_grid(st~cond,
             labeller = labeller(
               cond = c(foc = 'Focus', 
                        nfoc= 'Non-focus'),
               st = c(nst = 'Non-stød',
                       st = 'Stød'))) +
  ylab('*F*~0~ (*z*-scored)') +
  xlab('Time (norm.)') +
  scale_color_manual(values = c('blue', 'darkorange'),
                     labels = c('Jutland', 'Zealand')) +
  trajTheme
```

The bottom-right frame of @fig-baselineTrajs shows that the pitch onset is higher in syllables with stød, and that pitch rises slightly and then drops. 
This is the case in both varieties, but pitch both rises and drops much more dramatically in Jutland Danish. 
This is in line with the findings of @kyst2008 and @siem2023diss that stød in Jutland Danish is predominantly tonal, while in Zealand Danish there is a voice quality component which may not be captured in @fig-baselineTrajs. 
In any case, it is clearly the case -- in both varieties, but more so in Jutland Danish -- that syllables with stød place constraints on the vocal folds that may either strengthen or weaken C*F*~0~ effects, following *RQ*3.
It is the case across the board that trajectories in the non-focus condition have similar shapes to the focus condition, but with lowered pitch and much smaller excursions. 


## Co-intrinsic *F*~0~ {#sec-res-cf0}

The research questions posed in @sec-rq are tested with the GAMM that was presented in @sec-methods-stats. The model has a high effect size of $R^2=0.64$. 
We do not explore the parametric coefficients of the model in any detail, as they are all control variables, and generally taken into account in the plots below. 
It is worth mentioning here that all dynamic model terms are highly significant, that most levels of the parametric four-way interaction also differ significantly from the model intercept (i.e., they exert a constant influence on pitch level), and that high vowels are predicted to raise pitch by 0.29 standard deviations ($SE = 0.02, t = 12.02, p < .001$).

All model-predicted trajectories are shown in @fig-gammfit-nonst and @fig-gammfit-st. Both plots are faceted by focus condition and variety, such that focused words are shown in the left column and non-focused words in the right column, and speakers from Jutland are shown in the top row and speakers from Zealand in the second row.
Lines are colored by onset category, and in addition to the predicted values, the plots also show pointwise 95% confidence intervals. 
The straight lines at the top and bottom of each plot indicate parts of trajectories that are significantly higher than the nasal baseline.
@fig-gammfit-nonst shows words without stød, and @fig-gammfit-st shows words with stød.

```{r}
#| label: fig-gammfit-nonst
#| warning: false
#| message: false
#| fig-cap: Model predicted *F*~0~ trajectories with 95% confidence intervals of words without stød, faceted by focus condition and variety and colored by onset category. Straight lines at the top and bottom of each facet indicate parts of trajectories that are significantly above the nasal baseline.
#| fig-height: 5.5

preds %>% filter(st == 'nst') %>%
  ggplot() +
  aes(x=times_norm) +
  geom_ribbon(aes(ymin = fit - CI, ymax = fit + CI,
                  fill = voi), alpha = 0.2) +
  geom_line(aes(y = fit, color = voi)) +
  geom_linerange(aes(xmin=unasp_lower, xmax=unasp_upper, y=-2),
                 color = 'blue', lwd = 1) +
  geom_linerange(aes(xmin=asp_lower, xmax=asp_upper, y=2.5),
                 color = 'darkorange', lwd=1) +
  facet_grid(variety~cond,
             labeller = labeller(
               variety = c(j = 'Jutland', z = 'Zealand'),
               cond = c(foc = 'Focus', nfoc = 'Non-focus'))) +
  xlim(0, 1) +
  ylab('Fitted *F*~0~ (z-scored)') +
  xlab('Time (norm.)') +
  scale_color_manual(values = c('black', 'blue', 'darkorange'),
                     name = 'Onset',
                     labels = c('nasal', 'unaspirated', 'aspirated')) +
  scale_fill_manual(values = c('black', 'blue', 'darkorange'),
                     name = 'Onset',
                     labels = c('nasal', 'unaspirated', 'aspirated')) +
  ggtitle('Non-stød') +
  trajTheme
```

```{r}
#| label: fig-gammfit-st
#| warning: false
#| message: false
#| fig-cap: Model predicted *F*~0~ trajectories with 95% confidence intervals of words with stød, faceted by focus condition and variety and colored by onset category. Straight lines at the top and bottom of each facet indicate parts of trajectories that are significantly above the nasal baseline.
#| fig-height: 5.5

preds %>% filter(st == 'st') %>%
  ggplot() +
  aes(x=times_norm) +
  geom_ribbon(aes(ymin = fit - CI, ymax = fit + CI,
                  fill = voi), alpha = 0.2) +
  geom_line(aes(y = fit, color = voi)) +
  geom_linerange(aes(xmin=unasp_lower, xmax=unasp_upper, y=-2),
                 color = 'blue', lwd = 1) +
  geom_linerange(aes(xmin=asp_lower, xmax=asp_upper, y=2.5),
                 color = 'darkorange', lwd=1) +
  facet_grid(variety~cond,
             labeller = labeller(
               variety = c(j = 'Jutland', z = 'Zealand'),
               cond = c(foc = 'Focus', nfoc = 'Non-focus'))) +
  xlim(0, 1) +
  ylab('Fitted *F*~0~ (z-scored)') +
  xlab('Time (norm.)') +
  scale_color_manual(values = c('black', 'blue', 'darkorange'),
                     name = 'Onset',
                     labels = c('nasal', 'unaspirated', 'aspirated')) +
  scale_fill_manual(values = c('black', 'blue', 'darkorange'),
                     name = 'Onset',
                     labels = c('nasal', 'unaspirated', 'aspirated')) +
  ggtitle('Stød') +
  trajTheme
```

The plots show C*F*~0~ effects from both unaspirated and aspirated stops in all conditions, although of differing magnitude and temporal extent. The C*F*~0~ effect of aspirated stops immediately at the time of voicing onset have a magnitude of 1--1.5 standard deviations.
Unaspirated stops display C*F*~0~ effects of smaller magnitude and shorter temporal extent across all conditions. 
The differences are sometimes negligible, but among Zealand speakers the C*F*~0~ effects of unaspirated stops is often very short-lasting. *F*~0~ immediately following unaspirated stops is typically closer to aspirated stops than to nasals.

If we consider words without stød, the predicted C*F*~0~ effects are stronger under focus in terms of both magnitude and temporal extent. 
This is the case for both Jutland and Zealand speakers, although in aspirated stops, the weakening of C*F*~0~ effects in the non-focus condition is clearly more extensive for Jutland speakers. 
Although the pitch onset after the nasal baseline is low under focus for both Jutland and Zealand speakers, it is even lower when not under focus. 
Unfortunately, this means that we cannot straightforwardly tease apart the influence of high pitch and focus from these results alone, and the results cannot be straightforwardly explained with reference to dialectal differences in the pitch target, as laid out in @sec-rq. 

The situation is different in words with stød. 
Here, there is no obvious across-the-board reduction of C*F*~0~ effects when not focused.
In fact, if anything, C*F*~0~ effects tend to last somewhat longer when not focused, although it is not the case that their magnitude is greater.
This is especially clear for Jutland speakers.
When comparing focused words with and without stød, C*F*~0~ effects of aspirated stops in particular last much shorter in words with stød, and the magnitude of effects in aspirated stops is also smaller. 

Note that in the focused stød words of Zealand speakers, words with nasal onsets appear to have an *F*~0~ dip about halfway through the trajectory that words with obstruent onsets do not share. 
The global pitch shape in general appears simpler in words with obstruent onsets. 
We have no hypotheses about this or explanations of it and will not discuss this further; it may be due to pitch tracking issues during the stød phase proper, which is after all expected to be much less modal among speakers from Zealand than speakers from Jutland.

In the following section, we will discuss the theoretical implications of these findings in light of the research questions and hypotheses posed in @sec-rq.

# Discussion {#sec-disc}

In this section, we discuss our findings in light of our three research questions in turn: in @sec-disc-rq1, the effect of having two series of voiceless stops, and what the results tell us about general mechanisms of C*F*~0~ in light of the existing studies of how the Danish laryngeal contrast is implemented; in @sec-disc-rq2, we attempt to tease apart the influence of high pitch and focus on C*F*~0~; and in @sec-disc-rq3, we discuss how competing demands on the larynx influence C*F*~0~.

## Multiple series of voiceless stops and C*F*~0~ {#sec-disc-rq1}

Across all contexts and varieties tested in this study, we find raised *F*~0~ after stop releases relative to a neutral baseline, and we find more raising after aspirated stops, i.e. /p/ > /b/ > /m/.
These findings reproduce the results of @petersen1983 in a greater range of contexts and with more naturalistic data.
The findings are in line with *H*1~d~, and are clear evidence against the claim that C*F*~0~ effects are the result of gestures that promote voicing [e.g. @ewan1976], and as such also against Kingson and Diehl's [-@kingston1994] characterization of Danish stops and their arguments for proposing an underlying [+voice] specification for /b/. 
Instead, the results support accounts of C*F*~0~ as predominantly physiological reaction to gestures that inhibit voicing [following @goldstein1986]. 

@goldstein1986 do not offer many specific details about how this mechanism would work in practice.
@lofqvist1989 propose that it results from tensing of the cricothyroid muscle, but our results do not support this, since the limited available evidence suggests that the cricothyroid is in rest position during the production of Danish /b d g/ [@hutters1985]. 
A more likely driver is suppression of vocalis activity, followed by a sudden increase in activity near the vowel onset to re-initiate voicing, following e.g. @hoole2006; @hutters1985 finds evidence of this behavior in both series of stops, but especially /p t k/, which is in line with differences in magnitude and temporal extent of the reported C*F*~0~ effects.

The effect of aspiration on *F*~0~ is not universal. 
While aspiration increases *F*~0~ in languages like English, German, and Swedish, as well as Danish, but lowers *F*~0~ in languages like Nepali and Bengali. 
In yet other languages, like Kurtöp, *F*~0~ appears to be raised after aspirated stops but less so than after plain voiceless stops [@hyslop2024].
Similarly, syllable final /h/ has been shown to cause *F*~0~ lowering in the preceding vowel in some languages, like Arabic and Itunyuso Trique [@hombert1979; @dicanio2012], whereas in other languages, e.g. Eastern Khmu, it causes *F*~0~ raising [@kirby2024].
In other words, glottal spreading (achieved through tensing of the posterior crycoarytenoids) does not appear to lead to a specific *F*~0~ pattern, but rather, the various C*F*~0~ affects are likely the result of other concomitant laryngeal gestures.
In Danish, the most likely culprit is the pattern of activity in the vocalis.

These results are consistent with the phonological proposal by @goldstein1986, where the laryngeal contrast is underlyingly represented with continuous gestural scores. This proposal has the added advantage that it is also consistent with the intervocalic voicing patterns discussed by @puggaardrode2022labphon.

## C*F*~0~, focus, and high pitch {#sec-disc-rq2}

The design of the current study was motivated by studies, predominantly from the 1980s, showing that the pitch peak placement in a stress group falls much earlier in Jutland Danish than Copenhagen Danish. 
While we do find an earlier pitch peak in Jutland Danish, both varieties now appear to have peak delay, possibly due to incipient change that causes Jutland Danish to become more similar to Standard Copenhagen Danish; this requires more research, and falls beyond the scope of the current study.
In any case, this makes it difficult to directly test the hypotheses associated with our *RQ*2, i.e. to tease apart the influence of high pitch and focus on C*F*~0~ effects.
Luckily, our design affords some other ways to approach this.

Target *F*~0~ appears to be relatively low in the beginning of stressed syllables in both varieties. 
Even so, C*F*~0~ effects are stronger under focus -- at least in words with a modal voice target, i.e. words without stød.
Although, *F*~0~ is also generally higher under focus, including at the vowel onset, strengthened C*F*~0~ is unlikely to be a synergistic effect [as discussed by @chen2011jphon], as we would presumably not expect C*F*~0~ synergy unless it co-occurs with a pitch target that is actually high.
Another reason to doubt an *F*~0~ synergy account of C*F*~0~ enhancement is that we do *not* see C*F*~0~ enhancement in words with stød relative to words stød, even though stød words *do* have a high initial pitch target. 

This at least shows that focus *can* lead to C*F*~0~ enhancement independently of the pitch environment, which is in line with *H*2~b~. 
The mechanism behind this is not obvious, especially since, as we saw in @fig-pVOT, our data does not show evidence that focus increases pVOT. 
One possible explanation for this is that focus leads to enhancement of some, but not all, laryngeal gestures in stop onsets.

## C*F*~0~ and competing demands on the vocal folds

Many of the patterns in the results that we have yet to discuss can arguably be explained if we assume that C*F*~0~ effects can be constrained if there are competing demands on the vocal folds. 
As discussed in @sec-universality, there is ample support for this from tone languages, where C*F*~0~ effects often vary in scope, magnitude, and even direction based on the tonal context [for an overview, see @kirby2018jphon].

As mentioned above, we do not find evidence of a synergistic effect where C*F*~0~ is enhanced in high pitch contexts, as discussed by e.g. @chen2011jphon. 
There is certainly no evidence for this in words with stød, where C*F*~0~ effects are weakened even though they consistently have higher *F*~0~ onset than words without it. 
This is likely because stød places a range of demands on the vocal folds [see @fischerjorgensen1987; -@fischerjorgensen1989], including highly increased activity in the vocalis and cricothyroid muscles which extends into the beginning of the vowel or even the preceding consonant. 
This suggests that competing phonological demands on the vocal folds reduce the capability of C*F*~0~ effects to be temporally extensive.
Such a mechanism can also help explain why C*F*~0~ effects appear to be *more* extensive in syllables that lack focus; the pitch range is generally reduced here, so it is likely that the laryngeal adjustments caused by competing gestures are also weaker, allowing greater range for the C*F*~0~ effects.
These results support *H*3~b~.

In the focus context in syllables without stød, Jutland Danish shows more extensive C*F*~0~ effects than Zealand Danish even though the pitch peak associated with stress is further removed from the vowel onset in Zealand Danish.
As also mentioned above, this is unlikely to be a high pitch synergy effect in Jutland Danish, as the pitch peak is still quite far removed from the vowel onset. 
Another arguably more likely explanation is that the functional load of the pitch rise, i.e. the transition from low to high pitch, is higher in Zealand Danish. 
This would explain why *F*~0~ after aspirated stops typically falls to a low position and then rises, unlike in Jutland Danish, where the results suggest that the pitch rise may be optional after aspirated stops, possibly due to a higher functional load of the fall following the peak. 

# Conclusion

In this paper, we have revisited co-intrinsic pitch effects in Danish, a language with two series of contrastive voiceless stops. 
We found that both series of stops increase the pitch of the following vowel relative to a neutral baseline, although the aspirated and unaspirated series differ in terms of magnitude and temporal extent.
This result challenges accounts of co-intrinsic pitch as primarily a result of cricothyroid tensing to enforce voicelessness, since previous research suggests that the cricothyroid is essentially in rest position during the production of Danish unaspirated stops.
The exact biomechanical cause of co-intrinsic pitch in Danish is a topic we leave for further investigation.

In order to test how co-intrinsic pitch is affected by the phonological context in various ways, we varied the pragmatic focus condition and phonological voice quality of items, and recruited speakers of different varieties of Danish which do not appear to differ in the implementation of laryngeal contrast, but differ in terms of prosodic phonology.
The upshot is that we do not find evidence of co-intrinsic pitch being enhanced in high pitch environments as has previously been suggested, but rather we find evidence that co-intrinsic pitch is inhibited when there are competing phonological demands on the vocal folds. 
Focus appears to enhance co-intrinsic pitch, but this effect also disappears when there are strong competing demands on the vocal folds. 
